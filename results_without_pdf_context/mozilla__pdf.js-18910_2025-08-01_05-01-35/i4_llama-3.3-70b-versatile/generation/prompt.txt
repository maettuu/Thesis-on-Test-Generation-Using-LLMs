Before you begin:
- Keep going until the job is completely solved — don’t stop halfway.
- If you’re unsure about the behavior, reread the provided patch carefully; do not hallucinate.
- Plan your approach before writing code by reflecting on whether the test truly fails before and passes after.

Issue:
<issue>
Use ImageDecoder to speed up decoding images in PDFs
</issue>

Patch:
<patch>
diff --git a/src/core/base_stream.js b/src/core/base_stream.js
--- a/src/core/base_stream.js
+++ b/src/core/base_stream.js
@@ -68,6 +68,10 @@ class BaseStream {
     return false;
   }
 
+  async getTransferableImage() {
+    return null;
+  }
+
   peekByte() {
     const peekedByte = this.getByte();
     if (peekedByte !== -1) {

diff --git a/src/core/image.js b/src/core/image.js
--- a/src/core/image.js
+++ b/src/core/image.js
@@ -752,6 +752,10 @@ class PDFImage {
         drawWidth === originalWidth &&
         drawHeight === originalHeight
       ) {
+        const image = await this.#getImage(originalWidth, originalHeight);
+        if (image) {
+          return image;
+        }
         const data = await this.getImageBytes(originalHeight * rowBytes, {});
         if (isOffscreenCanvasSupported) {
           if (mustBeResized) {
@@ -810,6 +814,10 @@ class PDFImage {
           }
 
           if (isHandled) {
+            const image = await this.#getImage(drawWidth, drawHeight);
+            if (image) {
+              return image;
+            }
             const rgba = await this.getImageBytes(imageLength, {
               drawWidth,
               drawHeight,
@@ -1013,6 +1021,20 @@ class PDFImage {
     };
   }
 
+  async #getImage(width, height) {
+    const bitmap = await this.image.getTransferableImage();
+    if (!bitmap) {
+      return null;
+    }
+    return {
+      data: null,
+      width,
+      height,
+      bitmap,
+      interpolate: this.interpolate,
+    };
+  }
+
   async getImageBytes(
     length,
     {

diff --git a/src/core/jpeg_stream.js b/src/core/jpeg_stream.js
--- a/src/core/jpeg_stream.js
+++ b/src/core/jpeg_stream.js
@@ -13,10 +13,10 @@
  * limitations under the License.
  */
 
+import { shadow, warn } from "../shared/util.js";
 import { DecodeStream } from "./decode_stream.js";
 import { Dict } from "./primitives.js";
 import { JpegImage } from "./jpg.js";
-import { shadow } from "../shared/util.js";
 
 /**
  * For JPEG's we use a library to decode these images and the stream behaves
@@ -32,6 +32,18 @@ class JpegStream extends DecodeStream {
     this.params = params;
   }
 
+  static get canUseImageDecoder() {
+    return shadow(
+      this,
+      "canUseImageDecoder",
+      // eslint-disable-next-line no-undef
+      typeof ImageDecoder === "undefined"
+        ? Promise.resolve(false)
+        : // eslint-disable-next-line no-undef
+          ImageDecoder.isTypeSupported("image/jpeg")
+    );
+  }
+
   get bytes() {
     // If `this.maybeLength` is null, we'll get the entire stream.
     return shadow(this, "bytes", this.stream.getBytes(this.maybeLength));
@@ -46,22 +58,7 @@ class JpegStream extends DecodeStream {
     this.decodeImage();
   }
 
-  decodeImage(bytes) {
-    if (this.eof) {
-      return this.buffer;
-    }
-    bytes ||= this.bytes;
-
-    // Some images may contain 'junk' before the SOI (start-of-image) marker.
-    // Note: this seems to mainly affect inline images.
-    for (let i = 0, ii = bytes.length - 1; i < ii; i++) {
-      if (bytes[i] === 0xff && bytes[i + 1] === 0xd8) {
-        if (i > 0) {
-          bytes = bytes.subarray(i);
-        }
-        break;
-      }
-    }
+  get jpegOptions() {
     const jpegOptions = {
       decodeTransform: undefined,
       colorTransform: undefined,
@@ -93,8 +90,34 @@ class JpegStream extends DecodeStream {
         jpegOptions.colorTransform = colorTransform;
       }
     }
-    const jpegImage = new JpegImage(jpegOptions);
+    return shadow(this, "jpegOptions", jpegOptions);
+  }
+
+  #skipUselessBytes(data) {
+    // Some images may contain 'junk' before the SOI (start-of-image) marker.
+    // Note: this seems to mainly affect inline images.
+    for (let i = 0, ii = data.length - 1; i < ii; i++) {
+      if (data[i] === 0xff && data[i + 1] === 0xd8) {
+        if (i > 0) {
+          data = data.subarray(i);
+        }
+        break;
+      }
+    }
+    return data;
+  }
+
+  decodeImage(bytes) {
+    if (this.eof) {
+      return this.buffer;
+    }
+    bytes = this.#skipUselessBytes(bytes || this.bytes);
 
+    // TODO: if an image has a mask we need to combine the data.
+    // So ideally get a VideoFrame from getTransferableImage and then use
+    // copyTo.
+
+    const jpegImage = new JpegImage(this.jpegOptions);
     jpegImage.parse(bytes);
     const data = jpegImage.getData({
       width: this.drawWidth,
@@ -113,6 +136,48 @@ class JpegStream extends DecodeStream {
   get canAsyncDecodeImageFromBuffer() {
     return this.stream.isAsync;
   }
+
+  async getTransferableImage() {
+    if (!(await JpegStream.canUseImageDecoder)) {
+      return null;
+    }
+    const jpegOptions = this.jpegOptions;
+    if (jpegOptions.decodeTransform) {
+      // TODO: We could decode the image thanks to ImageDecoder and then
+      // get the pixels with copyTo and apply the decodeTransform.
+      return null;
+    }
+    let decoder;
+    try {
+      // TODO: If the stream is Flate & DCT we could try to just pipe the
+      // the DecompressionStream into the ImageDecoder: it'll avoid the
+      // intermediate ArrayBuffer.
+      const bytes =
+        (this.canAsyncDecodeImageFromBuffer &&
+          (await this.stream.asyncGetBytes())) ||
+        this.bytes;
+      if (!bytes) {
+        return null;
+      }
+      const data = this.#skipUselessBytes(bytes);
+      if (!JpegImage.canUseImageDecoder(data, jpegOptions.colorTransform)) {
+        return null;
+      }
+      // eslint-disable-next-line no-undef
+      decoder = new ImageDecoder({
+        data,
+        type: "image/jpeg",
+        preferAnimation: false,
+      });
+
+      return (await decoder.decode()).image;
+    } catch (reason) {
+      warn(`getTransferableImage - failed: "${reason}".`);
+      return null;
+    } finally {
+      decoder?.close();
+    }
+  }
 }
 
 export { JpegStream };

diff --git a/src/core/jpg.js b/src/core/jpg.js
--- a/src/core/jpg.js
+++ b/src/core/jpg.js
@@ -744,55 +744,109 @@ function findNextFileMarker(data, currentPos, startPos = currentPos) {
   };
 }
 
+function prepareComponents(frame) {
+  const mcusPerLine = Math.ceil(frame.samplesPerLine / 8 / frame.maxH);
+  const mcusPerColumn = Math.ceil(frame.scanLines / 8 / frame.maxV);
+  for (const component of frame.components) {
+    const blocksPerLine = Math.ceil(
+      (Math.ceil(frame.samplesPerLine / 8) * component.h) / frame.maxH
+    );
+    const blocksPerColumn = Math.ceil(
+      (Math.ceil(frame.scanLines / 8) * component.v) / frame.maxV
+    );
+    const blocksPerLineForMcu = mcusPerLine * component.h;
+    const blocksPerColumnForMcu = mcusPerColumn * component.v;
+
+    const blocksBufferSize =
+      64 * blocksPerColumnForMcu * (blocksPerLineForMcu + 1);
+    component.blockData = new Int16Array(blocksBufferSize);
+    component.blocksPerLine = blocksPerLine;
+    component.blocksPerColumn = blocksPerColumn;
+  }
+  frame.mcusPerLine = mcusPerLine;
+  frame.mcusPerColumn = mcusPerColumn;
+}
+
+function readDataBlock(data, offset) {
+  const length = readUint16(data, offset);
+  offset += 2;
+  let endOffset = offset + length - 2;
+
+  const fileMarker = findNextFileMarker(data, endOffset, offset);
+  if (fileMarker?.invalid) {
+    warn(
+      "readDataBlock - incorrect length, current marker is: " +
+        fileMarker.invalid
+    );
+    endOffset = fileMarker.offset;
+  }
+
+  const array = data.subarray(offset, endOffset);
+  offset += array.length;
+  return { appData: array, newOffset: offset };
+}
+
+function skipData(data, offset) {
+  const length = readUint16(data, offset);
+  offset += 2;
+  const endOffset = offset + length - 2;
+
+  const fileMarker = findNextFileMarker(data, endOffset, offset);
+  if (fileMarker?.invalid) {
+    return fileMarker.offset;
+  }
+  return endOffset;
+}
+
 class JpegImage {
   constructor({ decodeTransform = null, colorTransform = -1 } = {}) {
     this._decodeTransform = decodeTransform;
     this._colorTransform = colorTransform;
   }
 
-  parse(data, { dnlScanLines = null } = {}) {
-    function readDataBlock() {
-      const length = readUint16(data, offset);
-      offset += 2;
-      let endOffset = offset + length - 2;
-
-      const fileMarker = findNextFileMarker(data, endOffset, offset);
-      if (fileMarker?.invalid) {
-        warn(
-          "readDataBlock - incorrect length, current marker is: " +
-            fileMarker.invalid
-        );
-        endOffset = fileMarker.offset;
-      }
-
-      const array = data.subarray(offset, endOffset);
-      offset += array.length;
-      return array;
+  static canUseImageDecoder(data, colorTransform = -1) {
+    let offset = 0;
+    let numComponents = null;
+    let fileMarker = readUint16(data, offset);
+    offset += 2;
+    if (fileMarker !== /* SOI (Start of Image) = */ 0xffd8) {
+      throw new JpegError("SOI not found");
     }
+    fileMarker = readUint16(data, offset);
+    offset += 2;
 
-    function prepareComponents(frame) {
-      const mcusPerLine = Math.ceil(frame.samplesPerLine / 8 / frame.maxH);
-      const mcusPerColumn = Math.ceil(frame.scanLines / 8 / frame.maxV);
-      for (const component of frame.components) {
-        const blocksPerLine = Math.ceil(
-          (Math.ceil(frame.samplesPerLine / 8) * component.h) / frame.maxH
-        );
-        const blocksPerColumn = Math.ceil(
-          (Math.ceil(frame.scanLines / 8) * component.v) / frame.maxV
-        );
-        const blocksPerLineForMcu = mcusPerLine * component.h;
-        const blocksPerColumnForMcu = mcusPerColumn * component.v;
-
-        const blocksBufferSize =
-          64 * blocksPerColumnForMcu * (blocksPerLineForMcu + 1);
-        component.blockData = new Int16Array(blocksBufferSize);
-        component.blocksPerLine = blocksPerLine;
-        component.blocksPerColumn = blocksPerColumn;
+    markerLoop: while (fileMarker !== /* EOI (End of Image) = */ 0xffd9) {
+      switch (fileMarker) {
+        case 0xffc0: // SOF0 (Start of Frame, Baseline DCT)
+        case 0xffc1: // SOF1 (Start of Frame, Extended DCT)
+        case 0xffc2: // SOF2 (Start of Frame, Progressive DCT)
+          // Skip marker length.
+          // Skip precision.
+          // Skip scanLines.
+          // Skip samplesPerLine.
+          numComponents = data[offset + (2 + 1 + 2 + 2)];
+          break markerLoop;
+        case 0xffff: // Fill bytes
+          if (data[offset] !== 0xff) {
+            // Avoid skipping a valid marker.
+            offset--;
+          }
+          break;
       }
-      frame.mcusPerLine = mcusPerLine;
-      frame.mcusPerColumn = mcusPerColumn;
+      offset = skipData(data, offset);
+      fileMarker = readUint16(data, offset);
+      offset += 2;
+    }
+    if (numComponents === 4) {
+      return false;
+    }
+    if (numComponents === 3 && colorTransform === 0) {
+      return false;
     }
+    return true;
+  }
 
+  parse(data, { dnlScanLines = null } = {}) {
     let offset = 0;
     let jfif = null;
     let adobe = null;
@@ -830,7 +884,8 @@ class JpegImage {
         case 0xffee: // APP14
         case 0xffef: // APP15
         case 0xfffe: // COM (Comment)
-          const appData = readDataBlock();
+          const { appData, newOffset } = readDataBlock(data, offset);
+          offset = newOffset;
 
           if (fileMarker === 0xffe0) {
             // 'JFIF\x00'

diff --git a/src/display/canvas.js b/src/display/canvas.js
--- a/src/display/canvas.js
+++ b/src/display/canvas.js
@@ -1059,8 +1059,10 @@ class CanvasGraphics {
     // Vertical or horizontal scaling shall not be more than 2 to not lose the
     // pixels during drawImage operation, painting on the temporary canvas(es)
     // that are twice smaller in size.
-    const width = img.width;
-    const height = img.height;
+
+    // displayWidth and displayHeight are used for VideoFrame.
+    const width = img.width ?? img.displayWidth;
+    const height = img.height ?? img.displayHeight;
     let widthScale = Math.max(
       Math.hypot(inverseTransform[0], inverseTransform[1]),
       1


</patch>

Imports:
<imports>
Available Packages
Dev Dependencies:
- @babel/core: ^7.25.8
- @babel/preset-env: ^7.25.8
- @babel/runtime: ^7.25.7
- @fluent/bundle: ^0.18.0
- @fluent/dom: ^0.10.0
- @jazzer.js/core: ^2.1.0
- @metalsmith/layouts: ^2.7.0
- @metalsmith/markdown: ^1.10.0
- autoprefixer: ^10.4.20
- babel-loader: ^9.2.1
- caniuse-lite: ^1.0.30001669
- canvas: ^3.0.0-rc2
- core-js: ^3.38.1
- eslint: ^8.57.1
- eslint-plugin-import: ^2.31.0
- eslint-plugin-jasmine: ^4.2.2
- eslint-plugin-json: ^3.1.0
- eslint-plugin-no-unsanitized: ^4.1.2
- eslint-plugin-perfectionist: ^3.9.1
- eslint-plugin-prettier: ^5.2.1
- eslint-plugin-unicorn: ^56.0.0
- gulp: ^5.0.0
- gulp-cli: ^3.0.0
- gulp-postcss: ^10.0.0
- gulp-rename: ^2.0.0
- gulp-replace: ^1.1.4
- gulp-zip: ^6.0.0
- highlight.js: ^11.10.0
- jasmine: ^5.4.0
- jsdoc: ^4.0.4
- jstransformer-nunjucks: ^1.2.0
- metalsmith: ^2.6.3
- metalsmith-html-relative: ^2.0.5
- ordered-read-streams: ^2.0.0
- path2d: ^0.2.1
- pngjs: ^7.0.0
- postcss: ^8.4.47
- postcss-dark-theme-class: ^1.3.0
- postcss-dir-pseudo-class: ^9.0.0
- postcss-discard-comments: ^7.0.3
- postcss-nesting: ^13.0.0
- prettier: ^3.3.3
- puppeteer: 23.3.1
- stylelint: ^16.10.0
- stylelint-prettier: ^5.0.2
- svglint: ^3.0.0
- terser-webpack-plugin: ^5.3.10
- tsc-alias: ^1.8.10
- ttest: ^4.0.0
- typescript: ^5.6.3
- vinyl: ^3.0.0
- webpack: ^5.95.0
- webpack-stream: ^7.0.0
- yargs: ^17.7.2

Engines:
- node: >=18

Available Relative Imports:
- `../../src/core/annotation.js`: Annotation, AnnotationBorderStyle, AnnotationFactory, MarkupAnnotation, getQuadPoints
- `../../src/core/bidi.js`: bidi
- `../../src/core/cff_parser.js`: CFFCharset, CFFCompiler, CFFFDSelect, CFFParser, CFFStrings
- `../../src/core/cmap.js`: CMap, CMapFactory, IdentityCMap
- `../../src/core/colorspace.js`: ColorSpace
- `../../src/core/core_utils.js`: arrayBuffersToBytes, encodeToXmlString, escapePDFName, escapeString, getInheritableProperty, getSizeInBytes, isAscii, isWhiteSpace, log2, numberToString, parseXFAPath, recoverJsURL, stringToUTF16HexString, stringToUTF16String, toRomanNumerals, validateCSSFont
- `../../src/core/crypto.js`: AES128Cipher, AES256Cipher, ARCFourCipher, CipherTransformFactory, PDF17, PDF20, calculateMD5, calculateSHA256, calculateSHA384, calculateSHA512
- `../../src/core/default_appearance.js`: createDefaultAppearance, parseAppearanceStream, parseDefaultAppearance
- `../../src/core/document.js`: PDFDocument, Page
- `../../src/core/encodings.js`: getEncoding
- `../../src/core/evaluator.js`: PartialEvaluator
- `../../src/core/flate_stream.js`: FlateStream
- `../../src/core/font_substitutions.js`: getFontSubstitution
- `../../src/core/fonts_utils.js`: SEAC_ANALYSIS_ENABLED
- `../../src/core/function.js`: PDFFunctionFactory, PostScriptCompiler, PostScriptEvaluator
- `../../src/core/glyphlist.js`: getDingbatsGlyphsUnicode, getGlyphsUnicode
- `../../src/core/image_utils.js`: GlobalImageCache, LocalColorSpaceCache
- `../../src/core/jbig2.js`: Jbig2Error, Jbig2Image
- `../../src/core/jpg.js`: JpegError, JpegImage
- `../../src/core/jpx.js`: JpxError, JpxImage
- `../../src/core/metadata_parser.js`: MetadataParser
- `../../src/core/operator_list.js`: OperatorList
- `../../src/core/parser.js`: Lexer, Linearization, Parser
- `../../src/core/predictor_stream.js`: PredictorStream
- `../../src/core/primitives.js`: Cmd, Dict, EOF, Name, Ref, RefSet, RefSetCache, isCmd, isDict, isName, isRefsEqual
- `../../src/core/ps_parser.js`: PostScriptLexer, PostScriptParser
- `../../src/core/stream.js`: NullStream, Stream, StringStream
- `../../src/core/type1_parser.js`: Type1Parser
- `../../src/core/unicode.js`: getCharUnicodeCategory, getUnicodeForGlyph, getUnicodeRangeFor, mapSpecialUnicodeValues
- `../../src/core/worker.js`: WorkerMessageHandler, WorkerTask
- `../../src/core/writer.js`: incrementalUpdate, writeDict
- `../../src/core/xfa/bind.js`: Binder
- `../../src/core/xfa/data.js`: DataHandler
- `../../src/core/xfa/factory.js`: XFAFactory
- `../../src/core/xfa/formcalc_lexer.js`: Lexer, TOKEN, Token
- `../../src/core/xfa/formcalc_parser.js`: Errors, Parser
- `../../src/core/xfa/parser.js`: XFAParser
- `../../src/core/xfa/som.js`: searchNode
- `../../src/core/xfa/symbol_utils.js`: $dump, $getChildren, $getChildrenByClass, $getChildrenByName, $text, $uid
- `../../src/core/xml_parser.js`: SimpleXMLParser, XMLParserBase
- `../../src/display/annotation_layer.js`: AnnotationLayer
- `../../src/display/annotation_storage.js`: AnnotationStorage
- `../../src/display/api.js`: DefaultCMapReaderFactory, DefaultCanvasFactory, DefaultStandardFontDataFactory, LoopbackPort, PDFDataRangeTransport, PDFDocumentLoadingTask, PDFDocumentProxy, PDFPageProxy, PDFWorker, RenderTask, build, getDocument, version
- `../../src/display/display_utils.js`: DOMCanvasFactory, DOMSVGFactory, OutputScale, PDFDateString, PageViewport, PixelsPerInch, RenderingCancelledException, StatTimer, fetchData, getFilenameFromUrl, getPdfFilenameFromUrl, getXfaPageViewport, isDataScheme, isPdfFile, isValidFetchUrl, noContextMenu, setLayerDimensions
- `../../src/display/draw_layer.js`: DrawLayer
- `../../src/display/editor/annotation_editor_layer.js`: AnnotationEditorLayer
- `../../src/display/editor/color_picker.js`: ColorPicker
- `../../src/display/editor/tools.js`: AnnotationEditorUIManager, CommandManager
- `../../src/display/fetch_stream.js`: PDFFetchStream
- `../../src/display/metadata.js`: Metadata
- `../../src/display/network.js`: PDFNetworkStream
- `../../src/display/network_utils.js`: createHeaders, createResponseStatusError, extractFilenameFromHeader, validateRangeRequestCapabilities, validateResponseStatus
- `../../src/display/node_stream.js`: PDFNodeStream
- `../../src/display/node_utils.js`: NodePackages, fetchData
- `../../src/display/text_layer.js`: TextLayer
- `../../src/display/worker_options.js`: GlobalWorkerOptions
- `../../src/display/xfa_layer.js`: XfaLayer
- `../../src/shared/message_handler.js`: MessageHandler
- `../../src/shared/murmurhash3.js`: MurmurHash3_64
- `../../src/shared/util.js`: AbortException, AnnotationBorderStyleType, AnnotationEditorParamsType, AnnotationEditorType, AnnotationFieldFlag, AnnotationFlag, AnnotationMode, AnnotationType, BaseException, CMapCompressionType, FeatureTest, FormatError, ImageKind, InvalidPDFException, MissingPDFException, OPS, PasswordException, PasswordResponses, PermissionFlag, RenderingIntentFlag, UnexpectedResponseException, UnknownErrorException, Util, VerbosityLevel, assert, bytesToString, createValidAbsoluteUrl, getModificationDate, getVerbosityLevel, isNodeJS, normalizeUnicode, objectSize, setVerbosityLevel, shadow, string32, stringToBytes, stringToPDFString, stringToUTF8String
- `../../web/annotation_layer_builder.js`: AnnotationLayerBuilder
- `../../web/app_options.js`: AppOptions, OptionKind
- `../../web/download_manager.js`: DownloadManager
- `../../web/event_utils.js`: EventBus, WaitOnType, waitOnEventOrTimeout
- `../../web/genericl10n.js`: GenericL10n
- `../../web/pdf_find_controller.js`: FindState, PDFFindController
- `../../web/pdf_find_utils.js`: CharacterType, getCharacterType
- `../../web/pdf_history.js`: PDFHistory, isDestArraysEqual, isDestHashesEqual
- `../../web/pdf_link_service.js`: LinkTarget, PDFLinkService, SimpleLinkService
- `../../web/pdf_page_view.js`: PDFPageView
- `../../web/pdf_scripting_manager.component.js`: PDFScriptingManager
- `../../web/pdf_single_page_viewer.js`: PDFSinglePageViewer
- `../../web/pdf_viewer.js`: PDFPageViewBuffer, PDFViewer
- `../../web/struct_tree_layer_builder.js`: StructTreeLayerBuilder
- `../../web/text_layer_builder.js`: TextLayerBuilder
- `../../web/ui_utils.js`: AutoPrintRegExp, ProgressBar, RenderingStates, ScrollMode, SpreadMode, backtrackBeforeAllVisibleElements, binarySearchFirstItem, calcRound, getPageSizeInches, getVisibleElements, isPortraitOrientation, isValidRotation, parseQueryString, removeNullCharacters
- `../../web/xfa_layer_builder.js`: XfaLayerBuilder
- `./test_utils.js`: CMAP_URL, DefaultFileReaderFactory, STANDARD_FONT_DATA_URL, TEST_PDFS_PATH, XRefMock, buildGetDocumentParams, createIdFactory, createTemporaryNodeServer
- `./testreporter.js`: TestReporter
</imports>

Code:
<code>
File:
src/core/base_stream.js
1 /* Copyright 2021 Mozilla Foundation
2  *
3  * Licensed under the Apache License, Version 2.0 (the "License");
4  * you may not use this file except in compliance with the License.
5  * You may obtain a copy of the License at
6  *
7  *     http://www.apache.org/licenses/LICENSE-2.0
8  *
9  * Unless required by applicable law or agreed to in writing, software
10  * distributed under the License is distributed on an "AS IS" BASIS,
11  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12  * See the License for the specific language governing permissions and
13  * limitations under the License.
14  */
15 
16 import { bytesToString, shadow, unreachable } from "../shared/util.js";
17 
18 class BaseStream {
19   constructor() {
20     if (
21       (typeof PDFJSDev === "undefined" || PDFJSDev.test("TESTING")) &&
22       this.constructor === BaseStream
23     ) {
24       unreachable("Cannot initialize BaseStream.");
25     }
26   }
27 
28   // eslint-disable-next-line getter-return
29   get length() {
30     unreachable("Abstract getter `length` accessed");
31   }
32 
33   // eslint-disable-next-line getter-return
34   get isEmpty() {
35     unreachable("Abstract getter `isEmpty` accessed");
36   }
37 
38   get isDataLoaded() {
39     return shadow(this, "isDataLoaded", true);
40   }
41 
42   getByte() {
43     unreachable("Abstract method `getByte` called");
44   }
45 
46   getBytes(length) {
47     unreachable("Abstract method `getBytes` called");
48   }
49 
50   /**
51    * NOTE: This method can only be used to get image-data that is guaranteed
52    *       to be fully loaded, since otherwise intermittent errors may occur;
53    *       note the `ObjectLoader` class.
54    */
55   async getImageData(length, decoderOptions) {
56     return this.getBytes(length, decoderOptions);
57   }
58 
59   async asyncGetBytes() {
60     unreachable("Abstract method `asyncGetBytes` called");
61   }
62 
63   get isAsync() {
64     return false;
65   }
66 
67   get canAsyncDecodeImageFromBuffer() {
68     return false;
69   }
70 
71   peekByte() {
72     const peekedByte = this.getByte();
73     if (peekedByte !== -1) {
74       this.pos--;
75     }
76     return peekedByte;
77   }
78 
79   peekBytes(length) {
80     const bytes = this.getBytes(length);
81     this.pos -= bytes.length;
82     return bytes;
83   }
84 
85   getUint16() {
86     const b0 = this.getByte();
87     const b1 = this.getByte();
88     if (b0 === -1 || b1 === -1) {
89       return -1;
90     }
91     return (b0 << 8) + b1;
92   }
93 
94   getInt32() {
95     const b0 = this.getByte();
96     const b1 = this.getByte();
97     const b2 = this.getByte();
98     const b3 = this.getByte();
99     return (b0 << 24) + (b1 << 16) + (b2 << 8) + b3;
100   }
101 
102   getByteRange(begin, end) {
103     unreachable("Abstract method `getByteRange` called");
104   }
105 
106   getString(length) {
107     return bytesToString(this.getBytes(length));
108   }
109 
110   skip(n) {
111     this.pos += n || 1;
112   }
113 
114   reset() {
115     unreachable("Abstract method `reset` called");
116   }
117 
118   moveStart() {
119     unreachable("Abstract method `moveStart` called");
120   }
121 
122   makeSubStream(start, length, dict = null) {
123     unreachable("Abstract method `makeSubStream` called");
124   }
125 
126   /**
127    * @returns {Array | null}
128    */
129   getBaseStreams() {
130     return null;
131   }
132 }
133 
134 export { BaseStream };
File:
src/core/image.js
1 /* Copyright 2012 Mozilla Foundation
2  *
3  * Licensed under the Apache License, Version 2.0 (the "License");
4  * you may not use this file except in compliance with the License.
5  * You may obtain a copy of the License at
6  *
7  *     http://www.apache.org/licenses/LICENSE-2.0
8  *
9  * Unless required by applicable law or agreed to in writing, software
10  * distributed under the License is distributed on an "AS IS" BASIS,
11  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12  * See the License for the specific language governing permissions and
13  * limitations under the License.
14  */
15 
16 import {
17   assert,
18   FeatureTest,
19   FormatError,
20   ImageKind,
21   warn,
22 } from "../shared/util.js";
23 import {
24   convertBlackAndWhiteToRGBA,
25   convertToRGBA,
26 } from "../shared/image_utils.js";
27 import { BaseStream } from "./base_stream.js";
28 import { ColorSpace } from "./colorspace.js";
29 import { DecodeStream } from "./decode_stream.js";
30 import { ImageResizer } from "./image_resizer.js";
31 import { JpegStream } from "./jpeg_stream.js";
32 import { JpxImage } from "./jpx.js";
33 import { Name } from "./primitives.js";
34 
35 /**
36  * Decode and clamp a value. The formula is different from the spec because we
37  * don't decode to float range [0,1], we decode it in the [0,max] range.
38  */
39 function decodeAndClamp(value, addend, coefficient, max) {
40   value = addend + value * coefficient;
41   // Clamp the value to the range
42   if (value < 0) {
43     value = 0;
44   } else if (value > max) {
45     value = max;
46   }
47   return value;
48 }
49 
50 /**
51  * Resizes an image mask with 1 component.
52  * @param {TypedArray} src - The source buffer.
53  * @param {number} bpc - Number of bits per component.
54  * @param {number} w1 - Original width.
55  * @param {number} h1 - Original height.
56  * @param {number} w2 - New width.
57  * @param {number} h2 - New height.
58  * @returns {TypedArray} The resized image mask buffer.
59  */
60 function resizeImageMask(src, bpc, w1, h1, w2, h2) {
61   const length = w2 * h2;
62   let dest;
63   if (bpc <= 8) {
64     dest = new Uint8Array(length);
65   } else if (bpc <= 16) {
66     dest = new Uint16Array(length);
67   } else {
68     dest = new Uint32Array(length);
69   }
70   const xRatio = w1 / w2;
71   const yRatio = h1 / h2;
72   let i,
73     j,
74     py,
75     newIndex = 0,
76     oldIndex;
77   const xScaled = new Uint16Array(w2);
78   const w1Scanline = w1;
79 
80   for (i = 0; i < w2; i++) {
81     xScaled[i] = Math.floor(i * xRatio);
82   }
83   for (i = 0; i < h2; i++) {
84     py = Math.floor(i * yRatio) * w1Scanline;
85     for (j = 0; j < w2; j++) {
86       oldIndex = py + xScaled[j];
87       dest[newIndex++] = src[oldIndex];
88     }
89   }
90   return dest;
91 }
92 
93 class PDFImage {
94   constructor({
95     xref,
96     res,
97     image,
98     isInline = false,
99     smask = null,
100     mask = null,
101     isMask = false,
102     pdfFunctionFactory,
103     localColorSpaceCache,
104   }) {
105     this.image = image;
106     const dict = image.dict;
107 
108     const filter = dict.get("F", "Filter");
109     let filterName;
110     if (filter instanceof Name) {
111       filterName = filter.name;
112     } else if (Array.isArray(filter)) {
113       const filterZero = xref.fetchIfRef(filter[0]);
114       if (filterZero instanceof Name) {
115         filterName = filterZero.name;
116       }
117     }
118     switch (filterName) {
119       case "JPXDecode":
120         ({
121           width: image.width,
122           height: image.height,
123           componentsCount: image.numComps,
124           bitsPerComponent: image.bitsPerComponent,
125         } = JpxImage.parseImageProperties(image.stream));
126         image.stream.reset();
127         this.jpxDecoderOptions = {
128           numComponents: 0,
129           isIndexedColormap: false,
130           smaskInData: dict.has("SMaskInData"),
131         };
132         break;
133       case "JBIG2Decode":
134         image.bitsPerComponent = 1;
135         image.numComps = 1;
136         break;
137     }
138 
139     let width = dict.get("W", "Width");
140     let height = dict.get("H", "Height");
141 
142     if (
143       Number.isInteger(image.width) &&
144       image.width > 0 &&
145       Number.isInteger(image.height) &&
146       image.height > 0 &&
147       (image.width !== width || image.height !== height)
148     ) {
149       warn(
150         "PDFImage - using the Width/Height of the image data, " +
151           "rather than the image dictionary."
152       );
153       width = image.width;
154       height = image.height;
155     }
156     if (width < 1 || height < 1) {
157       throw new FormatError(
158         `Invalid image width: ${width} or height: ${height}`
159       );
160     }
161     this.width = width;
162     this.height = height;
163 
164     this.interpolate = dict.get("I", "Interpolate");
165     this.imageMask = dict.get("IM", "ImageMask") || false;
166     this.matte = dict.get("Matte") || false;
167 
168     let bitsPerComponent = image.bitsPerComponent;
169     if (!bitsPerComponent) {
170       bitsPerComponent = dict.get("BPC", "BitsPerComponent");
171       if (!bitsPerComponent) {
172         if (this.imageMask) {
173           bitsPerComponent = 1;
174         } else {
175           throw new FormatError(
176             `Bits per component missing in image: ${this.imageMask}`
177           );
178         }
179       }
180     }
181     this.bpc = bitsPerComponent;
182 
183     if (!this.imageMask) {
184       let colorSpace = dict.getRaw("CS") || dict.getRaw("ColorSpace");
185       const hasColorSpace = !!colorSpace;
186       if (!hasColorSpace) {
187         if (this.jpxDecoderOptions) {
188           colorSpace = Name.get("DeviceRGBA");
189         } else {
190           switch (image.numComps) {
191             case 1:
192               colorSpace = Name.get("DeviceGray");
193               break;
194             case 3:
195               colorSpace = Name.get("DeviceRGB");
196               break;
197             case 4:
198               colorSpace = Name.get("DeviceCMYK");
199               break;
200             default:
201               throw new Error(
202                 `Images with ${image.numComps} color components not supported.`
203               );
204           }
205         }
206       } else if (this.jpxDecoderOptions?.smaskInData) {
207         // If the jpx image has a color space then it mustn't be used in order
208         // to be able to use the color space that comes from the pdf.
209         colorSpace = Name.get("DeviceRGBA");
210       }
211 
212       this.colorSpace = ColorSpace.parse({
213         cs: colorSpace,
214         xref,
215         resources: isInline ? res : null,
216         pdfFunctionFactory,
217         localColorSpaceCache,
218       });
219       this.numComps = this.colorSpace.numComps;
220 
221       if (this.jpxDecoderOptions) {
222         this.jpxDecoderOptions.numComponents = hasColorSpace ? this.numComp : 0;
223         // If the jpx image has a color space then it musn't be used in order to
224         // be able to use the color space that comes from the pdf.
225         this.jpxDecoderOptions.isIndexedColormap =
226           this.colorSpace.name === "Indexed";
227       }
228     }
229 
230     this.decode = dict.getArray("D", "Decode");
231     this.needsDecode = false;
232     if (
233       this.decode &&
234       ((this.colorSpace &&
235         !this.colorSpace.isDefaultDecode(this.decode, bitsPerComponent)) ||
236         (isMask &&
237           !ColorSpace.isDefaultDecode(this.decode, /* numComps = */ 1)))
238     ) {
239       this.needsDecode = true;
240       // Do some preprocessing to avoid more math.
241       const max = (1 << bitsPerComponent) - 1;
242       this.decodeCoefficients = [];
243       this.decodeAddends = [];
244       const isIndexed = this.colorSpace?.name === "Indexed";
245       for (let i = 0, j = 0; i < this.decode.length; i += 2, ++j) {
246         const dmin = this.decode[i];
247         const dmax = this.decode[i + 1];
248         this.decodeCoefficients[j] = isIndexed
249           ? (dmax - dmin) / max
250           : dmax - dmin;
251         this.decodeAddends[j] = isIndexed ? dmin : max * dmin;
252       }
253     }
254 
255     if (smask) {
256       this.smask = new PDFImage({
257         xref,
258         res,
259         image: smask,
260         isInline,
261         pdfFunctionFactory,
262         localColorSpaceCache,
263       });
264     } else if (mask) {
265       if (mask instanceof BaseStream) {
266         const maskDict = mask.dict,
267           imageMask = maskDict.get("IM", "ImageMask");
268         if (!imageMask) {
269           warn("Ignoring /Mask in image without /ImageMask.");
270         } else {
271           this.mask = new PDFImage({
272             xref,
273             res,
274             image: mask,
275             isInline,
276             isMask: true,
277             pdfFunctionFactory,
278             localColorSpaceCache,
279           });
280         }
281       } else {
282         // Color key mask (just an array).
283         this.mask = mask;
284       }
285     }
286   }
287 
288   /**
289    * Handles processing of image data and returns the Promise that is resolved
290    * with a PDFImage when the image is ready to be used.
291    */
292   static async buildImage({
293     xref,
294     res,
295     image,
296     isInline = false,
297     pdfFunctionFactory,
298     localColorSpaceCache,
299   }) {
300     const imageData = image;
301     let smaskData = null;
302     let maskData = null;
303 
304     const smask = image.dict.get("SMask");
305     const mask = image.dict.get("Mask");
306 
307     if (smask) {
308       if (smask instanceof BaseStream) {
309         smaskData = smask;
310       } else {
311         warn("Unsupported /SMask format.");
312       }
313     } else if (mask) {
314       if (mask instanceof BaseStream || Array.isArray(mask)) {
315         maskData = mask;
316       } else {
317         warn("Unsupported /Mask format.");
318       }
319     }
320 
321     return new PDFImage({
322       xref,
323       res,
324       image: imageData,
325       isInline,
326       smask: smaskData,
327       mask: maskData,
328       pdfFunctionFactory,
329       localColorSpaceCache,
330     });
331   }
332 
333   static createRawMask({
334     imgArray,
335     width,
336     height,
337     imageIsFromDecodeStream,
338     inverseDecode,
339     interpolate,
340   }) {
341     // |imgArray| might not contain full data for every pixel of the mask, so
342     // we need to distinguish between |computedLength| and |actualLength|.
343     // In particular, if inverseDecode is true, then the array we return must
344     // have a length of |computedLength|.
345 
346     const computedLength = ((width + 7) >> 3) * height;
347     const actualLength = imgArray.byteLength;
348     const haveFullData = computedLength === actualLength;
349     let data, i;
350 
351     if (imageIsFromDecodeStream && (!inverseDecode || haveFullData)) {
352       // imgArray came from a DecodeStream and its data is in an appropriate
353       // form, so we can just transfer it.
354       data = imgArray;
355     } else if (!inverseDecode) {
356       data = new Uint8Array(imgArray);
357     } else {
358       data = new Uint8Array(computedLength);
359       data.set(imgArray);
360       data.fill(0xff, actualLength);
361     }
362 
363     // If necessary, invert the original mask data (but not any extra we might
364     // have added above). It's safe to modify the array -- whether it's the
365     // original or a copy, we're about to transfer it anyway, so nothing else
366     // in this thread can be relying on its contents.
367     if (inverseDecode) {
368       for (i = 0; i < actualLength; i++) {
369         data[i] ^= 0xff;
370       }
371     }
372 
373     return { data, width, height, interpolate };
374   }
375 
376   static async createMask({
377     imgArray,
378     width,
379     height,
380     imageIsFromDecodeStream,
381     inverseDecode,
382     interpolate,
383     isOffscreenCanvasSupported = false,
384   }) {
385     const isSingleOpaquePixel =
386       width === 1 &&
387       height === 1 &&
388       inverseDecode === (imgArray.length === 0 || !!(imgArray[0] & 128));
389 
390     if (isSingleOpaquePixel) {
391       return { isSingleOpaquePixel };
392     }
393 
394     if (isOffscreenCanvasSupported) {
395       if (ImageResizer.needsToBeResized(width, height)) {
396         const data = new Uint8ClampedArray(width * height * 4);
397         convertBlackAndWhiteToRGBA({
398           src: imgArray,
399           dest: data,
400           width,
401           height,
402           nonBlackColor: 0,
403           inverseDecode,
404         });
405         return ImageResizer.createImage({
406           kind: ImageKind.RGBA_32BPP,
407           data,
408           width,
409           height,
410           interpolate,
411         });
412       }
413 
414       const canvas = new OffscreenCanvas(width, height);
415       const ctx = canvas.getContext("2d");
416       const imgData = ctx.createImageData(width, height);
417       convertBlackAndWhiteToRGBA({
418         src: imgArray,
419         dest: imgData.data,
420         width,
421         height,
422         nonBlackColor: 0,
423         inverseDecode,
424       });
425 
426       ctx.putImageData(imgData, 0, 0);
427       const bitmap = canvas.transferToImageBitmap();
428 
429       return {
430         data: null,
431         width,
432         height,
433         interpolate,
434         bitmap,
435       };
436     }
437 
438     // Get the data almost as they're and they'll be decoded
439     // just before being drawn.
440     return this.createRawMask({
441       imgArray,
442       width,
443       height,
444       inverseDecode,
445       imageIsFromDecodeStream,
446       interpolate,
447     });
448   }
449 
450   get drawWidth() {
451     return Math.max(this.width, this.smask?.width || 0, this.mask?.width || 0);
452   }
453 
454   get drawHeight() {
455     return Math.max(
456       this.height,
457       this.smask?.height || 0,
458       this.mask?.height || 0
459     );
460   }
461 
462   decodeBuffer(buffer) {
463     const bpc = this.bpc;
464     const numComps = this.numComps;
465 
466     const decodeAddends = this.decodeAddends;
467     const decodeCoefficients = this.decodeCoefficients;
468     const max = (1 << bpc) - 1;
469     let i, ii;
470 
471     if (bpc === 1) {
472       // If the buffer needed decode that means it just needs to be inverted.
473       for (i = 0, ii = buffer.length; i < ii; i++) {
474         buffer[i] = +!buffer[i];
475       }
476       return;
477     }
478     let index = 0;
479     for (i = 0, ii = this.width * this.height; i < ii; i++) {
480       for (let j = 0; j < numComps; j++) {
481         buffer[index] = decodeAndClamp(
482           buffer[index],
483           decodeAddends[j],
484           decodeCoefficients[j],
485           max
486         );
487         index++;
488       }
489     }
490   }
491 
492   getComponents(buffer) {
493     const bpc = this.bpc;
494 
495     // This image doesn't require any extra work.
496     if (bpc === 8) {
497       return buffer;
498     }
499 
500     const width = this.width;
501     const height = this.height;
502     const numComps = this.numComps;
503 
504     const length = width * height * numComps;
505     let bufferPos = 0;
506     let output;
507     if (bpc <= 8) {
508       output = new Uint8Array(length);
509     } else if (bpc <= 16) {
510       output = new Uint16Array(length);
511     } else {
512       output = new Uint32Array(length);
513     }
514     const rowComps = width * numComps;
515 
516     const max = (1 << bpc) - 1;
517     let i = 0,
518       ii,
519       buf;
520 
521     if (bpc === 1) {
522       // Optimization for reading 1 bpc images.
523       let mask, loop1End, loop2End;
524       for (let j = 0; j < height; j++) {
525         loop1End = i + (rowComps & ~7);
526         loop2End = i + rowComps;
527 
528         // unroll loop for all full bytes
529         while (i < loop1End) {
530           buf = buffer[bufferPos++];
531           output[i] = (buf >> 7) & 1;
532           output[i + 1] = (buf >> 6) & 1;
533           output[i + 2] = (buf >> 5) & 1;
534           output[i + 3] = (buf >> 4) & 1;
535           output[i + 4] = (buf >> 3) & 1;
536           output[i + 5] = (buf >> 2) & 1;
537           output[i + 6] = (buf >> 1) & 1;
538           output[i + 7] = buf & 1;
539           i += 8;
540         }
541 
542         // handle remaining bits
543         if (i < loop2End) {
544           buf = buffer[bufferPos++];
545           mask = 128;
546           while (i < loop2End) {
547             output[i++] = +!!(buf & mask);
548             mask >>= 1;
549           }
550         }
551       }
552     } else {
553       // The general case that handles all other bpc values.
554       let bits = 0;
555       buf = 0;
556       for (i = 0, ii = length; i < ii; ++i) {
557         if (i % rowComps === 0) {
558           buf = 0;
559           bits = 0;
560         }
561 
562         while (bits < bpc) {
563           buf = (buf << 8) | buffer[bufferPos++];
564           bits += 8;
565         }
566 
567         const remainingBits = bits - bpc;
568         let value = buf >> remainingBits;
569         if (value < 0) {
570           value = 0;
571         } else if (value > max) {
572           value = max;
573         }
574         output[i] = value;
575         buf &= (1 << remainingBits) - 1;
576         bits = remainingBits;
577       }
578     }
579     return output;
580   }
581 
582   async fillOpacity(rgbaBuf, width, height, actualHeight, image) {
583     if (typeof PDFJSDev === "undefined" || PDFJSDev.test("TESTING")) {
584       assert(
585         rgbaBuf instanceof Uint8ClampedArray,
586         'PDFImage.fillOpacity: Unsupported "rgbaBuf" type.'
587       );
588     }
589     const smask = this.smask;
590     const mask = this.mask;
591     let alphaBuf, sw, sh, i, ii, j;
592 
593     if (smask) {
594       sw = smask.width;
595       sh = smask.height;
596       alphaBuf = new Uint8ClampedArray(sw * sh);
597       await smask.fillGrayBuffer(alphaBuf);
598       if (sw !== width || sh !== height) {
599         alphaBuf = resizeImageMask(alphaBuf, smask.bpc, sw, sh, width, height);
600       }
601     } else if (mask) {
602       if (mask instanceof PDFImage) {
603         sw = mask.width;
604         sh = mask.height;
605         alphaBuf = new Uint8ClampedArray(sw * sh);
606         mask.numComps = 1;
607         await mask.fillGrayBuffer(alphaBuf);
608 
609         // Need to invert values in rgbaBuf
610         for (i = 0, ii = sw * sh; i < ii; ++i) {
611           alphaBuf[i] = 255 - alphaBuf[i];
612         }
613 
614         if (sw !== width || sh !== height) {
615           alphaBuf = resizeImageMask(alphaBuf, mask.bpc, sw, sh, width, height);
616         }
617       } else if (Array.isArray(mask)) {
618         // Color key mask: if any of the components are outside the range
619         // then they should be painted.
620         alphaBuf = new Uint8ClampedArray(width * height);
621         const numComps = this.numComps;
622         for (i = 0, ii = width * height; i < ii; ++i) {
623           let opacity = 0;
624           const imageOffset = i * numComps;
625           for (j = 0; j < numComps; ++j) {
626             const color = image[imageOffset + j];
627             const maskOffset = j * 2;
628             if (color < mask[maskOffset] || color > mask[maskOffset + 1]) {
629               opacity = 255;
630               break;
631             }
632           }
633           alphaBuf[i] = opacity;
634         }
635       } else {
636         throw new FormatError("Unknown mask format.");
637       }
638     }
639 
640     if (alphaBuf) {
641       for (i = 0, j = 3, ii = width * actualHeight; i < ii; ++i, j += 4) {
642         rgbaBuf[j] = alphaBuf[i];
643       }
644     } else {
645       // No mask.
646       for (i = 0, j = 3, ii = width * actualHeight; i < ii; ++i, j += 4) {
647         rgbaBuf[j] = 255;
648       }
649     }
650   }
651 
652   undoPreblend(buffer, width, height) {
653     if (typeof PDFJSDev === "undefined" || PDFJSDev.test("TESTING")) {
654       assert(
655         buffer instanceof Uint8ClampedArray,
656         'PDFImage.undoPreblend: Unsupported "buffer" type.'
657       );
658     }
659     const matte = this.smask?.matte;
660     if (!matte) {
661       return;
662     }
663     const matteRgb = this.colorSpace.getRgb(matte, 0);
664     const matteR = matteRgb[0];
665     const matteG = matteRgb[1];
666     const matteB = matteRgb[2];
667     const length = width * height * 4;
668     for (let i = 0; i < length; i += 4) {
669       const alpha = buffer[i + 3];
670       if (alpha === 0) {
671         // according formula we have to get Infinity in all components
672         // making it white (typical paper color) should be okay
673         buffer[i] = 255;
674         buffer[i + 1] = 255;
675         buffer[i + 2] = 255;
676         continue;
677       }
678       const k = 255 / alpha;
679       buffer[i] = (buffer[i] - matteR) * k + matteR;
680       buffer[i + 1] = (buffer[i + 1] - matteG) * k + matteG;
681       buffer[i + 2] = (buffer[i + 2] - matteB) * k + matteB;
682     }
683   }
684 
685   async createImageData(forceRGBA = false, isOffscreenCanvasSupported = false) {
686     const drawWidth = this.drawWidth;
687     const drawHeight = this.drawHeight;
688     const imgData = {
689       width: drawWidth,
690       height: drawHeight,
691       interpolate: this.interpolate,
692       kind: 0,
693       data: null,
694       // Other fields are filled in below.
695     };
696 
697     const numComps = this.numComps;
698     const originalWidth = this.width;
699     const originalHeight = this.height;
700     const bpc = this.bpc;
701 
702     // Rows start at byte boundary.
703     const rowBytes = (originalWidth * numComps * bpc + 7) >> 3;
704     const mustBeResized =
705       isOffscreenCanvasSupported &&
706       ImageResizer.needsToBeResized(drawWidth, drawHeight);
707 
708     if (!this.smask && !this.mask && this.colorSpace.name === "DeviceRGBA") {
709       imgData.kind = ImageKind.RGBA_32BPP;
710       const imgArray = (imgData.data = await this.getImageBytes(
711         originalHeight * originalWidth * 4,
712         {}
713       ));
714 
715       if (isOffscreenCanvasSupported) {
716         if (!mustBeResized) {
717           return this.createBitmap(
718             ImageKind.RGBA_32BPP,
719             drawWidth,
720             drawHeight,
721             imgArray
722           );
723         }
724         return ImageResizer.createImage(imgData, false);
725       }
726 
727       return imgData;
728     }
729 
730     if (!forceRGBA) {
731       // If it is a 1-bit-per-pixel grayscale (i.e. black-and-white) image
732       // without any complications, we pass a same-sized copy to the main
733       // thread rather than expanding by 32x to RGBA form. This saves *lots*
734       // of memory for many scanned documents. It's also much faster.
735       //
736       // Similarly, if it is a 24-bit-per pixel RGB image without any
737       // complications, we avoid expanding by 1.333x to RGBA form.
738       let kind;
739       if (this.colorSpace.name === "DeviceGray" && bpc === 1) {
740         kind = ImageKind.GRAYSCALE_1BPP;
741       } else if (
742         this.colorSpace.name === "DeviceRGB" &&
743         bpc === 8 &&
744         !this.needsDecode
745       ) {
746         kind = ImageKind.RGB_24BPP;
747       }
748       if (
749         kind &&
750         !this.smask &&
751         !this.mask &&
752         drawWidth === originalWidth &&
753         drawHeight === originalHeight
754       ) {
755         const data = await this.getImageBytes(originalHeight * rowBytes, {});
756         if (isOffscreenCanvasSupported) {
757           if (mustBeResized) {
758             return ImageResizer.createImage(
759               {
760                 data,
761                 kind,
762                 width: drawWidth,
763                 height: drawHeight,
764                 interpolate: this.interpolate,
765               },
766               this.needsDecode
767             );
768           }
769           return this.createBitmap(kind, originalWidth, originalHeight, data);
770         }
771         imgData.kind = kind;
772         imgData.data = data;
773 
774         if (this.needsDecode) {
775           // Invert the buffer (which must be grayscale if we reached here).
776           assert(
777             kind === ImageKind.GRAYSCALE_1BPP,
778             "PDFImage.createImageData: The image must be grayscale."
779           );
780           const buffer = imgData.data;
781           for (let i = 0, ii = buffer.length; i < ii; i++) {
782             buffer[i] ^= 0xff;
783           }
784         }
785         return imgData;
786       }
787       if (
788         this.image instanceof JpegStream &&
789         !this.smask &&
790         !this.mask &&
791         !this.needsDecode
792       ) {
793         let imageLength = originalHeight * rowBytes;
794         if (isOffscreenCanvasSupported && !mustBeResized) {
795           let isHandled = false;
796           switch (this.colorSpace.name) {
797             case "DeviceGray":
798               // Avoid truncating the image, since `JpegImage.getData`
799               // will expand the image data when `forceRGB === true`.
800               imageLength *= 4;
801               isHandled = true;
802               break;
803             case "DeviceRGB":
804               imageLength = (imageLength / 3) * 4;
805               isHandled = true;
806               break;
807             case "DeviceCMYK":
808               isHandled = true;
809               break;
810           }
811 
812           if (isHandled) {
813             const rgba = await this.getImageBytes(imageLength, {
814               drawWidth,
815               drawHeight,
816               forceRGBA: true,
817             });
818             return this.createBitmap(
819               ImageKind.RGBA_32BPP,
820               drawWidth,
821               drawHeight,
822               rgba
823             );
824           }
825         } else {
826           switch (this.colorSpace.name) {
827             case "DeviceGray":
828               imageLength *= 3;
829             /* falls through */
830             case "DeviceRGB":
831             case "DeviceCMYK":
832               imgData.kind = ImageKind.RGB_24BPP;
833               imgData.data = await this.getImageBytes(imageLength, {
834                 drawWidth,
835                 drawHeight,
836                 forceRGB: true,
837               });
838               if (mustBeResized) {
839                 // The image is too big so we resize it.
840                 return ImageResizer.createImage(imgData);
841               }
842               return imgData;
843           }
844         }
845       }
846     }
847 
848     const imgArray = await this.getImageBytes(originalHeight * rowBytes, {
849       internal: true,
850     });
851     // imgArray can be incomplete (e.g. after CCITT fax encoding).
852     const actualHeight =
853       0 | (((imgArray.length / rowBytes) * drawHeight) / originalHeight);
854 
855     const comps = this.getComponents(imgArray);
856 
857     // If opacity data is present, use RGBA_32BPP form. Otherwise, use the
858     // more compact RGB_24BPP form if allowable.
859     let alpha01, maybeUndoPreblend;
860 
861     let canvas, ctx, canvasImgData, data;
862     if (isOffscreenCanvasSupported && !mustBeResized) {
863       canvas = new OffscreenCanvas(drawWidth, drawHeight);
864       ctx = canvas.getContext("2d");
865       canvasImgData = ctx.createImageData(drawWidth, drawHeight);
866       data = canvasImgData.data;
867     }
868 
869     imgData.kind = ImageKind.RGBA_32BPP;
870 
871     if (!forceRGBA && !this.smask && !this.mask) {
872       if (!isOffscreenCanvasSupported || mustBeResized) {
873         imgData.kind = ImageKind.RGB_24BPP;
874         data = new Uint8ClampedArray(drawWidth * drawHeight * 3);
875         alpha01 = 0;
876       } else {
877         const arr = new Uint32Array(data.buffer);
878         arr.fill(FeatureTest.isLittleEndian ? 0xff000000 : 0x000000ff);
879         alpha01 = 1;
880       }
881       maybeUndoPreblend = false;
882     } else {
883       if (!isOffscreenCanvasSupported || mustBeResized) {
884         data = new Uint8ClampedArray(drawWidth * drawHeight * 4);
885       }
886 
887       alpha01 = 1;
888       maybeUndoPreblend = true;
889 
890       // Color key masking (opacity) must be performed before decoding.
891       await this.fillOpacity(data, drawWidth, drawHeight, actualHeight, comps);
892     }
893 
894     if (this.needsDecode) {
895       this.decodeBuffer(comps);
896     }
897     this.colorSpace.fillRgb(
898       data,
899       originalWidth,
900       originalHeight,
901       drawWidth,
902       drawHeight,
903       actualHeight,
904       bpc,
905       comps,
906       alpha01
907     );
908     if (maybeUndoPreblend) {
909       this.undoPreblend(data, drawWidth, actualHeight);
910     }
911 
912     if (isOffscreenCanvasSupported && !mustBeResized) {
913       ctx.putImageData(canvasImgData, 0, 0);
914       const bitmap = canvas.transferToImageBitmap();
915 
916       return {
917         data: null,
918         width: drawWidth,
919         height: drawHeight,
920         bitmap,
921         interpolate: this.interpolate,
922       };
923     }
924 
925     imgData.data = data;
926     if (mustBeResized) {
927       return ImageResizer.createImage(imgData);
928     }
929     return imgData;
930   }
931 
932   async fillGrayBuffer(buffer) {
933     if (typeof PDFJSDev === "undefined" || PDFJSDev.test("TESTING")) {
934       assert(
935         buffer instanceof Uint8ClampedArray,
936         'PDFImage.fillGrayBuffer: Unsupported "buffer" type.'
937       );
938     }
939     const numComps = this.numComps;
940     if (numComps !== 1) {
941       throw new FormatError(
942         `Reading gray scale from a color image: ${numComps}`
943       );
944     }
945 
946     const width = this.width;
947     const height = this.height;
948     const bpc = this.bpc;
949 
950     // rows start at byte boundary
951     const rowBytes = (width * numComps * bpc + 7) >> 3;
952     const imgArray = await this.getImageBytes(height * rowBytes, {
953       internal: true,
954     });
955 
956     const comps = this.getComponents(imgArray);
957     let i, length;
958 
959     if (bpc === 1) {
960       // inline decoding (= inversion) for 1 bpc images
961       length = width * height;
962       if (this.needsDecode) {
963         // invert and scale to {0, 255}
964         for (i = 0; i < length; ++i) {
965           buffer[i] = (comps[i] - 1) & 255;
966         }
967       } else {
968         // scale to {0, 255}
969         for (i = 0; i < length; ++i) {
970           buffer[i] = -comps[i] & 255;
971         }
972       }
973       return;
974     }
975 
976     if (this.needsDecode) {
977       this.decodeBuffer(comps);
978     }
979     length = width * height;
980     // we aren't using a colorspace so we need to scale the value
981     const scale = 255 / ((1 << bpc) - 1);
982     for (i = 0; i < length; ++i) {
983       buffer[i] = scale * comps[i];
984     }
985   }
986 
987   createBitmap(kind, width, height, src) {
988     const canvas = new OffscreenCanvas(width, height);
989     const ctx = canvas.getContext("2d");
990     let imgData;
991     if (kind === ImageKind.RGBA_32BPP) {
992       imgData = new ImageData(src, width, height);
993     } else {
994       imgData = ctx.createImageData(width, height);
995       convertToRGBA({
996         kind,
997         src,
998         dest: new Uint32Array(imgData.data.buffer),
999         width,
1000         height,
1001         inverseDecode: this.needsDecode,
1002       });
1003     }
1004     ctx.putImageData(imgData, 0, 0);
1005     const bitmap = canvas.transferToImageBitmap();
1006 
1007     return {
1008       data: null,
1009       width,
1010       height,
1011       bitmap,
1012       interpolate: this.interpolate,
1013     };
1014   }
1015 
1016   async getImageBytes(
1017     length,
1018     {
1019       drawWidth,
1020       drawHeight,
1021       forceRGBA = false,
1022       forceRGB = false,
1023       internal = false,
1024     }
1025   ) {
1026     this.image.reset();
1027     this.image.drawWidth = drawWidth || this.width;
1028     this.image.drawHeight = drawHeight || this.height;
1029     this.image.forceRGBA = !!forceRGBA;
1030     this.image.forceRGB = !!forceRGB;
1031     const imageBytes = await this.image.getImageData(
1032       length,
1033       this.jpxDecoderOptions
1034     );
1035 
1036     // If imageBytes came from a DecodeStream, we're safe to transfer it
1037     // (and thus detach its underlying buffer) because it will constitute
1038     // the entire DecodeStream's data.  But if it came from a Stream, we
1039     // need to copy it because it'll only be a portion of the Stream's
1040     // data, and the rest will be read later on.
1041     if (internal || this.image instanceof DecodeStream) {
1042       return imageBytes;
1043     }
1044     assert(
1045       imageBytes instanceof Uint8Array,
1046       'PDFImage.getImageBytes: Unsupported "imageBytes" type.'
1047     );
1048     return new Uint8Array(imageBytes);
1049   }
1050 }
1051 
1052 export { PDFImage };
File:
src/core/jpeg_stream.js
1 /* Copyright 2012 Mozilla Foundation
2  *
3  * Licensed under the Apache License, Version 2.0 (the "License");
4  * you may not use this file except in compliance with the License.
5  * You may obtain a copy of the License at
6  *
7  *     http://www.apache.org/licenses/LICENSE-2.0
8  *
9  * Unless required by applicable law or agreed to in writing, software
10  * distributed under the License is distributed on an "AS IS" BASIS,
11  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12  * See the License for the specific language governing permissions and
13  * limitations under the License.
14  */
15 
16 import { DecodeStream } from "./decode_stream.js";
17 import { Dict } from "./primitives.js";
18 import { JpegImage } from "./jpg.js";
19 import { shadow } from "../shared/util.js";
20 
21 /**
22  * For JPEG's we use a library to decode these images and the stream behaves
23  * like all the other DecodeStreams.
24  */
25 class JpegStream extends DecodeStream {
26   constructor(stream, maybeLength, params) {
27     super(maybeLength);
28 
29     this.stream = stream;
30     this.dict = stream.dict;
31     this.maybeLength = maybeLength;
32     this.params = params;
33   }
34 
35   get bytes() {
36     // If `this.maybeLength` is null, we'll get the entire stream.
37     return shadow(this, "bytes", this.stream.getBytes(this.maybeLength));
38   }
39 
40   ensureBuffer(requested) {
41     // No-op, since `this.readBlock` will always parse the entire image and
42     // directly insert all of its data into `this.buffer`.
43   }
44 
45   readBlock() {
46     this.decodeImage();
47   }
48 
49   decodeImage(bytes) {
50     if (this.eof) {
51       return this.buffer;
52     }
53     bytes ||= this.bytes;
54 
55     // Some images may contain 'junk' before the SOI (start-of-image) marker.
56     // Note: this seems to mainly affect inline images.
57     for (let i = 0, ii = bytes.length - 1; i < ii; i++) {
58       if (bytes[i] === 0xff && bytes[i + 1] === 0xd8) {
59         if (i > 0) {
60           bytes = bytes.subarray(i);
61         }
62         break;
63       }
64     }
65     const jpegOptions = {
66       decodeTransform: undefined,
67       colorTransform: undefined,
68     };
69 
70     // Checking if values need to be transformed before conversion.
71     const decodeArr = this.dict.getArray("D", "Decode");
72     if ((this.forceRGBA || this.forceRGB) && Array.isArray(decodeArr)) {
73       const bitsPerComponent = this.dict.get("BPC", "BitsPerComponent") || 8;
74       const decodeArrLength = decodeArr.length;
75       const transform = new Int32Array(decodeArrLength);
76       let transformNeeded = false;
77       const maxValue = (1 << bitsPerComponent) - 1;
78       for (let i = 0; i < decodeArrLength; i += 2) {
79         transform[i] = ((decodeArr[i + 1] - decodeArr[i]) * 256) | 0;
80         transform[i + 1] = (decodeArr[i] * maxValue) | 0;
81         if (transform[i] !== 256 || transform[i + 1] !== 0) {
82           transformNeeded = true;
83         }
84       }
85       if (transformNeeded) {
86         jpegOptions.decodeTransform = transform;
87       }
88     }
89     // Fetching the 'ColorTransform' entry, if it exists.
90     if (this.params instanceof Dict) {
91       const colorTransform = this.params.get("ColorTransform");
92       if (Number.isInteger(colorTransform)) {
93         jpegOptions.colorTransform = colorTransform;
94       }
95     }
96     const jpegImage = new JpegImage(jpegOptions);
97 
98     jpegImage.parse(bytes);
99     const data = jpegImage.getData({
100       width: this.drawWidth,
101       height: this.drawHeight,
102       forceRGBA: this.forceRGBA,
103       forceRGB: this.forceRGB,
104       isSourcePDF: true,
105     });
106     this.buffer = data;
107     this.bufferLength = data.length;
108     this.eof = true;
109 
110     return this.buffer;
111   }
112 
113   get canAsyncDecodeImageFromBuffer() {
114     return this.stream.isAsync;
115   }
116 }
117 
118 export { JpegStream };
File:
src/core/jpg.js
1 /* Copyright 2014 Mozilla Foundation
2  *
3  * Licensed under the Apache License, Version 2.0 (the 'License');
4  * you may not use this file except in compliance with the License.
5  * You may obtain a copy of the License at
6  *
7  *     http://www.apache.org/licenses/LICENSE-2.0
8  *
9  * Unless required by applicable law or agreed to in writing, software
10  * distributed under the License is distributed on an 'AS IS' BASIS,
11  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12  * See the License for the specific language governing permissions and
13  * limitations under the License.
14  */
15 
16 import { assert, BaseException, warn } from "../shared/util.js";
17 import { grayToRGBA } from "../shared/image_utils.js";
18 import { readUint16 } from "./core_utils.js";
19 
20 class JpegError extends BaseException {
21   constructor(msg) {
22     super(msg, "JpegError");
23   }
24 }
25 
26 class DNLMarkerError extends BaseException {
27   constructor(message, scanLines) {
28     super(message, "DNLMarkerError");
29     this.scanLines = scanLines;
30   }
31 }
32 
33 class EOIMarkerError extends BaseException {
34   constructor(msg) {
35     super(msg, "EOIMarkerError");
36   }
37 }
38 
39 /**
40  * This code was forked from https://github.com/notmasteryet/jpgjs.
41  * The original version was created by GitHub user notmasteryet.
42  *
43  * - The JPEG specification can be found in the ITU CCITT Recommendation T.81
44  *   (www.w3.org/Graphics/JPEG/itu-t81.pdf)
45  * - The JFIF specification can be found in the JPEG File Interchange Format
46  *   (www.w3.org/Graphics/JPEG/jfif3.pdf)
47  * - The Adobe Application-Specific JPEG markers in the
48  *   Supporting the DCT Filters in PostScript Level 2, Technical Note #5116
49  *   (partners.adobe.com/public/developer/en/ps/sdk/5116.DCT_Filter.pdf)
50  */
51 
52 // prettier-ignore
53 const dctZigZag = new Uint8Array([
54    0,
55    1,  8,
56   16,  9,  2,
57    3, 10, 17, 24,
58   32, 25, 18, 11, 4,
59    5, 12, 19, 26, 33, 40,
60   48, 41, 34, 27, 20, 13,  6,
61    7, 14, 21, 28, 35, 42, 49, 56,
62   57, 50, 43, 36, 29, 22, 15,
63   23, 30, 37, 44, 51, 58,
64   59, 52, 45, 38, 31,
65   39, 46, 53, 60,
66   61, 54, 47,
67   55, 62,
68   63
69 ]);
70 
71 const dctCos1 = 4017; // cos(pi/16)
72 const dctSin1 = 799; // sin(pi/16)
73 const dctCos3 = 3406; // cos(3*pi/16)
74 const dctSin3 = 2276; // sin(3*pi/16)
75 const dctCos6 = 1567; // cos(6*pi/16)
76 const dctSin6 = 3784; // sin(6*pi/16)
77 const dctSqrt2 = 5793; // sqrt(2)
78 const dctSqrt1d2 = 2896; // sqrt(2) / 2
79 
80 function buildHuffmanTable(codeLengths, values) {
81   let k = 0,
82     i,
83     j,
84     length = 16;
85   while (length > 0 && !codeLengths[length - 1]) {
86     length--;
87   }
88   const code = [{ children: [], index: 0 }];
89   let p = code[0],
90     q;
91   for (i = 0; i < length; i++) {
92     for (j = 0; j < codeLengths[i]; j++) {
93       p = code.pop();
94       p.children[p.index] = values[k];
95       while (p.index > 0) {
96         p = code.pop();
97       }
98       p.index++;
99       code.push(p);
100       while (code.length <= i) {
101         code.push((q = { children: [], index: 0 }));
102         p.children[p.index] = q.children;
103         p = q;
104       }
105       k++;
106     }
107     if (i + 1 < length) {
108       // p here points to last code
109       code.push((q = { children: [], index: 0 }));
110       p.children[p.index] = q.children;
111       p = q;
112     }
113   }
114   return code[0].children;
115 }
116 
117 function getBlockBufferOffset(component, row, col) {
118   return 64 * ((component.blocksPerLine + 1) * row + col);
119 }
120 
121 function decodeScan(
122   data,
123   offset,
124   frame,
125   components,
126   resetInterval,
127   spectralStart,
128   spectralEnd,
129   successivePrev,
130   successive,
131   parseDNLMarker = false
132 ) {
133   const mcusPerLine = frame.mcusPerLine;
134   const progressive = frame.progressive;
135 
136   const startOffset = offset;
137   let bitsData = 0,
138     bitsCount = 0;
139 
140   function readBit() {
141     if (bitsCount > 0) {
142       bitsCount--;
143       return (bitsData >> bitsCount) & 1;
144     }
145     bitsData = data[offset++];
146     if (bitsData === 0xff) {
147       const nextByte = data[offset++];
148       if (nextByte) {
149         if (nextByte === /* DNL = */ 0xdc && parseDNLMarker) {
150           offset += 2; // Skip marker length.
151 
152           const scanLines = readUint16(data, offset);
153           offset += 2;
154           if (scanLines > 0 && scanLines !== frame.scanLines) {
155             throw new DNLMarkerError(
156               "Found DNL marker (0xFFDC) while parsing scan data",
157               scanLines
158             );
159           }
160         } else if (nextByte === /* EOI = */ 0xd9) {
161           if (parseDNLMarker) {
162             // NOTE: only 8-bit JPEG images are supported in this decoder.
163             const maybeScanLines = blockRow * (frame.precision === 8 ? 8 : 0);
164             // Heuristic to attempt to handle corrupt JPEG images with too
165             // large `scanLines` parameter, by falling back to the currently
166             // parsed number of scanLines when it's at least (approximately)
167             // one "half" order of magnitude smaller than expected (fixes
168             // issue10880.pdf, issue10989.pdf, issue15492.pdf).
169             if (
170               maybeScanLines > 0 &&
171               Math.round(frame.scanLines / maybeScanLines) >= 5
172             ) {
173               throw new DNLMarkerError(
174                 "Found EOI marker (0xFFD9) while parsing scan data, " +
175                   "possibly caused by incorrect `scanLines` parameter",
176                 maybeScanLines
177               );
178             }
179           }
180           throw new EOIMarkerError(
181             "Found EOI marker (0xFFD9) while parsing scan data"
182           );
183         }
184         throw new JpegError(
185           `unexpected marker ${((bitsData << 8) | nextByte).toString(16)}`
186         );
187       }
188       // unstuff 0
189     }
190     bitsCount = 7;
191     return bitsData >>> 7;
192   }
193 
194   function decodeHuffman(tree) {
195     let node = tree;
196     while (true) {
197       node = node[readBit()];
198       switch (typeof node) {
199         case "number":
200           return node;
201         case "object":
202           continue;
203       }
204       throw new JpegError("invalid huffman sequence");
205     }
206   }
207 
208   function receive(length) {
209     let n = 0;
210     while (length > 0) {
211       n = (n << 1) | readBit();
212       length--;
213     }
214     return n;
215   }
216 
217   function receiveAndExtend(length) {
218     if (length === 1) {
219       return readBit() === 1 ? 1 : -1;
220     }
221     const n = receive(length);
222     if (n >= 1 << (length - 1)) {
223       return n;
224     }
225     return n + (-1 << length) + 1;
226   }
227 
228   function decodeBaseline(component, blockOffset) {
229     const t = decodeHuffman(component.huffmanTableDC);
230     const diff = t === 0 ? 0 : receiveAndExtend(t);
231     component.blockData[blockOffset] = component.pred += diff;
232     let k = 1;
233     while (k < 64) {
234       const rs = decodeHuffman(component.huffmanTableAC);
235       const s = rs & 15,
236         r = rs >> 4;
237       if (s === 0) {
238         if (r < 15) {
239           break;
240         }
241         k += 16;
242         continue;
243       }
244       k += r;
245       const z = dctZigZag[k];
246       component.blockData[blockOffset + z] = receiveAndExtend(s);
247       k++;
248     }
249   }
250 
251   function decodeDCFirst(component, blockOffset) {
252     const t = decodeHuffman(component.huffmanTableDC);
253     const diff = t === 0 ? 0 : receiveAndExtend(t) << successive;
254     component.blockData[blockOffset] = component.pred += diff;
255   }
256 
257   function decodeDCSuccessive(component, blockOffset) {
258     component.blockData[blockOffset] |= readBit() << successive;
259   }
260 
261   let eobrun = 0;
262   function decodeACFirst(component, blockOffset) {
263     if (eobrun > 0) {
264       eobrun--;
265       return;
266     }
267     let k = spectralStart;
268     const e = spectralEnd;
269     while (k <= e) {
270       const rs = decodeHuffman(component.huffmanTableAC);
271       const s = rs & 15,
272         r = rs >> 4;
273       if (s === 0) {
274         if (r < 15) {
275           eobrun = receive(r) + (1 << r) - 1;
276           break;
277         }
278         k += 16;
279         continue;
280       }
281       k += r;
282       const z = dctZigZag[k];
283       component.blockData[blockOffset + z] =
284         receiveAndExtend(s) * (1 << successive);
285       k++;
286     }
287   }
288 
289   let successiveACState = 0,
290     successiveACNextValue;
291   function decodeACSuccessive(component, blockOffset) {
292     let k = spectralStart;
293     const e = spectralEnd;
294     let r = 0;
295     let s;
296     let rs;
297     while (k <= e) {
298       const offsetZ = blockOffset + dctZigZag[k];
299       const sign = component.blockData[offsetZ] < 0 ? -1 : 1;
300       switch (successiveACState) {
301         case 0: // initial state
302           rs = decodeHuffman(component.huffmanTableAC);
303           s = rs & 15;
304           r = rs >> 4;
305           if (s === 0) {
306             if (r < 15) {
307               eobrun = receive(r) + (1 << r);
308               successiveACState = 4;
309             } else {
310               r = 16;
311               successiveACState = 1;
312             }
313           } else {
314             if (s !== 1) {
315               throw new JpegError("invalid ACn encoding");
316             }
317             successiveACNextValue = receiveAndExtend(s);
318             successiveACState = r ? 2 : 3;
319           }
320           continue;
321         case 1: // skipping r zero items
322         case 2:
323           if (component.blockData[offsetZ]) {
324             component.blockData[offsetZ] += sign * (readBit() << successive);
325           } else {
326             r--;
327             if (r === 0) {
328               successiveACState = successiveACState === 2 ? 3 : 0;
329             }
330           }
331           break;
332         case 3: // set value for a zero item
333           if (component.blockData[offsetZ]) {
334             component.blockData[offsetZ] += sign * (readBit() << successive);
335           } else {
336             component.blockData[offsetZ] = successiveACNextValue << successive;
337             successiveACState = 0;
338           }
339           break;
340         case 4: // eob
341           if (component.blockData[offsetZ]) {
342             component.blockData[offsetZ] += sign * (readBit() << successive);
343           }
344           break;
345       }
346       k++;
347     }
348     if (successiveACState === 4) {
349       eobrun--;
350       if (eobrun === 0) {
351         successiveACState = 0;
352       }
353     }
354   }
355 
356   let blockRow = 0;
357   function decodeMcu(component, decode, mcu, row, col) {
358     const mcuRow = (mcu / mcusPerLine) | 0;
359     const mcuCol = mcu % mcusPerLine;
360     blockRow = mcuRow * component.v + row;
361     const blockCol = mcuCol * component.h + col;
362     const blockOffset = getBlockBufferOffset(component, blockRow, blockCol);
363     decode(component, blockOffset);
364   }
365 
366   function decodeBlock(component, decode, mcu) {
367     blockRow = (mcu / component.blocksPerLine) | 0;
368     const blockCol = mcu % component.blocksPerLine;
369     const blockOffset = getBlockBufferOffset(component, blockRow, blockCol);
370     decode(component, blockOffset);
371   }
372 
373   const componentsLength = components.length;
374   let component, i, j, k, n;
375   let decodeFn;
376   if (progressive) {
377     if (spectralStart === 0) {
378       decodeFn = successivePrev === 0 ? decodeDCFirst : decodeDCSuccessive;
379     } else {
380       decodeFn = successivePrev === 0 ? decodeACFirst : decodeACSuccessive;
381     }
382   } else {
383     decodeFn = decodeBaseline;
384   }
385 
386   let mcu = 0,
387     fileMarker;
388   const mcuExpected =
389     componentsLength === 1
390       ? components[0].blocksPerLine * components[0].blocksPerColumn
391       : mcusPerLine * frame.mcusPerColumn;
392 
393   let h, v;
394   while (mcu <= mcuExpected) {
395     // reset interval stuff
396     const mcuToRead = resetInterval
397       ? Math.min(mcuExpected - mcu, resetInterval)
398       : mcuExpected;
399 
400     // The `mcuToRead === 0` case should only occur when all of the expected
401     // MCU data has been already parsed, i.e. when `mcu === mcuExpected`, but
402     // some corrupt JPEG images contain more data than intended and we thus
403     // want to skip over any extra RSTx markers below (fixes issue11794.pdf).
404     if (mcuToRead > 0) {
405       for (i = 0; i < componentsLength; i++) {
406         components[i].pred = 0;
407       }
408       eobrun = 0;
409 
410       if (componentsLength === 1) {
411         component = components[0];
412         for (n = 0; n < mcuToRead; n++) {
413           decodeBlock(component, decodeFn, mcu);
414           mcu++;
415         }
416       } else {
417         for (n = 0; n < mcuToRead; n++) {
418           for (i = 0; i < componentsLength; i++) {
419             component = components[i];
420             h = component.h;
421             v = component.v;
422             for (j = 0; j < v; j++) {
423               for (k = 0; k < h; k++) {
424                 decodeMcu(component, decodeFn, mcu, j, k);
425               }
426             }
427           }
428           mcu++;
429         }
430       }
431     }
432 
433     // find marker
434     bitsCount = 0;
435     fileMarker = findNextFileMarker(data, offset);
436     if (!fileMarker) {
437       break; // Reached the end of the image data without finding any marker.
438     }
439     if (fileMarker.invalid) {
440       // Some bad images seem to pad Scan blocks with e.g. zero bytes, skip
441       // past those to attempt to find a valid marker (fixes issue4090.pdf).
442       const partialMsg = mcuToRead > 0 ? "unexpected" : "excessive";
443       warn(
444         `decodeScan - ${partialMsg} MCU data, current marker is: ${fileMarker.invalid}`
445       );
446       offset = fileMarker.offset;
447     }
448     if (fileMarker.marker >= 0xffd0 && fileMarker.marker <= 0xffd7) {
449       // RSTx
450       offset += 2;
451     } else {
452       break;
453     }
454   }
455 
456   return offset - startOffset;
457 }
458 
459 // A port of poppler's IDCT method which in turn is taken from:
460 //   Christoph Loeffler, Adriaan Ligtenberg, George S. Moschytz,
461 //   'Practical Fast 1-D DCT Algorithms with 11 Multiplications',
462 //   IEEE Intl. Conf. on Acoustics, Speech & Signal Processing, 1989,
463 //   988-991.
464 function quantizeAndInverse(component, blockBufferOffset, p) {
465   const qt = component.quantizationTable,
466     blockData = component.blockData;
467   let v0, v1, v2, v3, v4, v5, v6, v7;
468   let p0, p1, p2, p3, p4, p5, p6, p7;
469   let t;
470 
471   if (!qt) {
472     throw new JpegError("missing required Quantization Table.");
473   }
474 
475   // inverse DCT on rows
476   for (let row = 0; row < 64; row += 8) {
477     // gather block data
478     p0 = blockData[blockBufferOffset + row];
479     p1 = blockData[blockBufferOffset + row + 1];
480     p2 = blockData[blockBufferOffset + row + 2];
481     p3 = blockData[blockBufferOffset + row + 3];
482     p4 = blockData[blockBufferOffset + row + 4];
483     p5 = blockData[blockBufferOffset + row + 5];
484     p6 = blockData[blockBufferOffset + row + 6];
485     p7 = blockData[blockBufferOffset + row + 7];
486 
487     // dequant p0
488     p0 *= qt[row];
489 
490     // check for all-zero AC coefficients
491     if ((p1 | p2 | p3 | p4 | p5 | p6 | p7) === 0) {
492       t = (dctSqrt2 * p0 + 512) >> 10;
493       p[row] = t;
494       p[row + 1] = t;
495       p[row + 2] = t;
496       p[row + 3] = t;
497       p[row + 4] = t;
498       p[row + 5] = t;
499       p[row + 6] = t;
500       p[row + 7] = t;
501       continue;
502     }
503     // dequant p1 ... p7
504     p1 *= qt[row + 1];
505     p2 *= qt[row + 2];
506     p3 *= qt[row + 3];
507     p4 *= qt[row + 4];
508     p5 *= qt[row + 5];
509     p6 *= qt[row + 6];
510     p7 *= qt[row + 7];
511 
512     // stage 4
513     v0 = (dctSqrt2 * p0 + 128) >> 8;
514     v1 = (dctSqrt2 * p4 + 128) >> 8;
515     v2 = p2;
516     v3 = p6;
517     v4 = (dctSqrt1d2 * (p1 - p7) + 128) >> 8;
518     v7 = (dctSqrt1d2 * (p1 + p7) + 128) >> 8;
519     v5 = p3 << 4;
520     v6 = p5 << 4;
521 
522     // stage 3
523     v0 = (v0 + v1 + 1) >> 1;
524     v1 = v0 - v1;
525     t = (v2 * dctSin6 + v3 * dctCos6 + 128) >> 8;
526     v2 = (v2 * dctCos6 - v3 * dctSin6 + 128) >> 8;
527     v3 = t;
528     v4 = (v4 + v6 + 1) >> 1;
529     v6 = v4 - v6;
530     v7 = (v7 + v5 + 1) >> 1;
531     v5 = v7 - v5;
532 
533     // stage 2
534     v0 = (v0 + v3 + 1) >> 1;
535     v3 = v0 - v3;
536     v1 = (v1 + v2 + 1) >> 1;
537     v2 = v1 - v2;
538     t = (v4 * dctSin3 + v7 * dctCos3 + 2048) >> 12;
539     v4 = (v4 * dctCos3 - v7 * dctSin3 + 2048) >> 12;
540     v7 = t;
541     t = (v5 * dctSin1 + v6 * dctCos1 + 2048) >> 12;
542     v5 = (v5 * dctCos1 - v6 * dctSin1 + 2048) >> 12;
543     v6 = t;
544 
545     // stage 1
546     p[row] = v0 + v7;
547     p[row + 7] = v0 - v7;
548     p[row + 1] = v1 + v6;
549     p[row + 6] = v1 - v6;
550     p[row + 2] = v2 + v5;
551     p[row + 5] = v2 - v5;
552     p[row + 3] = v3 + v4;
553     p[row + 4] = v3 - v4;
554   }
555 
556   // inverse DCT on columns
557   for (let col = 0; col < 8; ++col) {
558     p0 = p[col];
559     p1 = p[col + 8];
560     p2 = p[col + 16];
561     p3 = p[col + 24];
562     p4 = p[col + 32];
563     p5 = p[col + 40];
564     p6 = p[col + 48];
565     p7 = p[col + 56];
566 
567     // check for all-zero AC coefficients
568     if ((p1 | p2 | p3 | p4 | p5 | p6 | p7) === 0) {
569       t = (dctSqrt2 * p0 + 8192) >> 14;
570       // Convert to 8-bit.
571       if (t < -2040) {
572         t = 0;
573       } else if (t >= 2024) {
574         t = 255;
575       } else {
576         t = (t + 2056) >> 4;
577       }
578       blockData[blockBufferOffset + col] = t;
579       blockData[blockBufferOffset + col + 8] = t;
580       blockData[blockBufferOffset + col + 16] = t;
581       blockData[blockBufferOffset + col + 24] = t;
582       blockData[blockBufferOffset + col + 32] = t;
583       blockData[blockBufferOffset + col + 40] = t;
584       blockData[blockBufferOffset + col + 48] = t;
585       blockData[blockBufferOffset + col + 56] = t;
586       continue;
587     }
588 
589     // stage 4
590     v0 = (dctSqrt2 * p0 + 2048) >> 12;
591     v1 = (dctSqrt2 * p4 + 2048) >> 12;
592     v2 = p2;
593     v3 = p6;
594     v4 = (dctSqrt1d2 * (p1 - p7) + 2048) >> 12;
595     v7 = (dctSqrt1d2 * (p1 + p7) + 2048) >> 12;
596     v5 = p3;
597     v6 = p5;
598 
599     // stage 3
600     // Shift v0 by 128.5 << 5 here, so we don't need to shift p0...p7 when
601     // converting to UInt8 range later.
602     v0 = ((v0 + v1 + 1) >> 1) + 4112;
603     v1 = v0 - v1;
604     t = (v2 * dctSin6 + v3 * dctCos6 + 2048) >> 12;
605     v2 = (v2 * dctCos6 - v3 * dctSin6 + 2048) >> 12;
606     v3 = t;
607     v4 = (v4 + v6 + 1) >> 1;
608     v6 = v4 - v6;
609     v7 = (v7 + v5 + 1) >> 1;
610     v5 = v7 - v5;
611 
612     // stage 2
613     v0 = (v0 + v3 + 1) >> 1;
614     v3 = v0 - v3;
615     v1 = (v1 + v2 + 1) >> 1;
616     v2 = v1 - v2;
617     t = (v4 * dctSin3 + v7 * dctCos3 + 2048) >> 12;
618     v4 = (v4 * dctCos3 - v7 * dctSin3 + 2048) >> 12;
619     v7 = t;
620     t = (v5 * dctSin1 + v6 * dctCos1 + 2048) >> 12;
621     v5 = (v5 * dctCos1 - v6 * dctSin1 + 2048) >> 12;
622     v6 = t;
623 
624     // stage 1
625     p0 = v0 + v7;
626     p7 = v0 - v7;
627     p1 = v1 + v6;
628     p6 = v1 - v6;
629     p2 = v2 + v5;
630     p5 = v2 - v5;
631     p3 = v3 + v4;
632     p4 = v3 - v4;
633 
634     // Convert to 8-bit integers.
635     if (p0 < 16) {
636       p0 = 0;
637     } else if (p0 >= 4080) {
638       p0 = 255;
639     } else {
640       p0 >>= 4;
641     }
642     if (p1 < 16) {
643       p1 = 0;
644     } else if (p1 >= 4080) {
645       p1 = 255;
646     } else {
647       p1 >>= 4;
648     }
649     if (p2 < 16) {
650       p2 = 0;
651     } else if (p2 >= 4080) {
652       p2 = 255;
653     } else {
654       p2 >>= 4;
655     }
656     if (p3 < 16) {
657       p3 = 0;
658     } else if (p3 >= 4080) {
659       p3 = 255;
660     } else {
661       p3 >>= 4;
662     }
663     if (p4 < 16) {
664       p4 = 0;
665     } else if (p4 >= 4080) {
666       p4 = 255;
667     } else {
668       p4 >>= 4;
669     }
670     if (p5 < 16) {
671       p5 = 0;
672     } else if (p5 >= 4080) {
673       p5 = 255;
674     } else {
675       p5 >>= 4;
676     }
677     if (p6 < 16) {
678       p6 = 0;
679     } else if (p6 >= 4080) {
680       p6 = 255;
681     } else {
682       p6 >>= 4;
683     }
684     if (p7 < 16) {
685       p7 = 0;
686     } else if (p7 >= 4080) {
687       p7 = 255;
688     } else {
689       p7 >>= 4;
690     }
691 
692     // store block data
693     blockData[blockBufferOffset + col] = p0;
694     blockData[blockBufferOffset + col + 8] = p1;
695     blockData[blockBufferOffset + col + 16] = p2;
696     blockData[blockBufferOffset + col + 24] = p3;
697     blockData[blockBufferOffset + col + 32] = p4;
698     blockData[blockBufferOffset + col + 40] = p5;
699     blockData[blockBufferOffset + col + 48] = p6;
700     blockData[blockBufferOffset + col + 56] = p7;
701   }
702 }
703 
704 function buildComponentData(frame, component) {
705   const blocksPerLine = component.blocksPerLine;
706   const blocksPerColumn = component.blocksPerColumn;
707   const computationBuffer = new Int16Array(64);
708 
709   for (let blockRow = 0; blockRow < blocksPerColumn; blockRow++) {
710     for (let blockCol = 0; blockCol < blocksPerLine; blockCol++) {
711       const offset = getBlockBufferOffset(component, blockRow, blockCol);
712       quantizeAndInverse(component, offset, computationBuffer);
713     }
714   }
715   return component.blockData;
716 }
717 
718 function findNextFileMarker(data, currentPos, startPos = currentPos) {
719   const maxPos = data.length - 1;
720   let newPos = startPos < currentPos ? startPos : currentPos;
721 
722   if (currentPos >= maxPos) {
723     return null; // Don't attempt to read non-existent data and just return.
724   }
725   const currentMarker = readUint16(data, currentPos);
726   if (currentMarker >= 0xffc0 && currentMarker <= 0xfffe) {
727     return {
728       invalid: null,
729       marker: currentMarker,
730       offset: currentPos,
731     };
732   }
733   let newMarker = readUint16(data, newPos);
734   while (!(newMarker >= 0xffc0 && newMarker <= 0xfffe)) {
735     if (++newPos >= maxPos) {
736       return null; // Don't attempt to read non-existent data and just return.
737     }
738     newMarker = readUint16(data, newPos);
739   }
740   return {
741     invalid: currentMarker.toString(16),
742     marker: newMarker,
743     offset: newPos,
744   };
745 }
746 
747 class JpegImage {
748   constructor({ decodeTransform = null, colorTransform = -1 } = {}) {
749     this._decodeTransform = decodeTransform;
750     this._colorTransform = colorTransform;
751   }
752 
753   parse(data, { dnlScanLines = null } = {}) {
754     function readDataBlock() {
755       const length = readUint16(data, offset);
756       offset += 2;
757       let endOffset = offset + length - 2;
758 
759       const fileMarker = findNextFileMarker(data, endOffset, offset);
760       if (fileMarker?.invalid) {
761         warn(
762           "readDataBlock - incorrect length, current marker is: " +
763             fileMarker.invalid
764         );
765         endOffset = fileMarker.offset;
766       }
767 
768       const array = data.subarray(offset, endOffset);
769       offset += array.length;
770       return array;
771     }
772 
773     function prepareComponents(frame) {
774       const mcusPerLine = Math.ceil(frame.samplesPerLine / 8 / frame.maxH);
775       const mcusPerColumn = Math.ceil(frame.scanLines / 8 / frame.maxV);
776       for (const component of frame.components) {
777         const blocksPerLine = Math.ceil(
778           (Math.ceil(frame.samplesPerLine / 8) * component.h) / frame.maxH
779         );
780         const blocksPerColumn = Math.ceil(
781           (Math.ceil(frame.scanLines / 8) * component.v) / frame.maxV
782         );
783         const blocksPerLineForMcu = mcusPerLine * component.h;
784         const blocksPerColumnForMcu = mcusPerColumn * component.v;
785 
786         const blocksBufferSize =
787           64 * blocksPerColumnForMcu * (blocksPerLineForMcu + 1);
788         component.blockData = new Int16Array(blocksBufferSize);
789         component.blocksPerLine = blocksPerLine;
790         component.blocksPerColumn = blocksPerColumn;
791       }
792       frame.mcusPerLine = mcusPerLine;
793       frame.mcusPerColumn = mcusPerColumn;
794     }
795 
796     let offset = 0;
797     let jfif = null;
798     let adobe = null;
799     let frame, resetInterval;
800     let numSOSMarkers = 0;
801     const quantizationTables = [];
802     const huffmanTablesAC = [],
803       huffmanTablesDC = [];
804 
805     let fileMarker = readUint16(data, offset);
806     offset += 2;
807     if (fileMarker !== /* SOI (Start of Image) = */ 0xffd8) {
808       throw new JpegError("SOI not found");
809     }
810     fileMarker = readUint16(data, offset);
811     offset += 2;
812 
813     markerLoop: while (fileMarker !== /* EOI (End of Image) = */ 0xffd9) {
814       let i, j, l;
815       switch (fileMarker) {
816         case 0xffe0: // APP0 (Application Specific)
817         case 0xffe1: // APP1
818         case 0xffe2: // APP2
819         case 0xffe3: // APP3
820         case 0xffe4: // APP4
821         case 0xffe5: // APP5
822         case 0xffe6: // APP6
823         case 0xffe7: // APP7
824         case 0xffe8: // APP8
825         case 0xffe9: // APP9
826         case 0xffea: // APP10
827         case 0xffeb: // APP11
828         case 0xffec: // APP12
829         case 0xffed: // APP13
830         case 0xffee: // APP14
831         case 0xffef: // APP15
832         case 0xfffe: // COM (Comment)
833           const appData = readDataBlock();
834 
835           if (fileMarker === 0xffe0) {
836             // 'JFIF\x00'
837             if (
838               appData[0] === 0x4a &&
839               appData[1] === 0x46 &&
840               appData[2] === 0x49 &&
841               appData[3] === 0x46 &&
842               appData[4] === 0
843             ) {
844               jfif = {
845                 version: { major: appData[5], minor: appData[6] },
846                 densityUnits: appData[7],
847                 xDensity: (appData[8] << 8) | appData[9],
848                 yDensity: (appData[10] << 8) | appData[11],
849                 thumbWidth: appData[12],
850                 thumbHeight: appData[13],
851                 thumbData: appData.subarray(
852                   14,
853                   14 + 3 * appData[12] * appData[13]
854                 ),
855               };
856             }
857           }
858           // TODO APP1 - Exif
859           if (fileMarker === 0xffee) {
860             // 'Adobe'
861             if (
862               appData[0] === 0x41 &&
863               appData[1] === 0x64 &&
864               appData[2] === 0x6f &&
865               appData[3] === 0x62 &&
866               appData[4] === 0x65
867             ) {
868               adobe = {
869                 version: (appData[5] << 8) | appData[6],
870                 flags0: (appData[7] << 8) | appData[8],
871                 flags1: (appData[9] << 8) | appData[10],
872                 transformCode: appData[11],
873               };
874             }
875           }
876           break;
877 
878         case 0xffdb: // DQT (Define Quantization Tables)
879           const quantizationTablesLength = readUint16(data, offset);
880           offset += 2;
881           const quantizationTablesEnd = quantizationTablesLength + offset - 2;
882           let z;
883           while (offset < quantizationTablesEnd) {
884             const quantizationTableSpec = data[offset++];
885             const tableData = new Uint16Array(64);
886             if (quantizationTableSpec >> 4 === 0) {
887               // 8 bit values
888               for (j = 0; j < 64; j++) {
889                 z = dctZigZag[j];
890                 tableData[z] = data[offset++];
891               }
892             } else if (quantizationTableSpec >> 4 === 1) {
893               // 16 bit values
894               for (j = 0; j < 64; j++) {
895                 z = dctZigZag[j];
896                 tableData[z] = readUint16(data, offset);
897                 offset += 2;
898               }
899             } else {
900               throw new JpegError("DQT - invalid table spec");
901             }
902             quantizationTables[quantizationTableSpec & 15] = tableData;
903           }
904           break;
905 
906         case 0xffc0: // SOF0 (Start of Frame, Baseline DCT)
907         case 0xffc1: // SOF1 (Start of Frame, Extended DCT)
908         case 0xffc2: // SOF2 (Start of Frame, Progressive DCT)
909           if (frame) {
910             throw new JpegError("Only single frame JPEGs supported");
911           }
912           offset += 2; // Skip marker length.
913 
914           frame = {};
915           frame.extended = fileMarker === 0xffc1;
916           frame.progressive = fileMarker === 0xffc2;
917           frame.precision = data[offset++];
918           const sofScanLines = readUint16(data, offset);
919           offset += 2;
920           frame.scanLines = dnlScanLines || sofScanLines;
921           frame.samplesPerLine = readUint16(data, offset);
922           offset += 2;
923           frame.components = [];
924           frame.componentIds = {};
925           const componentsCount = data[offset++];
926           let maxH = 0,
927             maxV = 0;
928           for (i = 0; i < componentsCount; i++) {
929             const componentId = data[offset];
930             const h = data[offset + 1] >> 4;
931             const v = data[offset + 1] & 15;
932             if (maxH < h) {
933               maxH = h;
934             }
935             if (maxV < v) {
936               maxV = v;
937             }
938             const qId = data[offset + 2];
939             l = frame.components.push({
940               h,
941               v,
942               quantizationId: qId,
943               quantizationTable: null, // See comment below.
944             });
945             frame.componentIds[componentId] = l - 1;
946             offset += 3;
947           }
948           frame.maxH = maxH;
949           frame.maxV = maxV;
950           prepareComponents(frame);
951           break;
952 
953         case 0xffc4: // DHT (Define Huffman Tables)
954           const huffmanLength = readUint16(data, offset);
955           offset += 2;
956           for (i = 2; i < huffmanLength; ) {
957             const huffmanTableSpec = data[offset++];
958             const codeLengths = new Uint8Array(16);
959             let codeLengthSum = 0;
960             for (j = 0; j < 16; j++, offset++) {
961               codeLengthSum += codeLengths[j] = data[offset];
962             }
963             const huffmanValues = new Uint8Array(codeLengthSum);
964             for (j = 0; j < codeLengthSum; j++, offset++) {
965               huffmanValues[j] = data[offset];
966             }
967             i += 17 + codeLengthSum;
968 
969             (huffmanTableSpec >> 4 === 0 ? huffmanTablesDC : huffmanTablesAC)[
970               huffmanTableSpec & 15
971             ] = buildHuffmanTable(codeLengths, huffmanValues);
972           }
973           break;
974 
975         case 0xffdd: // DRI (Define Restart Interval)
976           offset += 2; // Skip marker length.
977 
978           resetInterval = readUint16(data, offset);
979           offset += 2;
980           break;
981 
982         case 0xffda: // SOS (Start of Scan)
983           // A DNL marker (0xFFDC), if it exists, is only allowed at the end
984           // of the first scan segment and may only occur once in an image.
985           // Furthermore, to prevent an infinite loop, do *not* attempt to
986           // parse DNL markers during re-parsing of the JPEG scan data.
987           const parseDNLMarker = ++numSOSMarkers === 1 && !dnlScanLines;
988 
989           offset += 2; // Skip marker length.
990 
991           const selectorsCount = data[offset++],
992             components = [];
993           for (i = 0; i < selectorsCount; i++) {
994             const index = data[offset++];
995             const componentIndex = frame.componentIds[index];
996             const component = frame.components[componentIndex];
997             component.index = index;
998             const tableSpec = data[offset++];
999             component.huffmanTableDC = huffmanTablesDC[tableSpec >> 4];
1000             component.huffmanTableAC = huffmanTablesAC[tableSpec & 15];
1001             components.push(component);
1002           }
1003           const spectralStart = data[offset++],
1004             spectralEnd = data[offset++],
1005             successiveApproximation = data[offset++];
1006           try {
1007             const processed = decodeScan(
1008               data,
1009               offset,
1010               frame,
1011               components,
1012               resetInterval,
1013               spectralStart,
1014               spectralEnd,
1015               successiveApproximation >> 4,
1016               successiveApproximation & 15,
1017               parseDNLMarker
1018             );
1019             offset += processed;
1020           } catch (ex) {
1021             if (ex instanceof DNLMarkerError) {
1022               warn(`${ex.message} -- attempting to re-parse the JPEG image.`);
1023               return this.parse(data, { dnlScanLines: ex.scanLines });
1024             } else if (ex instanceof EOIMarkerError) {
1025               warn(`${ex.message} -- ignoring the rest of the image data.`);
1026               break markerLoop;
1027             }
1028             throw ex;
1029           }
1030           break;
1031 
1032         case 0xffdc: // DNL (Define Number of Lines)
1033           // Ignore the marker, since it's being handled in `decodeScan`.
1034           offset += 4;
1035           break;
1036 
1037         case 0xffff: // Fill bytes
1038           if (data[offset] !== 0xff) {
1039             // Avoid skipping a valid marker.
1040             offset--;
1041           }
1042           break;
1043 
1044         default:
1045           // Could be incorrect encoding -- the last 0xFF byte of the previous
1046           // block could have been eaten by the encoder, hence we fallback to
1047           // `startPos = offset - 3` when looking for the next valid marker.
1048           const nextFileMarker = findNextFileMarker(
1049             data,
1050             /* currentPos = */ offset - 2,
1051             /* startPos = */ offset - 3
1052           );
1053           if (nextFileMarker?.invalid) {
1054             warn(
1055               "JpegImage.parse - unexpected data, current marker is: " +
1056                 nextFileMarker.invalid
1057             );
1058             offset = nextFileMarker.offset;
1059             break;
1060           }
1061           if (!nextFileMarker || offset >= data.length - 1) {
1062             warn(
1063               "JpegImage.parse - reached the end of the image data " +
1064                 "without finding an EOI marker (0xFFD9)."
1065             );
1066             break markerLoop;
1067           }
1068           throw new JpegError(
1069             "JpegImage.parse - unknown marker: " + fileMarker.toString(16)
1070           );
1071       }
1072       fileMarker = readUint16(data, offset);
1073       offset += 2;
1074     }
1075 
1076     if (!frame) {
1077       throw new JpegError("JpegImage.parse - no frame data found.");
1078     }
1079     this.width = frame.samplesPerLine;
1080     this.height = frame.scanLines;
1081     this.jfif = jfif;
1082     this.adobe = adobe;
1083     this.components = [];
1084     for (const component of frame.components) {
1085       // Prevent errors when DQT markers are placed after SOF{n} markers,
1086       // by assigning the `quantizationTable` entry after the entire image
1087       // has been parsed (fixes issue7406.pdf).
1088       const quantizationTable = quantizationTables[component.quantizationId];
1089       if (quantizationTable) {
1090         component.quantizationTable = quantizationTable;
1091       }
1092 
1093       this.components.push({
1094         index: component.index,
1095         output: buildComponentData(frame, component),
1096         scaleX: component.h / frame.maxH,
1097         scaleY: component.v / frame.maxV,
1098         blocksPerLine: component.blocksPerLine,
1099         blocksPerColumn: component.blocksPerColumn,
1100       });
1101     }
1102     this.numComponents = this.components.length;
1103     return undefined;
1104   }
1105 
1106   _getLinearizedBlockData(width, height, isSourcePDF = false) {
1107     const scaleX = this.width / width,
1108       scaleY = this.height / height;
1109 
1110     let component, componentScaleX, componentScaleY, blocksPerScanline;
1111     let x, y, i, j, k;
1112     let index;
1113     let offset = 0;
1114     let output;
1115     const numComponents = this.components.length;
1116     const dataLength = width * height * numComponents;
1117     const data = new Uint8ClampedArray(dataLength);
1118     const xScaleBlockOffset = new Uint32Array(width);
1119     const mask3LSB = 0xfffffff8; // used to clear the 3 LSBs
1120     let lastComponentScaleX;
1121 
1122     for (i = 0; i < numComponents; i++) {
1123       component = this.components[i];
1124       componentScaleX = component.scaleX * scaleX;
1125       componentScaleY = component.scaleY * scaleY;
1126       offset = i;
1127       output = component.output;
1128       blocksPerScanline = (component.blocksPerLine + 1) << 3;
1129       // Precalculate the `xScaleBlockOffset`. Since it doesn't depend on the
1130       // component data, that's only necessary when `componentScaleX` changes.
1131       if (componentScaleX !== lastComponentScaleX) {
1132         for (x = 0; x < width; x++) {
1133           j = 0 | (x * componentScaleX);
1134           xScaleBlockOffset[x] = ((j & mask3LSB) << 3) | (j & 7);
1135         }
1136         lastComponentScaleX = componentScaleX;
1137       }
1138       // linearize the blocks of the component
1139       for (y = 0; y < height; y++) {
1140         j = 0 | (y * componentScaleY);
1141         index = (blocksPerScanline * (j & mask3LSB)) | ((j & 7) << 3);
1142         for (x = 0; x < width; x++) {
1143           data[offset] = output[index + xScaleBlockOffset[x]];
1144           offset += numComponents;
1145         }
1146       }
1147     }
1148 
1149     // decodeTransform contains pairs of multiplier (-256..256) and additive
1150     let transform = this._decodeTransform;
1151 
1152     // In PDF files, JPEG images with CMYK colour spaces are usually inverted
1153     // (this can be observed by extracting the raw image data).
1154     // Since the conversion algorithms (see below) were written primarily for
1155     // the PDF use-cases, attempting to use `JpegImage` to parse standalone
1156     // JPEG (CMYK) images may thus result in inverted images (see issue 9513).
1157     //
1158     // Unfortunately it's not (always) possible to tell, from the image data
1159     // alone, if it needs to be inverted. Thus in an attempt to provide better
1160     // out-of-box behaviour when `JpegImage` is used standalone, default to
1161     // inverting JPEG (CMYK) images if and only if the image data does *not*
1162     // come from a PDF file and no `decodeTransform` was passed by the user.
1163     if (!isSourcePDF && numComponents === 4 && !transform) {
1164       transform = new Int32Array([-256, 255, -256, 255, -256, 255, -256, 255]);
1165     }
1166 
1167     if (transform) {
1168       for (i = 0; i < dataLength; ) {
1169         for (j = 0, k = 0; j < numComponents; j++, i++, k += 2) {
1170           data[i] = ((data[i] * transform[k]) >> 8) + transform[k + 1];
1171         }
1172       }
1173     }
1174     return data;
1175   }
1176 
1177   get _isColorConversionNeeded() {
1178     if (this.adobe) {
1179       // The adobe transform marker overrides any previous setting.
1180       return !!this.adobe.transformCode;
1181     }
1182     if (this.numComponents === 3) {
1183       if (this._colorTransform === 0) {
1184         // If the Adobe transform marker is not present and the image
1185         // dictionary has a 'ColorTransform' entry, explicitly set to `0`,
1186         // then the colours should *not* be transformed.
1187         return false;
1188       } else if (
1189         this.components[0].index === /* "R" = */ 0x52 &&
1190         this.components[1].index === /* "G" = */ 0x47 &&
1191         this.components[2].index === /* "B" = */ 0x42
1192       ) {
1193         // If the three components are indexed as RGB in ASCII
1194         // then the colours should *not* be transformed.
1195         return false;
1196       }
1197       return true;
1198     }
1199     // `this.numComponents !== 3`
1200     if (this._colorTransform === 1) {
1201       // If the Adobe transform marker is not present and the image
1202       // dictionary has a 'ColorTransform' entry, explicitly set to `1`,
1203       // then the colours should be transformed.
1204       return true;
1205     }
1206     return false;
1207   }
1208 
1209   _convertYccToRgb(data) {
1210     let Y, Cb, Cr;
1211     for (let i = 0, length = data.length; i < length; i += 3) {
1212       Y = data[i];
1213       Cb = data[i + 1];
1214       Cr = data[i + 2];
1215       data[i] = Y - 179.456 + 1.402 * Cr;
1216       data[i + 1] = Y + 135.459 - 0.344 * Cb - 0.714 * Cr;
1217       data[i + 2] = Y - 226.816 + 1.772 * Cb;
1218     }
1219     return data;
1220   }
1221 
1222   _convertYccToRgba(data, out) {
1223     for (let i = 0, j = 0, length = data.length; i < length; i += 3, j += 4) {
1224       const Y = data[i];
1225       const Cb = data[i + 1];
1226       const Cr = data[i + 2];
1227       out[j] = Y - 179.456 + 1.402 * Cr;
1228       out[j + 1] = Y + 135.459 - 0.344 * Cb - 0.714 * Cr;
1229       out[j + 2] = Y - 226.816 + 1.772 * Cb;
1230       out[j + 3] = 255;
1231     }
1232     return out;
1233   }
1234 
1235   _convertYcckToRgb(data) {
1236     let Y, Cb, Cr, k;
1237     let offset = 0;
1238     for (let i = 0, length = data.length; i < length; i += 4) {
1239       Y = data[i];
1240       Cb = data[i + 1];
1241       Cr = data[i + 2];
1242       k = data[i + 3];
1243 
1244       data[offset++] =
1245         -122.67195406894 +
1246         Cb *
1247           (-6.60635669420364e-5 * Cb +
1248             0.000437130475926232 * Cr -
1249             5.4080610064599e-5 * Y +
1250             0.00048449797120281 * k -
1251             0.154362151871126) +
1252         Cr *
1253           (-0.000957964378445773 * Cr +
1254             0.000817076911346625 * Y -
1255             0.00477271405408747 * k +
1256             1.53380253221734) +
1257         Y *
1258           (0.000961250184130688 * Y -
1259             0.00266257332283933 * k +
1260             0.48357088451265) +
1261         k * (-0.000336197177618394 * k + 0.484791561490776);
1262 
1263       data[offset++] =
1264         107.268039397724 +
1265         Cb *
1266           (2.19927104525741e-5 * Cb -
1267             0.000640992018297945 * Cr +
1268             0.000659397001245577 * Y +
1269             0.000426105652938837 * k -
1270             0.176491792462875) +
1271         Cr *
1272           (-0.000778269941513683 * Cr +
1273             0.00130872261408275 * Y +
1274             0.000770482631801132 * k -
1275             0.151051492775562) +
1276         Y *
1277           (0.00126935368114843 * Y -
1278             0.00265090189010898 * k +
1279             0.25802910206845) +
1280         k * (-0.000318913117588328 * k - 0.213742400323665);
1281 
1282       data[offset++] =
1283         -20.810012546947 +
1284         Cb *
1285           (-0.000570115196973677 * Cb -
1286             2.63409051004589e-5 * Cr +
1287             0.0020741088115012 * Y -
1288             0.00288260236853442 * k +
1289             0.814272968359295) +
1290         Cr *
1291           (-1.53496057440975e-5 * Cr -
1292             0.000132689043961446 * Y +
1293             0.000560833691242812 * k -
1294             0.195152027534049) +
1295         Y *
1296           (0.00174418132927582 * Y -
1297             0.00255243321439347 * k +
1298             0.116935020465145) +
1299         k * (-0.000343531996510555 * k + 0.24165260232407);
1300     }
1301     // Ensure that only the converted RGB data is returned.
1302     return data.subarray(0, offset);
1303   }
1304 
1305   _convertYcckToRgba(data) {
1306     for (let i = 0, length = data.length; i < length; i += 4) {
1307       const Y = data[i];
1308       const Cb = data[i + 1];
1309       const Cr = data[i + 2];
1310       const k = data[i + 3];
1311 
1312       data[i] =
1313         -122.67195406894 +
1314         Cb *
1315           (-6.60635669420364e-5 * Cb +
1316             0.000437130475926232 * Cr -
1317             5.4080610064599e-5 * Y +
1318             0.00048449797120281 * k -
1319             0.154362151871126) +
1320         Cr *
1321           (-0.000957964378445773 * Cr +
1322             0.000817076911346625 * Y -
1323             0.00477271405408747 * k +
1324             1.53380253221734) +
1325         Y *
1326           (0.000961250184130688 * Y -
1327             0.00266257332283933 * k +
1328             0.48357088451265) +
1329         k * (-0.000336197177618394 * k + 0.484791561490776);
1330 
1331       data[i + 1] =
1332         107.268039397724 +
1333         Cb *
1334           (2.19927104525741e-5 * Cb -
1335             0.000640992018297945 * Cr +
1336             0.000659397001245577 * Y +
1337             0.000426105652938837 * k -
1338             0.176491792462875) +
1339         Cr *
1340           (-0.000778269941513683 * Cr +
1341             0.00130872261408275 * Y +
1342             0.000770482631801132 * k -
1343             0.151051492775562) +
1344         Y *
1345           (0.00126935368114843 * Y -
1346             0.00265090189010898 * k +
1347             0.25802910206845) +
1348         k * (-0.000318913117588328 * k - 0.213742400323665);
1349 
1350       data[i + 2] =
1351         -20.810012546947 +
1352         Cb *
1353           (-0.000570115196973677 * Cb -
1354             2.63409051004589e-5 * Cr +
1355             0.0020741088115012 * Y -
1356             0.00288260236853442 * k +
1357             0.814272968359295) +
1358         Cr *
1359           (-1.53496057440975e-5 * Cr -
1360             0.000132689043961446 * Y +
1361             0.000560833691242812 * k -
1362             0.195152027534049) +
1363         Y *
1364           (0.00174418132927582 * Y -
1365             0.00255243321439347 * k +
1366             0.116935020465145) +
1367         k * (-0.000343531996510555 * k + 0.24165260232407);
1368       data[i + 3] = 255;
1369     }
1370     return data;
1371   }
1372 
1373   _convertYcckToCmyk(data) {
1374     let Y, Cb, Cr;
1375     for (let i = 0, length = data.length; i < length; i += 4) {
1376       Y = data[i];
1377       Cb = data[i + 1];
1378       Cr = data[i + 2];
1379       data[i] = 434.456 - Y - 1.402 * Cr;
1380       data[i + 1] = 119.541 - Y + 0.344 * Cb + 0.714 * Cr;
1381       data[i + 2] = 481.816 - Y - 1.772 * Cb;
1382       // K in data[i + 3] is unchanged
1383     }
1384     return data;
1385   }
1386 
1387   _convertCmykToRgb(data) {
1388     let c, m, y, k;
1389     let offset = 0;
1390     for (let i = 0, length = data.length; i < length; i += 4) {
1391       c = data[i];
1392       m = data[i + 1];
1393       y = data[i + 2];
1394       k = data[i + 3];
1395 
1396       data[offset++] =
1397         255 +
1398         c *
1399           (-0.00006747147073602441 * c +
1400             0.0008379262121013727 * m +
1401             0.0002894718188643294 * y +
1402             0.003264231057537806 * k -
1403             1.1185611867203937) +
1404         m *
1405           (0.000026374107616089405 * m -
1406             0.00008626949158638572 * y -
1407             0.0002748769067499491 * k -
1408             0.02155688794978967) +
1409         y *
1410           (-0.00003878099212869363 * y -
1411             0.0003267808279485286 * k +
1412             0.0686742238595345) -
1413         k * (0.0003361971776183937 * k + 0.7430659151342254);
1414 
1415       data[offset++] =
1416         255 +
1417         c *
1418           (0.00013596372813588848 * c +
1419             0.000924537132573585 * m +
1420             0.00010567359618683593 * y +
1421             0.0004791864687436512 * k -
1422             0.3109689587515875) +
1423         m *
1424           (-0.00023545346108370344 * m +
1425             0.0002702845253534714 * y +
1426             0.0020200308977307156 * k -
1427             0.7488052167015494) +
1428         y *
1429           (0.00006834815998235662 * y +
1430             0.00015168452363460973 * k -
1431             0.09751927774728933) -
1432         k * (0.0003189131175883281 * k + 0.7364883807733168);
1433 
1434       data[offset++] =
1435         255 +
1436         c *
1437           (0.000013598650411385307 * c +
1438             0.00012423956175490851 * m +
1439             0.0004751985097583589 * y -
1440             0.0000036729317476630422 * k -
1441             0.05562186980264034) +
1442         m *
1443           (0.00016141380598724676 * m +
1444             0.0009692239130725186 * y +
1445             0.0007782692450036253 * k -
1446             0.44015232367526463) +
1447         y *
1448           (5.068882914068769e-7 * y +
1449             0.0017778369011375071 * k -
1450             0.7591454649749609) -
1451         k * (0.0003435319965105553 * k + 0.7063770186160144);
1452     }
1453     // Ensure that only the converted RGB data is returned.
1454     return data.subarray(0, offset);
1455   }
1456 
1457   _convertCmykToRgba(data) {
1458     for (let i = 0, length = data.length; i < length; i += 4) {
1459       const c = data[i];
1460       const m = data[i + 1];
1461       const y = data[i + 2];
1462       const k = data[i + 3];
1463 
1464       data[i] =
1465         255 +
1466         c *
1467           (-0.00006747147073602441 * c +
1468             0.0008379262121013727 * m +
1469             0.0002894718188643294 * y +
1470             0.003264231057537806 * k -
1471             1.1185611867203937) +
1472         m *
1473           (0.000026374107616089405 * m -
1474             0.00008626949158638572 * y -
1475             0.0002748769067499491 * k -
1476             0.02155688794978967) +
1477         y *
1478           (-0.00003878099212869363 * y -
1479             0.0003267808279485286 * k +
1480             0.0686742238595345) -
1481         k * (0.0003361971776183937 * k + 0.7430659151342254);
1482 
1483       data[i + 1] =
1484         255 +
1485         c *
1486           (0.00013596372813588848 * c +
1487             0.000924537132573585 * m +
1488             0.00010567359618683593 * y +
1489             0.0004791864687436512 * k -
1490             0.3109689587515875) +
1491         m *
1492           (-0.00023545346108370344 * m +
1493             0.0002702845253534714 * y +
1494             0.0020200308977307156 * k -
1495             0.7488052167015494) +
1496         y *
1497           (0.00006834815998235662 * y +
1498             0.00015168452363460973 * k -
1499             0.09751927774728933) -
1500         k * (0.0003189131175883281 * k + 0.7364883807733168);
1501 
1502       data[i + 2] =
1503         255 +
1504         c *
1505           (0.000013598650411385307 * c +
1506             0.00012423956175490851 * m +
1507             0.0004751985097583589 * y -
1508             0.0000036729317476630422 * k -
1509             0.05562186980264034) +
1510         m *
1511           (0.00016141380598724676 * m +
1512             0.0009692239130725186 * y +
1513             0.0007782692450036253 * k -
1514             0.44015232367526463) +
1515         y *
1516           (5.068882914068769e-7 * y +
1517             0.0017778369011375071 * k -
1518             0.7591454649749609) -
1519         k * (0.0003435319965105553 * k + 0.7063770186160144);
1520       data[i + 3] = 255;
1521     }
1522     return data;
1523   }
1524 
1525   getData({
1526     width,
1527     height,
1528     forceRGBA = false,
1529     forceRGB = false,
1530     isSourcePDF = false,
1531   }) {
1532     if (typeof PDFJSDev === "undefined" || PDFJSDev.test("TESTING")) {
1533       assert(
1534         isSourcePDF === true,
1535         'JpegImage.getData: Unexpected "isSourcePDF" value for PDF files.'
1536       );
1537     }
1538     if (this.numComponents > 4) {
1539       throw new JpegError("Unsupported color mode");
1540     }
1541     // Type of data: Uint8ClampedArray(width * height * numComponents)
1542     const data = this._getLinearizedBlockData(width, height, isSourcePDF);
1543 
1544     if (this.numComponents === 1 && (forceRGBA || forceRGB)) {
1545       const len = data.length * (forceRGBA ? 4 : 3);
1546       const rgbaData = new Uint8ClampedArray(len);
1547       let offset = 0;
1548       if (forceRGBA) {
1549         grayToRGBA(data, new Uint32Array(rgbaData.buffer));
1550       } else {
1551         for (const grayColor of data) {
1552           rgbaData[offset++] = grayColor;
1553           rgbaData[offset++] = grayColor;
1554           rgbaData[offset++] = grayColor;
1555         }
1556       }
1557       return rgbaData;
1558     } else if (this.numComponents === 3 && this._isColorConversionNeeded) {
1559       if (forceRGBA) {
1560         const rgbaData = new Uint8ClampedArray((data.length / 3) * 4);
1561         return this._convertYccToRgba(data, rgbaData);
1562       }
1563       return this._convertYccToRgb(data);
1564     } else if (this.numComponents === 4) {
1565       if (this._isColorConversionNeeded) {
1566         if (forceRGBA) {
1567           return this._convertYcckToRgba(data);
1568         }
1569         if (forceRGB) {
1570           return this._convertYcckToRgb(data);
1571         }
1572         return this._convertYcckToCmyk(data);
1573       } else if (forceRGBA) {
1574         return this._convertCmykToRgba(data);
1575       } else if (forceRGB) {
1576         return this._convertCmykToRgb(data);
1577       }
1578     }
1579     return data;
1580   }
1581 }
1582 
1583 export { JpegError, JpegImage };
File:
src/display/canvas.js
1 /* Copyright 2012 Mozilla Foundation
2  *
3  * Licensed under the Apache License, Version 2.0 (the "License");
4  * you may not use this file except in compliance with the License.
5  * You may obtain a copy of the License at
6  *
7  *     http://www.apache.org/licenses/LICENSE-2.0
8  *
9  * Unless required by applicable law or agreed to in writing, software
10  * distributed under the License is distributed on an "AS IS" BASIS,
11  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12  * See the License for the specific language governing permissions and
13  * limitations under the License.
14  */
15 
16 import {
17   FeatureTest,
18   FONT_IDENTITY_MATRIX,
19   IDENTITY_MATRIX,
20   ImageKind,
21   info,
22   isNodeJS,
23   OPS,
24   shadow,
25   TextRenderingMode,
26   unreachable,
27   Util,
28   warn,
29 } from "../shared/util.js";
30 import {
31   getCurrentTransform,
32   getCurrentTransformInverse,
33   PixelsPerInch,
34 } from "./display_utils.js";
35 import {
36   getShadingPattern,
37   PathType,
38   TilingPattern,
39 } from "./pattern_helper.js";
40 import { convertBlackAndWhiteToRGBA } from "../shared/image_utils.js";
41 
42 // <canvas> contexts store most of the state we need natively.
43 // However, PDF needs a bit more state, which we store here.
44 // Minimal font size that would be used during canvas fillText operations.
45 const MIN_FONT_SIZE = 16;
46 // Maximum font size that would be used during canvas fillText operations.
47 const MAX_FONT_SIZE = 100;
48 
49 // Defines the time the `executeOperatorList`-method is going to be executing
50 // before it stops and schedules a continue of execution.
51 const EXECUTION_TIME = 15; // ms
52 // Defines the number of steps before checking the execution time.
53 const EXECUTION_STEPS = 10;
54 
55 // To disable Type3 compilation, set the value to `-1`.
56 const MAX_SIZE_TO_COMPILE = 1000;
57 
58 const FULL_CHUNK_HEIGHT = 16;
59 
60 /**
61  * Overrides certain methods on a 2d ctx so that when they are called they
62  * will also call the same method on the destCtx. The methods that are
63  * overridden are all the transformation state modifiers, path creation, and
64  * save/restore. We only forward these specific methods because they are the
65  * only state modifiers that we cannot copy over when we switch contexts.
66  *
67  * To remove mirroring call `ctx._removeMirroring()`.
68  *
69  * @param {Object} ctx - The 2d canvas context that will duplicate its calls on
70  *   the destCtx.
71  * @param {Object} destCtx - The 2d canvas context that will receive the
72  *   forwarded calls.
73  */
74 function mirrorContextOperations(ctx, destCtx) {
75   if (ctx._removeMirroring) {
76     throw new Error("Context is already forwarding operations.");
77   }
78   ctx.__originalSave = ctx.save;
79   ctx.__originalRestore = ctx.restore;
80   ctx.__originalRotate = ctx.rotate;
81   ctx.__originalScale = ctx.scale;
82   ctx.__originalTranslate = ctx.translate;
83   ctx.__originalTransform = ctx.transform;
84   ctx.__originalSetTransform = ctx.setTransform;
85   ctx.__originalResetTransform = ctx.resetTransform;
86   ctx.__originalClip = ctx.clip;
87   ctx.__originalMoveTo = ctx.moveTo;
88   ctx.__originalLineTo = ctx.lineTo;
89   ctx.__originalBezierCurveTo = ctx.bezierCurveTo;
90   ctx.__originalRect = ctx.rect;
91   ctx.__originalClosePath = ctx.closePath;
92   ctx.__originalBeginPath = ctx.beginPath;
93 
94   ctx._removeMirroring = () => {
95     ctx.save = ctx.__originalSave;
96     ctx.restore = ctx.__originalRestore;
97     ctx.rotate = ctx.__originalRotate;
98     ctx.scale = ctx.__originalScale;
99     ctx.translate = ctx.__originalTranslate;
100     ctx.transform = ctx.__originalTransform;
101     ctx.setTransform = ctx.__originalSetTransform;
102     ctx.resetTransform = ctx.__originalResetTransform;
103 
104     ctx.clip = ctx.__originalClip;
105     ctx.moveTo = ctx.__originalMoveTo;
106     ctx.lineTo = ctx.__originalLineTo;
107     ctx.bezierCurveTo = ctx.__originalBezierCurveTo;
108     ctx.rect = ctx.__originalRect;
109     ctx.closePath = ctx.__originalClosePath;
110     ctx.beginPath = ctx.__originalBeginPath;
111     delete ctx._removeMirroring;
112   };
113 
114   ctx.save = function ctxSave() {
115     destCtx.save();
116     this.__originalSave();
117   };
118 
119   ctx.restore = function ctxRestore() {
120     destCtx.restore();
121     this.__originalRestore();
122   };
123 
124   ctx.translate = function ctxTranslate(x, y) {
125     destCtx.translate(x, y);
126     this.__originalTranslate(x, y);
127   };
128 
129   ctx.scale = function ctxScale(x, y) {
130     destCtx.scale(x, y);
131     this.__originalScale(x, y);
132   };
133 
134   ctx.transform = function ctxTransform(a, b, c, d, e, f) {
135     destCtx.transform(a, b, c, d, e, f);
136     this.__originalTransform(a, b, c, d, e, f);
137   };
138 
139   ctx.setTransform = function ctxSetTransform(a, b, c, d, e, f) {
140     destCtx.setTransform(a, b, c, d, e, f);
141     this.__originalSetTransform(a, b, c, d, e, f);
142   };
143 
144   ctx.resetTransform = function ctxResetTransform() {
145     destCtx.resetTransform();
146     this.__originalResetTransform();
147   };
148 
149   ctx.rotate = function ctxRotate(angle) {
150     destCtx.rotate(angle);
151     this.__originalRotate(angle);
152   };
153 
154   ctx.clip = function ctxRotate(rule) {
155     destCtx.clip(rule);
156     this.__originalClip(rule);
157   };
158 
159   ctx.moveTo = function (x, y) {
160     destCtx.moveTo(x, y);
161     this.__originalMoveTo(x, y);
162   };
163 
164   ctx.lineTo = function (x, y) {
165     destCtx.lineTo(x, y);
166     this.__originalLineTo(x, y);
167   };
168 
169   ctx.bezierCurveTo = function (cp1x, cp1y, cp2x, cp2y, x, y) {
170     destCtx.bezierCurveTo(cp1x, cp1y, cp2x, cp2y, x, y);
171     this.__originalBezierCurveTo(cp1x, cp1y, cp2x, cp2y, x, y);
172   };
173 
174   ctx.rect = function (x, y, width, height) {
175     destCtx.rect(x, y, width, height);
176     this.__originalRect(x, y, width, height);
177   };
178 
179   ctx.closePath = function () {
180     destCtx.closePath();
181     this.__originalClosePath();
182   };
183 
184   ctx.beginPath = function () {
185     destCtx.beginPath();
186     this.__originalBeginPath();
187   };
188 }
189 
190 class CachedCanvases {
191   constructor(canvasFactory) {
192     this.canvasFactory = canvasFactory;
193     this.cache = Object.create(null);
194   }
195 
196   getCanvas(id, width, height) {
197     let canvasEntry;
198     if (this.cache[id] !== undefined) {
199       canvasEntry = this.cache[id];
200       this.canvasFactory.reset(canvasEntry, width, height);
201     } else {
202       canvasEntry = this.canvasFactory.create(width, height);
203       this.cache[id] = canvasEntry;
204     }
205     return canvasEntry;
206   }
207 
208   delete(id) {
209     delete this.cache[id];
210   }
211 
212   clear() {
213     for (const id in this.cache) {
214       const canvasEntry = this.cache[id];
215       this.canvasFactory.destroy(canvasEntry);
216       delete this.cache[id];
217     }
218   }
219 }
220 
221 function drawImageAtIntegerCoords(
222   ctx,
223   srcImg,
224   srcX,
225   srcY,
226   srcW,
227   srcH,
228   destX,
229   destY,
230   destW,
231   destH
232 ) {
233   const [a, b, c, d, tx, ty] = getCurrentTransform(ctx);
234   if (b === 0 && c === 0) {
235     // top-left corner is at (X, Y) and
236     // bottom-right one is at (X + width, Y + height).
237 
238     // If leftX is 4.321 then it's rounded to 4.
239     // If width is 10.432 then it's rounded to 11 because
240     // rightX = leftX + width = 14.753 which is rounded to 15
241     // so after rounding the total width is 11 (15 - 4).
242     // It's why we can't just floor/ceil uniformly, it just depends
243     // on the values we've.
244 
245     const tlX = destX * a + tx;
246     const rTlX = Math.round(tlX);
247     const tlY = destY * d + ty;
248     const rTlY = Math.round(tlY);
249     const brX = (destX + destW) * a + tx;
250 
251     // Some pdf contains images with 1x1 images so in case of 0-width after
252     // scaling we must fallback on 1 to be sure there is something.
253     const rWidth = Math.abs(Math.round(brX) - rTlX) || 1;
254     const brY = (destY + destH) * d + ty;
255     const rHeight = Math.abs(Math.round(brY) - rTlY) || 1;
256 
257     // We must apply a transformation in order to apply it on the image itself.
258     // For example if a == 1 && d == -1, it means that the image itself is
259     // mirrored w.r.t. the x-axis.
260     ctx.setTransform(Math.sign(a), 0, 0, Math.sign(d), rTlX, rTlY);
261     ctx.drawImage(srcImg, srcX, srcY, srcW, srcH, 0, 0, rWidth, rHeight);
262     ctx.setTransform(a, b, c, d, tx, ty);
263 
264     return [rWidth, rHeight];
265   }
266 
267   if (a === 0 && d === 0) {
268     // This path is taken in issue9462.pdf (page 3).
269     const tlX = destY * c + tx;
270     const rTlX = Math.round(tlX);
271     const tlY = destX * b + ty;
272     const rTlY = Math.round(tlY);
273     const brX = (destY + destH) * c + tx;
274     const rWidth = Math.abs(Math.round(brX) - rTlX) || 1;
275     const brY = (destX + destW) * b + ty;
276     const rHeight = Math.abs(Math.round(brY) - rTlY) || 1;
277 
278     ctx.setTransform(0, Math.sign(b), Math.sign(c), 0, rTlX, rTlY);
279     ctx.drawImage(srcImg, srcX, srcY, srcW, srcH, 0, 0, rHeight, rWidth);
280     ctx.setTransform(a, b, c, d, tx, ty);
281 
282     return [rHeight, rWidth];
283   }
284 
285   // Not a scale matrix so let the render handle the case without rounding.
286   ctx.drawImage(srcImg, srcX, srcY, srcW, srcH, destX, destY, destW, destH);
287 
288   const scaleX = Math.hypot(a, b);
289   const scaleY = Math.hypot(c, d);
290   return [scaleX * destW, scaleY * destH];
291 }
292 
293 function compileType3Glyph(imgData) {
294   const { width, height } = imgData;
295   if (width > MAX_SIZE_TO_COMPILE || height > MAX_SIZE_TO_COMPILE) {
296     return null;
297   }
298 
299   const POINT_TO_PROCESS_LIMIT = 1000;
300   const POINT_TYPES = new Uint8Array([
301     0, 2, 4, 0, 1, 0, 5, 4, 8, 10, 0, 8, 0, 2, 1, 0,
302   ]);
303 
304   const width1 = width + 1;
305   let points = new Uint8Array(width1 * (height + 1));
306   let i, j, j0;
307 
308   // decodes bit-packed mask data
309   const lineSize = (width + 7) & ~7;
310   let data = new Uint8Array(lineSize * height),
311     pos = 0;
312   for (const elem of imgData.data) {
313     let mask = 128;
314     while (mask > 0) {
315       data[pos++] = elem & mask ? 0 : 255;
316       mask >>= 1;
317     }
318   }
319 
320   // finding interesting points: every point is located between mask pixels,
321   // so there will be points of the (width + 1)x(height + 1) grid. Every point
322   // will have flags assigned based on neighboring mask pixels:
323   //   4 | 8
324   //   --P--
325   //   2 | 1
326   // We are interested only in points with the flags:
327   //   - outside corners: 1, 2, 4, 8;
328   //   - inside corners: 7, 11, 13, 14;
329   //   - and, intersections: 5, 10.
330   let count = 0;
331   pos = 0;
332   if (data[pos] !== 0) {
333     points[0] = 1;
334     ++count;
335   }
336   for (j = 1; j < width; j++) {
337     if (data[pos] !== data[pos + 1]) {
338       points[j] = data[pos] ? 2 : 1;
339       ++count;
340     }
341     pos++;
342   }
343   if (data[pos] !== 0) {
344     points[j] = 2;
345     ++count;
346   }
347   for (i = 1; i < height; i++) {
348     pos = i * lineSize;
349     j0 = i * width1;
350     if (data[pos - lineSize] !== data[pos]) {
351       points[j0] = data[pos] ? 1 : 8;
352       ++count;
353     }
354     // 'sum' is the position of the current pixel configuration in the 'TYPES'
355     // array (in order 8-1-2-4, so we can use '>>2' to shift the column).
356     let sum = (data[pos] ? 4 : 0) + (data[pos - lineSize] ? 8 : 0);
357     for (j = 1; j < width; j++) {
358       sum =
359         (sum >> 2) +
360         (data[pos + 1] ? 4 : 0) +
361         (data[pos - lineSize + 1] ? 8 : 0);
362       if (POINT_TYPES[sum]) {
363         points[j0 + j] = POINT_TYPES[sum];
364         ++count;
365       }
366       pos++;
367     }
368     if (data[pos - lineSize] !== data[pos]) {
369       points[j0 + j] = data[pos] ? 2 : 4;
370       ++count;
371     }
372 
373     if (count > POINT_TO_PROCESS_LIMIT) {
374       return null;
375     }
376   }
377 
378   pos = lineSize * (height - 1);
379   j0 = i * width1;
380   if (data[pos] !== 0) {
381     points[j0] = 8;
382     ++count;
383   }
384   for (j = 1; j < width; j++) {
385     if (data[pos] !== data[pos + 1]) {
386       points[j0 + j] = data[pos] ? 4 : 8;
387       ++count;
388     }
389     pos++;
390   }
391   if (data[pos] !== 0) {
392     points[j0 + j] = 4;
393     ++count;
394   }
395   if (count > POINT_TO_PROCESS_LIMIT) {
396     return null;
397   }
398 
399   // building outlines
400   const steps = new Int32Array([0, width1, -1, 0, -width1, 0, 0, 0, 1]);
401   const path = new Path2D();
402 
403   for (i = 0; count && i <= height; i++) {
404     let p = i * width1;
405     const end = p + width;
406     while (p < end && !points[p]) {
407       p++;
408     }
409     if (p === end) {
410       continue;
411     }
412     path.moveTo(p % width1, i);
413 
414     const p0 = p;
415     let type = points[p];
416     do {
417       const step = steps[type];
418       do {
419         p += step;
420       } while (!points[p]);
421 
422       const pp = points[p];
423       if (pp !== 5 && pp !== 10) {
424         // set new direction
425         type = pp;
426         // delete mark
427         points[p] = 0;
428       } else {
429         // type is 5 or 10, ie, a crossing
430         // set new direction
431         type = pp & ((0x33 * type) >> 4);
432         // set new type for "future hit"
433         points[p] &= (type >> 2) | (type << 2);
434       }
435       path.lineTo(p % width1, (p / width1) | 0);
436 
437       if (!points[p]) {
438         --count;
439       }
440     } while (p0 !== p);
441     --i;
442   }
443 
444   // Immediately release the, potentially large, `Uint8Array`s after parsing.
445   data = null;
446   points = null;
447 
448   const drawOutline = function (c) {
449     c.save();
450     // the path shall be painted in [0..1]x[0..1] space
451     c.scale(1 / width, -1 / height);
452     c.translate(0, -height);
453     c.fill(path);
454     c.beginPath();
455     c.restore();
456   };
457 
458   return drawOutline;
459 }
460 
461 class CanvasExtraState {
462   constructor(width, height) {
463     // Are soft masks and alpha values shapes or opacities?
464     this.alphaIsShape = false;
465     this.fontSize = 0;
466     this.fontSizeScale = 1;
467     this.textMatrix = IDENTITY_MATRIX;
468     this.textMatrixScale = 1;
469     this.fontMatrix = FONT_IDENTITY_MATRIX;
470     this.leading = 0;
471     // Current point (in user coordinates)
472     this.x = 0;
473     this.y = 0;
474     // Start of text line (in text coordinates)
475     this.lineX = 0;
476     this.lineY = 0;
477     // Character and word spacing
478     this.charSpacing = 0;
479     this.wordSpacing = 0;
480     this.textHScale = 1;
481     this.textRenderingMode = TextRenderingMode.FILL;
482     this.textRise = 0;
483     // Default fore and background colors
484     this.fillColor = "#000000";
485     this.strokeColor = "#000000";
486     this.patternFill = false;
487     // Note: fill alpha applies to all non-stroking operations
488     this.fillAlpha = 1;
489     this.strokeAlpha = 1;
490     this.lineWidth = 1;
491     this.activeSMask = null;
492     this.transferMaps = "none";
493 
494     this.startNewPathAndClipBox([0, 0, width, height]);
495   }
496 
497   clone() {
498     const clone = Object.create(this);
499     clone.clipBox = this.clipBox.slice();
500     return clone;
501   }
502 
503   setCurrentPoint(x, y) {
504     this.x = x;
505     this.y = y;
506   }
507 
508   updatePathMinMax(transform, x, y) {
509     [x, y] = Util.applyTransform([x, y], transform);
510     this.minX = Math.min(this.minX, x);
511     this.minY = Math.min(this.minY, y);
512     this.maxX = Math.max(this.maxX, x);
513     this.maxY = Math.max(this.maxY, y);
514   }
515 
516   updateRectMinMax(transform, rect) {
517     const p1 = Util.applyTransform(rect, transform);
518     const p2 = Util.applyTransform(rect.slice(2), transform);
519     const p3 = Util.applyTransform([rect[0], rect[3]], transform);
520     const p4 = Util.applyTransform([rect[2], rect[1]], transform);
521 
522     this.minX = Math.min(this.minX, p1[0], p2[0], p3[0], p4[0]);
523     this.minY = Math.min(this.minY, p1[1], p2[1], p3[1], p4[1]);
524     this.maxX = Math.max(this.maxX, p1[0], p2[0], p3[0], p4[0]);
525     this.maxY = Math.max(this.maxY, p1[1], p2[1], p3[1], p4[1]);
526   }
527 
528   updateScalingPathMinMax(transform, minMax) {
529     Util.scaleMinMax(transform, minMax);
530     this.minX = Math.min(this.minX, minMax[0]);
531     this.minY = Math.min(this.minY, minMax[1]);
532     this.maxX = Math.max(this.maxX, minMax[2]);
533     this.maxY = Math.max(this.maxY, minMax[3]);
534   }
535 
536   updateCurvePathMinMax(transform, x0, y0, x1, y1, x2, y2, x3, y3, minMax) {
537     const box = Util.bezierBoundingBox(x0, y0, x1, y1, x2, y2, x3, y3, minMax);
538     if (minMax) {
539       return;
540     }
541     this.updateRectMinMax(transform, box);
542   }
543 
544   getPathBoundingBox(pathType = PathType.FILL, transform = null) {
545     const box = [this.minX, this.minY, this.maxX, this.maxY];
546     if (pathType === PathType.STROKE) {
547       if (!transform) {
548         unreachable("Stroke bounding box must include transform.");
549       }
550       // Stroked paths can be outside of the path bounding box by 1/2 the line
551       // width.
552       const scale = Util.singularValueDecompose2dScale(transform);
553       const xStrokePad = (scale[0] * this.lineWidth) / 2;
554       const yStrokePad = (scale[1] * this.lineWidth) / 2;
555       box[0] -= xStrokePad;
556       box[1] -= yStrokePad;
557       box[2] += xStrokePad;
558       box[3] += yStrokePad;
559     }
560     return box;
561   }
562 
563   updateClipFromPath() {
564     const intersect = Util.intersect(this.clipBox, this.getPathBoundingBox());
565     this.startNewPathAndClipBox(intersect || [0, 0, 0, 0]);
566   }
567 
568   isEmptyClip() {
569     return this.minX === Infinity;
570   }
571 
572   startNewPathAndClipBox(box) {
573     this.clipBox = box;
574     this.minX = Infinity;
575     this.minY = Infinity;
576     this.maxX = 0;
577     this.maxY = 0;
578   }
579 
580   getClippedPathBoundingBox(pathType = PathType.FILL, transform = null) {
581     return Util.intersect(
582       this.clipBox,
583       this.getPathBoundingBox(pathType, transform)
584     );
585   }
586 }
587 
588 function putBinaryImageData(ctx, imgData) {
589   if (typeof ImageData !== "undefined" && imgData instanceof ImageData) {
590     ctx.putImageData(imgData, 0, 0);
591     return;
592   }
593 
594   // Put the image data to the canvas in chunks, rather than putting the
595   // whole image at once.  This saves JS memory, because the ImageData object
596   // is smaller. It also possibly saves C++ memory within the implementation
597   // of putImageData(). (E.g. in Firefox we make two short-lived copies of
598   // the data passed to putImageData()). |n| shouldn't be too small, however,
599   // because too many putImageData() calls will slow things down.
600   //
601   // Note: as written, if the last chunk is partial, the putImageData() call
602   // will (conceptually) put pixels past the bounds of the canvas.  But
603   // that's ok; any such pixels are ignored.
604 
605   const height = imgData.height,
606     width = imgData.width;
607   const partialChunkHeight = height % FULL_CHUNK_HEIGHT;
608   const fullChunks = (height - partialChunkHeight) / FULL_CHUNK_HEIGHT;
609   const totalChunks = partialChunkHeight === 0 ? fullChunks : fullChunks + 1;
610 
611   const chunkImgData = ctx.createImageData(width, FULL_CHUNK_HEIGHT);
612   let srcPos = 0,
613     destPos;
614   const src = imgData.data;
615   const dest = chunkImgData.data;
616   let i, j, thisChunkHeight, elemsInThisChunk;
617 
618   // There are multiple forms in which the pixel data can be passed, and
619   // imgData.kind tells us which one this is.
620   if (imgData.kind === ImageKind.GRAYSCALE_1BPP) {
621     // Grayscale, 1 bit per pixel (i.e. black-and-white).
622     const srcLength = src.byteLength;
623     const dest32 = new Uint32Array(dest.buffer, 0, dest.byteLength >> 2);
624     const dest32DataLength = dest32.length;
625     const fullSrcDiff = (width + 7) >> 3;
626     const white = 0xffffffff;
627     const black = FeatureTest.isLittleEndian ? 0xff000000 : 0x000000ff;
628 
629     for (i = 0; i < totalChunks; i++) {
630       thisChunkHeight = i < fullChunks ? FULL_CHUNK_HEIGHT : partialChunkHeight;
631       destPos = 0;
632       for (j = 0; j < thisChunkHeight; j++) {
633         const srcDiff = srcLength - srcPos;
634         let k = 0;
635         const kEnd = srcDiff > fullSrcDiff ? width : srcDiff * 8 - 7;
636         const kEndUnrolled = kEnd & ~7;
637         let mask = 0;
638         let srcByte = 0;
639         for (; k < kEndUnrolled; k += 8) {
640           srcByte = src[srcPos++];
641           dest32[destPos++] = srcByte & 128 ? white : black;
642           dest32[destPos++] = srcByte & 64 ? white : black;
643           dest32[destPos++] = srcByte & 32 ? white : black;
644           dest32[destPos++] = srcByte & 16 ? white : black;
645           dest32[destPos++] = srcByte & 8 ? white : black;
646           dest32[destPos++] = srcByte & 4 ? white : black;
647           dest32[destPos++] = srcByte & 2 ? white : black;
648           dest32[destPos++] = srcByte & 1 ? white : black;
649         }
650         for (; k < kEnd; k++) {
651           if (mask === 0) {
652             srcByte = src[srcPos++];
653             mask = 128;
654           }
655 
656           dest32[destPos++] = srcByte & mask ? white : black;
657           mask >>= 1;
658         }
659       }
660       // We ran out of input. Make all remaining pixels transparent.
661       while (destPos < dest32DataLength) {
662         dest32[destPos++] = 0;
663       }
664 
665       ctx.putImageData(chunkImgData, 0, i * FULL_CHUNK_HEIGHT);
666     }
667   } else if (imgData.kind === ImageKind.RGBA_32BPP) {
668     // RGBA, 32-bits per pixel.
669     j = 0;
670     elemsInThisChunk = width * FULL_CHUNK_HEIGHT * 4;
671     for (i = 0; i < fullChunks; i++) {
672       dest.set(src.subarray(srcPos, srcPos + elemsInThisChunk));
673       srcPos += elemsInThisChunk;
674 
675       ctx.putImageData(chunkImgData, 0, j);
676       j += FULL_CHUNK_HEIGHT;
677     }
678     if (i < totalChunks) {
679       elemsInThisChunk = width * partialChunkHeight * 4;
680       dest.set(src.subarray(srcPos, srcPos + elemsInThisChunk));
681 
682       ctx.putImageData(chunkImgData, 0, j);
683     }
684   } else if (imgData.kind === ImageKind.RGB_24BPP) {
685     // RGB, 24-bits per pixel.
686     thisChunkHeight = FULL_CHUNK_HEIGHT;
687     elemsInThisChunk = width * thisChunkHeight;
688     for (i = 0; i < totalChunks; i++) {
689       if (i >= fullChunks) {
690         thisChunkHeight = partialChunkHeight;
691         elemsInThisChunk = width * thisChunkHeight;
692       }
693 
694       destPos = 0;
695       for (j = elemsInThisChunk; j--; ) {
696         dest[destPos++] = src[srcPos++];
697         dest[destPos++] = src[srcPos++];
698         dest[destPos++] = src[srcPos++];
699         dest[destPos++] = 255;
700       }
701 
702       ctx.putImageData(chunkImgData, 0, i * FULL_CHUNK_HEIGHT);
703     }
704   } else {
705     throw new Error(`bad image kind: ${imgData.kind}`);
706   }
707 }
708 
709 function putBinaryImageMask(ctx, imgData) {
710   if (imgData.bitmap) {
711     // The bitmap has been created in the worker.
712     ctx.drawImage(imgData.bitmap, 0, 0);
713     return;
714   }
715 
716   // Slow path: OffscreenCanvas isn't available in the worker.
717   const height = imgData.height,
718     width = imgData.width;
719   const partialChunkHeight = height % FULL_CHUNK_HEIGHT;
720   const fullChunks = (height - partialChunkHeight) / FULL_CHUNK_HEIGHT;
721   const totalChunks = partialChunkHeight === 0 ? fullChunks : fullChunks + 1;
722 
723   const chunkImgData = ctx.createImageData(width, FULL_CHUNK_HEIGHT);
724   let srcPos = 0;
725   const src = imgData.data;
726   const dest = chunkImgData.data;
727 
728   for (let i = 0; i < totalChunks; i++) {
729     const thisChunkHeight =
730       i < fullChunks ? FULL_CHUNK_HEIGHT : partialChunkHeight;
731 
732     // Expand the mask so it can be used by the canvas.  Any required
733     // inversion has already been handled.
734 
735     ({ srcPos } = convertBlackAndWhiteToRGBA({
736       src,
737       srcPos,
738       dest,
739       width,
740       height: thisChunkHeight,
741       nonBlackColor: 0,
742     }));
743 
744     ctx.putImageData(chunkImgData, 0, i * FULL_CHUNK_HEIGHT);
745   }
746 }
747 
748 function copyCtxState(sourceCtx, destCtx) {
749   const properties = [
750     "strokeStyle",
751     "fillStyle",
752     "fillRule",
753     "globalAlpha",
754     "lineWidth",
755     "lineCap",
756     "lineJoin",
757     "miterLimit",
758     "globalCompositeOperation",
759     "font",
760     "filter",
761   ];
762   for (const property of properties) {
763     if (sourceCtx[property] !== undefined) {
764       destCtx[property] = sourceCtx[property];
765     }
766   }
767   if (sourceCtx.setLineDash !== undefined) {
768     destCtx.setLineDash(sourceCtx.getLineDash());
769     destCtx.lineDashOffset = sourceCtx.lineDashOffset;
770   }
771 }
772 
773 function resetCtxToDefault(ctx) {
774   ctx.strokeStyle = ctx.fillStyle = "#000000";
775   ctx.fillRule = "nonzero";
776   ctx.globalAlpha = 1;
777   ctx.lineWidth = 1;
778   ctx.lineCap = "butt";
779   ctx.lineJoin = "miter";
780   ctx.miterLimit = 10;
781   ctx.globalCompositeOperation = "source-over";
782   ctx.font = "10px sans-serif";
783   if (ctx.setLineDash !== undefined) {
784     ctx.setLineDash([]);
785     ctx.lineDashOffset = 0;
786   }
787   if (
788     (typeof PDFJSDev !== "undefined" && PDFJSDev.test("MOZCENTRAL")) ||
789     !isNodeJS
790   ) {
791     const { filter } = ctx;
792     if (filter !== "none" && filter !== "") {
793       ctx.filter = "none";
794     }
795   }
796 }
797 
798 function getImageSmoothingEnabled(transform, interpolate) {
799   // In section 8.9.5.3 of the PDF spec, it's mentioned that the interpolate
800   // flag should be used when the image is upscaled.
801   // In Firefox, smoothing is always used when downscaling images (bug 1360415).
802 
803   if (interpolate) {
804     return true;
805   }
806 
807   const scale = Util.singularValueDecompose2dScale(transform);
808   // Round to a 32bit float so that `<=` check below will pass for numbers that
809   // are very close, but not exactly the same 64bit floats.
810   scale[0] = Math.fround(scale[0]);
811   scale[1] = Math.fround(scale[1]);
812   const actualScale = Math.fround(
813     (globalThis.devicePixelRatio || 1) * PixelsPerInch.PDF_TO_CSS_UNITS
814   );
815   return scale[0] <= actualScale && scale[1] <= actualScale;
816 }
817 
818 const LINE_CAP_STYLES = ["butt", "round", "square"];
819 const LINE_JOIN_STYLES = ["miter", "round", "bevel"];
820 const NORMAL_CLIP = {};
821 const EO_CLIP = {};
822 
823 class CanvasGraphics {
824   constructor(
825     canvasCtx,
826     commonObjs,
827     objs,
828     canvasFactory,
829     filterFactory,
830     { optionalContentConfig, markedContentStack = null },
831     annotationCanvasMap,
832     pageColors
833   ) {
834     this.ctx = canvasCtx;
835     this.current = new CanvasExtraState(
836       this.ctx.canvas.width,
837       this.ctx.canvas.height
838     );
839     this.stateStack = [];
840     this.pendingClip = null;
841     this.pendingEOFill = false;
842     this.res = null;
843     this.xobjs = null;
844     this.commonObjs = commonObjs;
845     this.objs = objs;
846     this.canvasFactory = canvasFactory;
847     this.filterFactory = filterFactory;
848     this.groupStack = [];
849     this.processingType3 = null;
850     // Patterns are painted relative to the initial page/form transform, see
851     // PDF spec 8.7.2 NOTE 1.
852     this.baseTransform = null;
853     this.baseTransformStack = [];
854     this.groupLevel = 0;
855     this.smaskStack = [];
856     this.smaskCounter = 0;
857     this.tempSMask = null;
858     this.suspendedCtx = null;
859     this.contentVisible = true;
860     this.markedContentStack = markedContentStack || [];
861     this.optionalContentConfig = optionalContentConfig;
862     this.cachedCanvases = new CachedCanvases(this.canvasFactory);
863     this.cachedPatterns = new Map();
864     this.annotationCanvasMap = annotationCanvasMap;
865     this.viewportScale = 1;
866     this.outputScaleX = 1;
867     this.outputScaleY = 1;
868     this.pageColors = pageColors;
869 
870     this._cachedScaleForStroking = [-1, 0];
871     this._cachedGetSinglePixelWidth = null;
872     this._cachedBitmapsMap = new Map();
873   }
874 
875   getObject(data, fallback = null) {
876     if (typeof data === "string") {
877       return data.startsWith("g_")
878         ? this.commonObjs.get(data)
879         : this.objs.get(data);
880     }
881     return fallback;
882   }
883 
884   beginDrawing({
885     transform,
886     viewport,
887     transparency = false,
888     background = null,
889   }) {
890     // For pdfs that use blend modes we have to clear the canvas else certain
891     // blend modes can look wrong since we'd be blending with a white
892     // backdrop. The problem with a transparent backdrop though is we then
893     // don't get sub pixel anti aliasing on text, creating temporary
894     // transparent canvas when we have blend modes.
895     const width = this.ctx.canvas.width;
896     const height = this.ctx.canvas.height;
897 
898     const savedFillStyle = this.ctx.fillStyle;
899     this.ctx.fillStyle = background || "#ffffff";
900     this.ctx.fillRect(0, 0, width, height);
901     this.ctx.fillStyle = savedFillStyle;
902 
903     if (transparency) {
904       const transparentCanvas = this.cachedCanvases.getCanvas(
905         "transparent",
906         width,
907         height
908       );
909       this.compositeCtx = this.ctx;
910       this.transparentCanvas = transparentCanvas.canvas;
911       this.ctx = transparentCanvas.context;
912       this.ctx.save();
913       // The transform can be applied before rendering, transferring it to
914       // the new canvas.
915       this.ctx.transform(...getCurrentTransform(this.compositeCtx));
916     }
917 
918     this.ctx.save();
919     resetCtxToDefault(this.ctx);
920     if (transform) {
921       this.ctx.transform(...transform);
922       this.outputScaleX = transform[0];
923       this.outputScaleY = transform[0];
924     }
925     this.ctx.transform(...viewport.transform);
926     this.viewportScale = viewport.scale;
927 
928     this.baseTransform = getCurrentTransform(this.ctx);
929   }
930 
931   executeOperatorList(
932     operatorList,
933     executionStartIdx,
934     continueCallback,
935     stepper
936   ) {
937     const argsArray = operatorList.argsArray;
938     const fnArray = operatorList.fnArray;
939     let i = executionStartIdx || 0;
940     const argsArrayLen = argsArray.length;
941 
942     // Sometimes the OperatorList to execute is empty.
943     if (argsArrayLen === i) {
944       return i;
945     }
946 
947     const chunkOperations =
948       argsArrayLen - i > EXECUTION_STEPS &&
949       typeof continueCallback === "function";
950     const endTime = chunkOperations ? Date.now() + EXECUTION_TIME : 0;
951     let steps = 0;
952 
953     const commonObjs = this.commonObjs;
954     const objs = this.objs;
955     let fnId;
956 
957     while (true) {
958       if (stepper !== undefined && i === stepper.nextBreakPoint) {
959         stepper.breakIt(i, continueCallback);
960         return i;
961       }
962 
963       fnId = fnArray[i];
964 
965       if (fnId !== OPS.dependency) {
966         // eslint-disable-next-line prefer-spread
967         this[fnId].apply(this, argsArray[i]);
968       } else {
969         for (const depObjId of argsArray[i]) {
970           const objsPool = depObjId.startsWith("g_") ? commonObjs : objs;
971 
972           // If the promise isn't resolved yet, add the continueCallback
973           // to the promise and bail out.
974           if (!objsPool.has(depObjId)) {
975             objsPool.get(depObjId, continueCallback);
976             return i;
977           }
978         }
979       }
980 
981       i++;
982 
983       // If the entire operatorList was executed, stop as were done.
984       if (i === argsArrayLen) {
985         return i;
986       }
987 
988       // If the execution took longer then a certain amount of time and
989       // `continueCallback` is specified, interrupt the execution.
990       if (chunkOperations && ++steps > EXECUTION_STEPS) {
991         if (Date.now() > endTime) {
992           continueCallback();
993           return i;
994         }
995         steps = 0;
996       }
997 
998       // If the operatorList isn't executed completely yet OR the execution
999       // time was short enough, do another execution round.
1000     }
1001   }
1002 
1003   #restoreInitialState() {
1004     // Finishing all opened operations such as SMask group painting.
1005     while (this.stateStack.length || this.inSMaskMode) {
1006       this.restore();
1007     }
1008 
1009     this.current.activeSMask = null;
1010     this.ctx.restore();
1011 
1012     if (this.transparentCanvas) {
1013       this.ctx = this.compositeCtx;
1014       this.ctx.save();
1015       this.ctx.setTransform(1, 0, 0, 1, 0, 0); // Avoid apply transform twice
1016       this.ctx.drawImage(this.transparentCanvas, 0, 0);
1017       this.ctx.restore();
1018       this.transparentCanvas = null;
1019     }
1020   }
1021 
1022   endDrawing() {
1023     this.#restoreInitialState();
1024 
1025     this.cachedCanvases.clear();
1026     this.cachedPatterns.clear();
1027 
1028     for (const cache of this._cachedBitmapsMap.values()) {
1029       for (const canvas of cache.values()) {
1030         if (
1031           typeof HTMLCanvasElement !== "undefined" &&
1032           canvas instanceof HTMLCanvasElement
1033         ) {
1034           canvas.width = canvas.height = 0;
1035         }
1036       }
1037       cache.clear();
1038     }
1039     this._cachedBitmapsMap.clear();
1040     this.#drawFilter();
1041   }
1042 
1043   #drawFilter() {
1044     if (this.pageColors) {
1045       const hcmFilterId = this.filterFactory.addHCMFilter(
1046         this.pageColors.foreground,
1047         this.pageColors.background
1048       );
1049       if (hcmFilterId !== "none") {
1050         const savedFilter = this.ctx.filter;
1051         this.ctx.filter = hcmFilterId;
1052         this.ctx.drawImage(this.ctx.canvas, 0, 0);
1053         this.ctx.filter = savedFilter;
1054       }
1055     }
1056   }
1057 
1058   _scaleImage(img, inverseTransform) {
1059     // Vertical or horizontal scaling shall not be more than 2 to not lose the
1060     // pixels during drawImage operation, painting on the temporary canvas(es)
1061     // that are twice smaller in size.
1062     const width = img.width;
1063     const height = img.height;
1064     let widthScale = Math.max(
1065       Math.hypot(inverseTransform[0], inverseTransform[1]),
1066       1
1067     );
1068     let heightScale = Math.max(
1069       Math.hypot(inverseTransform[2], inverseTransform[3]),
1070       1
1071     );
1072 
1073     let paintWidth = width,
1074       paintHeight = height;
1075     let tmpCanvasId = "prescale1";
1076     let tmpCanvas, tmpCtx;
1077     while (
1078       (widthScale > 2 && paintWidth > 1) ||
1079       (heightScale > 2 && paintHeight > 1)
1080     ) {
1081       let newWidth = paintWidth,
1082         newHeight = paintHeight;
1083       if (widthScale > 2 && paintWidth > 1) {
1084         // See bug 1820511 (Windows specific bug).
1085         // TODO: once the above bug is fixed we could revert to:
1086         // newWidth = Math.ceil(paintWidth / 2);
1087         newWidth =
1088           paintWidth >= 16384
1089             ? Math.floor(paintWidth / 2) - 1 || 1
1090             : Math.ceil(paintWidth / 2);
1091         widthScale /= paintWidth / newWidth;
1092       }
1093       if (heightScale > 2 && paintHeight > 1) {
1094         // TODO: see the comment above.
1095         newHeight =
1096           paintHeight >= 16384
1097             ? Math.floor(paintHeight / 2) - 1 || 1
1098             : Math.ceil(paintHeight) / 2;
1099         heightScale /= paintHeight / newHeight;
1100       }
1101       tmpCanvas = this.cachedCanvases.getCanvas(
1102         tmpCanvasId,
1103         newWidth,
1104         newHeight
1105       );
1106       tmpCtx = tmpCanvas.context;
1107       tmpCtx.clearRect(0, 0, newWidth, newHeight);
1108       tmpCtx.drawImage(
1109         img,
1110         0,
1111         0,
1112         paintWidth,
1113         paintHeight,
1114         0,
1115         0,
1116         newWidth,
1117         newHeight
1118       );
1119       img = tmpCanvas.canvas;
1120       paintWidth = newWidth;
1121       paintHeight = newHeight;
1122       tmpCanvasId = tmpCanvasId === "prescale1" ? "prescale2" : "prescale1";
1123     }
1124     return {
1125       img,
1126       paintWidth,
1127       paintHeight,
1128     };
1129   }
1130 
1131   _createMaskCanvas(img) {
1132     const ctx = this.ctx;
1133     const { width, height } = img;
1134     const fillColor = this.current.fillColor;
1135     const isPatternFill = this.current.patternFill;
1136     const currentTransform = getCurrentTransform(ctx);
1137 
1138     let cache, cacheKey, scaled, maskCanvas;
1139     if ((img.bitmap || img.data) && img.count > 1) {
1140       const mainKey = img.bitmap || img.data.buffer;
1141       // We're reusing the same image several times, so we can cache it.
1142       // In case we've a pattern fill we just keep the scaled version of
1143       // the image.
1144       // Only the scaling part matters, the translation part is just used
1145       // to compute offsets (but not when filling patterns see #15573).
1146       // TODO: handle the case of a pattern fill if it's possible.
1147       cacheKey = JSON.stringify(
1148         isPatternFill
1149           ? currentTransform
1150           : [currentTransform.slice(0, 4), fillColor]
1151       );
1152 
1153       cache = this._cachedBitmapsMap.get(mainKey);
1154       if (!cache) {
1155         cache = new Map();
1156         this._cachedBitmapsMap.set(mainKey, cache);
1157       }
1158       const cachedImage = cache.get(cacheKey);
1159       if (cachedImage && !isPatternFill) {
1160         const offsetX = Math.round(
1161           Math.min(currentTransform[0], currentTransform[2]) +
1162             currentTransform[4]
1163         );
1164         const offsetY = Math.round(
1165           Math.min(currentTransform[1], currentTransform[3]) +
1166             currentTransform[5]
1167         );
1168         return {
1169           canvas: cachedImage,
1170           offsetX,
1171           offsetY,
1172         };
1173       }
1174       scaled = cachedImage;
1175     }
1176 
1177     if (!scaled) {
1178       maskCanvas = this.cachedCanvases.getCanvas("maskCanvas", width, height);
1179       putBinaryImageMask(maskCanvas.context, img);
1180     }
1181 
1182     // Create the mask canvas at the size it will be drawn at and also set
1183     // its transform to match the current transform so if there are any
1184     // patterns applied they will be applied relative to the correct
1185     // transform.
1186 
1187     let maskToCanvas = Util.transform(currentTransform, [
1188       1 / width,
1189       0,
1190       0,
1191       -1 / height,
1192       0,
1193       0,
1194     ]);
1195     maskToCanvas = Util.transform(maskToCanvas, [1, 0, 0, 1, 0, -height]);
1196     const [minX, minY, maxX, maxY] = Util.getAxialAlignedBoundingBox(
1197       [0, 0, width, height],
1198       maskToCanvas
1199     );
1200     const drawnWidth = Math.round(maxX - minX) || 1;
1201     const drawnHeight = Math.round(maxY - minY) || 1;
1202     const fillCanvas = this.cachedCanvases.getCanvas(
1203       "fillCanvas",
1204       drawnWidth,
1205       drawnHeight
1206     );
1207     const fillCtx = fillCanvas.context;
1208 
1209     // The offset will be the top-left cordinate mask.
1210     // If objToCanvas is [a,b,c,d,e,f] then:
1211     //   - offsetX = min(a, c) + e
1212     //   - offsetY = min(b, d) + f
1213     const offsetX = minX;
1214     const offsetY = minY;
1215     fillCtx.translate(-offsetX, -offsetY);
1216     fillCtx.transform(...maskToCanvas);
1217 
1218     if (!scaled) {
1219       // Pre-scale if needed to improve image smoothing.
1220       scaled = this._scaleImage(
1221         maskCanvas.canvas,
1222         getCurrentTransformInverse(fillCtx)
1223       );
1224       scaled = scaled.img;
1225       if (cache && isPatternFill) {
1226         cache.set(cacheKey, scaled);
1227       }
1228     }
1229 
1230     fillCtx.imageSmoothingEnabled = getImageSmoothingEnabled(
1231       getCurrentTransform(fillCtx),
1232       img.interpolate
1233     );
1234 
1235     drawImageAtIntegerCoords(
1236       fillCtx,
1237       scaled,
1238       0,
1239       0,
1240       scaled.width,
1241       scaled.height,
1242       0,
1243       0,
1244       width,
1245       height
1246     );
1247     fillCtx.globalCompositeOperation = "source-in";
1248 
1249     const inverse = Util.transform(getCurrentTransformInverse(fillCtx), [
1250       1,
1251       0,
1252       0,
1253       1,
1254       -offsetX,
1255       -offsetY,
1256     ]);
1257     fillCtx.fillStyle = isPatternFill
1258       ? fillColor.getPattern(ctx, this, inverse, PathType.FILL)
1259       : fillColor;
1260 
1261     fillCtx.fillRect(0, 0, width, height);
1262 
1263     if (cache && !isPatternFill) {
1264       // The fill canvas is put in the cache associated to the mask image
1265       // so we must remove from the cached canvas: it mustn't be used again.
1266       this.cachedCanvases.delete("fillCanvas");
1267       cache.set(cacheKey, fillCanvas.canvas);
1268     }
1269 
1270     // Round the offsets to avoid drawing fractional pixels.
1271     return {
1272       canvas: fillCanvas.canvas,
1273       offsetX: Math.round(offsetX),
1274       offsetY: Math.round(offsetY),
1275     };
1276   }
1277 
1278   // Graphics state
1279   setLineWidth(width) {
1280     if (width !== this.current.lineWidth) {
1281       this._cachedScaleForStroking[0] = -1;
1282     }
1283     this.current.lineWidth = width;
1284     this.ctx.lineWidth = width;
1285   }
1286 
1287   setLineCap(style) {
1288     this.ctx.lineCap = LINE_CAP_STYLES[style];
1289   }
1290 
1291   setLineJoin(style) {
1292     this.ctx.lineJoin = LINE_JOIN_STYLES[style];
1293   }
1294 
1295   setMiterLimit(limit) {
1296     this.ctx.miterLimit = limit;
1297   }
1298 
1299   setDash(dashArray, dashPhase) {
1300     const ctx = this.ctx;
1301     if (ctx.setLineDash !== undefined) {
1302       ctx.setLineDash(dashArray);
1303       ctx.lineDashOffset = dashPhase;
1304     }
1305   }
1306 
1307   setRenderingIntent(intent) {
1308     // This operation is ignored since we haven't found a use case for it yet.
1309   }
1310 
1311   setFlatness(flatness) {
1312     // This operation is ignored since we haven't found a use case for it yet.
1313   }
1314 
1315   setGState(states) {
1316     for (const [key, value] of states) {
1317       switch (key) {
1318         case "LW":
1319           this.setLineWidth(value);
1320           break;
1321         case "LC":
1322           this.setLineCap(value);
1323           break;
1324         case "LJ":
1325           this.setLineJoin(value);
1326           break;
1327         case "ML":
1328           this.setMiterLimit(value);
1329           break;
1330         case "D":
1331           this.setDash(value[0], value[1]);
1332           break;
1333         case "RI":
1334           this.setRenderingIntent(value);
1335           break;
1336         case "FL":
1337           this.setFlatness(value);
1338           break;
1339         case "Font":
1340           this.setFont(value[0], value[1]);
1341           break;
1342         case "CA":
1343           this.current.strokeAlpha = value;
1344           break;
1345         case "ca":
1346           this.current.fillAlpha = value;
1347           this.ctx.globalAlpha = value;
1348           break;
1349         case "BM":
1350           this.ctx.globalCompositeOperation = value;
1351           break;
1352         case "SMask":
1353           this.current.activeSMask = value ? this.tempSMask : null;
1354           this.tempSMask = null;
1355           this.checkSMaskState();
1356           break;
1357         case "TR":
1358           this.ctx.filter = this.current.transferMaps =
1359             this.filterFactory.addFilter(value);
1360           break;
1361       }
1362     }
1363   }
1364 
1365   get inSMaskMode() {
1366     return !!this.suspendedCtx;
1367   }
1368 
1369   checkSMaskState() {
1370     const inSMaskMode = this.inSMaskMode;
1371     if (this.current.activeSMask && !inSMaskMode) {
1372       this.beginSMaskMode();
1373     } else if (!this.current.activeSMask && inSMaskMode) {
1374       this.endSMaskMode();
1375     }
1376     // Else, the state is okay and nothing needs to be done.
1377   }
1378 
1379   /**
1380    * Soft mask mode takes the current main drawing canvas and replaces it with
1381    * a temporary canvas. Any drawing operations that happen on the temporary
1382    * canvas need to be composed with the main canvas that was suspended (see
1383    * `compose()`). The temporary canvas also duplicates many of its operations
1384    * on the suspended canvas to keep them in sync, so that when the soft mask
1385    * mode ends any clipping paths or transformations will still be active and in
1386    * the right order on the canvas' graphics state stack.
1387    */
1388   beginSMaskMode() {
1389     if (this.inSMaskMode) {
1390       throw new Error("beginSMaskMode called while already in smask mode");
1391     }
1392     const drawnWidth = this.ctx.canvas.width;
1393     const drawnHeight = this.ctx.canvas.height;
1394     const cacheId = "smaskGroupAt" + this.groupLevel;
1395     const scratchCanvas = this.cachedCanvases.getCanvas(
1396       cacheId,
1397       drawnWidth,
1398       drawnHeight
1399     );
1400     this.suspendedCtx = this.ctx;
1401     this.ctx = scratchCanvas.context;
1402     const ctx = this.ctx;
1403     ctx.setTransform(...getCurrentTransform(this.suspendedCtx));
1404     copyCtxState(this.suspendedCtx, ctx);
1405     mirrorContextOperations(ctx, this.suspendedCtx);
1406 
1407     this.setGState([
1408       ["BM", "source-over"],
1409       ["ca", 1],
1410       ["CA", 1],
1411     ]);
1412   }
1413 
1414   endSMaskMode() {
1415     if (!this.inSMaskMode) {
1416       throw new Error("endSMaskMode called while not in smask mode");
1417     }
1418     // The soft mask is done, now restore the suspended canvas as the main
1419     // drawing canvas.
1420     this.ctx._removeMirroring();
1421     copyCtxState(this.ctx, this.suspendedCtx);
1422     this.ctx = this.suspendedCtx;
1423 
1424     this.suspendedCtx = null;
1425   }
1426 
1427   compose(dirtyBox) {
1428     if (!this.current.activeSMask) {
1429       return;
1430     }
1431 
1432     if (!dirtyBox) {
1433       dirtyBox = [0, 0, this.ctx.canvas.width, this.ctx.canvas.height];
1434     } else {
1435       dirtyBox[0] = Math.floor(dirtyBox[0]);
1436       dirtyBox[1] = Math.floor(dirtyBox[1]);
1437       dirtyBox[2] = Math.ceil(dirtyBox[2]);
1438       dirtyBox[3] = Math.ceil(dirtyBox[3]);
1439     }
1440     const smask = this.current.activeSMask;
1441     const suspendedCtx = this.suspendedCtx;
1442 
1443     this.composeSMask(suspendedCtx, smask, this.ctx, dirtyBox);
1444     // Whatever was drawn has been moved to the suspended canvas, now clear it
1445     // out of the current canvas.
1446     this.ctx.save();
1447     this.ctx.setTransform(1, 0, 0, 1, 0, 0);
1448     this.ctx.clearRect(0, 0, this.ctx.canvas.width, this.ctx.canvas.height);
1449     this.ctx.restore();
1450   }
1451 
1452   composeSMask(ctx, smask, layerCtx, layerBox) {
1453     const layerOffsetX = layerBox[0];
1454     const layerOffsetY = layerBox[1];
1455     const layerWidth = layerBox[2] - layerOffsetX;
1456     const layerHeight = layerBox[3] - layerOffsetY;
1457     if (layerWidth === 0 || layerHeight === 0) {
1458       return;
1459     }
1460     this.genericComposeSMask(
1461       smask.context,
1462       layerCtx,
1463       layerWidth,
1464       layerHeight,
1465       smask.subtype,
1466       smask.backdrop,
1467       smask.transferMap,
1468       layerOffsetX,
1469       layerOffsetY,
1470       smask.offsetX,
1471       smask.offsetY
1472     );
1473     ctx.save();
1474     ctx.globalAlpha = 1;
1475     ctx.globalCompositeOperation = "source-over";
1476     ctx.setTransform(1, 0, 0, 1, 0, 0);
1477     ctx.drawImage(layerCtx.canvas, 0, 0);
1478     ctx.restore();
1479   }
1480 
1481   genericComposeSMask(
1482     maskCtx,
1483     layerCtx,
1484     width,
1485     height,
1486     subtype,
1487     backdrop,
1488     transferMap,
1489     layerOffsetX,
1490     layerOffsetY,
1491     maskOffsetX,
1492     maskOffsetY
1493   ) {
1494     let maskCanvas = maskCtx.canvas;
1495     let maskX = layerOffsetX - maskOffsetX;
1496     let maskY = layerOffsetY - maskOffsetY;
1497 
1498     if (backdrop) {
1499       if (
1500         maskX < 0 ||
1501         maskY < 0 ||
1502         maskX + width > maskCanvas.width ||
1503         maskY + height > maskCanvas.height
1504       ) {
1505         const canvas = this.cachedCanvases.getCanvas(
1506           "maskExtension",
1507           width,
1508           height
1509         );
1510         const ctx = canvas.context;
1511         ctx.drawImage(maskCanvas, -maskX, -maskY);
1512         if (backdrop.some(c => c !== 0)) {
1513           ctx.globalCompositeOperation = "destination-atop";
1514           ctx.fillStyle = Util.makeHexColor(...backdrop);
1515           ctx.fillRect(0, 0, width, height);
1516           ctx.globalCompositeOperation = "source-over";
1517         }
1518 
1519         maskCanvas = canvas.canvas;
1520         maskX = maskY = 0;
1521       } else if (backdrop.some(c => c !== 0)) {
1522         maskCtx.save();
1523         maskCtx.globalAlpha = 1;
1524         maskCtx.setTransform(1, 0, 0, 1, 0, 0);
1525         const clip = new Path2D();
1526         clip.rect(maskX, maskY, width, height);
1527         maskCtx.clip(clip);
1528         maskCtx.globalCompositeOperation = "destination-atop";
1529         maskCtx.fillStyle = Util.makeHexColor(...backdrop);
1530         maskCtx.fillRect(maskX, maskY, width, height);
1531         maskCtx.restore();
1532       }
1533     }
1534 
1535     layerCtx.save();
1536     layerCtx.globalAlpha = 1;
1537     layerCtx.setTransform(1, 0, 0, 1, 0, 0);
1538 
1539     if (subtype === "Alpha" && transferMap) {
1540       layerCtx.filter = this.filterFactory.addAlphaFilter(transferMap);
1541     } else if (subtype === "Luminosity") {
1542       layerCtx.filter = this.filterFactory.addLuminosityFilter(transferMap);
1543     }
1544 
1545     const clip = new Path2D();
1546     clip.rect(layerOffsetX, layerOffsetY, width, height);
1547     layerCtx.clip(clip);
1548     layerCtx.globalCompositeOperation = "destination-in";
1549     layerCtx.drawImage(
1550       maskCanvas,
1551       maskX,
1552       maskY,
1553       width,
1554       height,
1555       layerOffsetX,
1556       layerOffsetY,
1557       width,
1558       height
1559     );
1560     layerCtx.restore();
1561   }
1562 
1563   save() {
1564     if (this.inSMaskMode) {
1565       // SMask mode may be turned on/off causing us to lose graphics state.
1566       // Copy the temporary canvas state to the main(suspended) canvas to keep
1567       // it in sync.
1568       copyCtxState(this.ctx, this.suspendedCtx);
1569       // Don't bother calling save on the temporary canvas since state is not
1570       // saved there.
1571       this.suspendedCtx.save();
1572     } else {
1573       this.ctx.save();
1574     }
1575     const old = this.current;
1576     this.stateStack.push(old);
1577     this.current = old.clone();
1578   }
1579 
1580   restore() {
1581     if (this.stateStack.length === 0 && this.inSMaskMode) {
1582       this.endSMaskMode();
1583     }
1584     if (this.stateStack.length !== 0) {
1585       this.current = this.stateStack.pop();
1586       if (this.inSMaskMode) {
1587         // Graphics state is stored on the main(suspended) canvas. Restore its
1588         // state then copy it over to the temporary canvas.
1589         this.suspendedCtx.restore();
1590         copyCtxState(this.suspendedCtx, this.ctx);
1591       } else {
1592         this.ctx.restore();
1593       }
1594       this.checkSMaskState();
1595 
1596       // Ensure that the clipping path is reset (fixes issue6413.pdf).
1597       this.pendingClip = null;
1598 
1599       this._cachedScaleForStroking[0] = -1;
1600       this._cachedGetSinglePixelWidth = null;
1601     }
1602   }
1603 
1604   transform(a, b, c, d, e, f) {
1605     this.ctx.transform(a, b, c, d, e, f);
1606 
1607     this._cachedScaleForStroking[0] = -1;
1608     this._cachedGetSinglePixelWidth = null;
1609   }
1610 
1611   // Path
1612   constructPath(ops, args, minMax) {
1613     const ctx = this.ctx;
1614     const current = this.current;
1615     let x = current.x,
1616       y = current.y;
1617     let startX, startY;
1618     const currentTransform = getCurrentTransform(ctx);
1619 
1620     // Most of the time the current transform is a scaling matrix
1621     // so we don't need to transform points before computing min/max:
1622     // we can compute min/max first and then smartly "apply" the
1623     // transform (see Util.scaleMinMax).
1624     // For rectangle, moveTo and lineTo, min/max are computed in the
1625     // worker (see evaluator.js).
1626     const isScalingMatrix =
1627       (currentTransform[0] === 0 && currentTransform[3] === 0) ||
1628       (currentTransform[1] === 0 && currentTransform[2] === 0);
1629     const minMaxForBezier = isScalingMatrix ? minMax.slice(0) : null;
1630 
1631     for (let i = 0, j = 0, ii = ops.length; i < ii; i++) {
1632       switch (ops[i] | 0) {
1633         case OPS.rectangle:
1634           x = args[j++];
1635           y = args[j++];
1636           const width = args[j++];
1637           const height = args[j++];
1638 
1639           const xw = x + width;
1640           const yh = y + height;
1641           ctx.moveTo(x, y);
1642           if (width === 0 || height === 0) {
1643             ctx.lineTo(xw, yh);
1644           } else {
1645             ctx.lineTo(xw, y);
1646             ctx.lineTo(xw, yh);
1647             ctx.lineTo(x, yh);
1648           }
1649           if (!isScalingMatrix) {
1650             current.updateRectMinMax(currentTransform, [x, y, xw, yh]);
1651           }
1652           ctx.closePath();
1653           break;
1654         case OPS.moveTo:
1655           x = args[j++];
1656           y = args[j++];
1657           ctx.moveTo(x, y);
1658           if (!isScalingMatrix) {
1659             current.updatePathMinMax(currentTransform, x, y);
1660           }
1661           break;
1662         case OPS.lineTo:
1663           x = args[j++];
1664           y = args[j++];
1665           ctx.lineTo(x, y);
1666           if (!isScalingMatrix) {
1667             current.updatePathMinMax(currentTransform, x, y);
1668           }
1669           break;
1670         case OPS.curveTo:
1671           startX = x;
1672           startY = y;
1673           x = args[j + 4];
1674           y = args[j + 5];
1675           ctx.bezierCurveTo(
1676             args[j],
1677             args[j + 1],
1678             args[j + 2],
1679             args[j + 3],
1680             x,
1681             y
1682           );
1683           current.updateCurvePathMinMax(
1684             currentTransform,
1685             startX,
1686             startY,
1687             args[j],
1688             args[j + 1],
1689             args[j + 2],
1690             args[j + 3],
1691             x,
1692             y,
1693             minMaxForBezier
1694           );
1695           j += 6;
1696           break;
1697         case OPS.curveTo2:
1698           startX = x;
1699           startY = y;
1700           ctx.bezierCurveTo(
1701             x,
1702             y,
1703             args[j],
1704             args[j + 1],
1705             args[j + 2],
1706             args[j + 3]
1707           );
1708           current.updateCurvePathMinMax(
1709             currentTransform,
1710             startX,
1711             startY,
1712             x,
1713             y,
1714             args[j],
1715             args[j + 1],
1716             args[j + 2],
1717             args[j + 3],
1718             minMaxForBezier
1719           );
1720           x = args[j + 2];
1721           y = args[j + 3];
1722           j += 4;
1723           break;
1724         case OPS.curveTo3:
1725           startX = x;
1726           startY = y;
1727           x = args[j + 2];
1728           y = args[j + 3];
1729           ctx.bezierCurveTo(args[j], args[j + 1], x, y, x, y);
1730           current.updateCurvePathMinMax(
1731             currentTransform,
1732             startX,
1733             startY,
1734             args[j],
1735             args[j + 1],
1736             x,
1737             y,
1738             x,
1739             y,
1740             minMaxForBezier
1741           );
1742           j += 4;
1743           break;
1744         case OPS.closePath:
1745           ctx.closePath();
1746           break;
1747       }
1748     }
1749 
1750     if (isScalingMatrix) {
1751       current.updateScalingPathMinMax(currentTransform, minMaxForBezier);
1752     }
1753 
1754     current.setCurrentPoint(x, y);
1755   }
1756 
1757   closePath() {
1758     this.ctx.closePath();
1759   }
1760 
1761   stroke(consumePath = true) {
1762     const ctx = this.ctx;
1763     const strokeColor = this.current.strokeColor;
1764     // For stroke we want to temporarily change the global alpha to the
1765     // stroking alpha.
1766     ctx.globalAlpha = this.current.strokeAlpha;
1767     if (this.contentVisible) {
1768       if (typeof strokeColor === "object" && strokeColor?.getPattern) {
1769         ctx.save();
1770         ctx.strokeStyle = strokeColor.getPattern(
1771           ctx,
1772           this,
1773           getCurrentTransformInverse(ctx),
1774           PathType.STROKE
1775         );
1776         this.rescaleAndStroke(/* saveRestore */ false);
1777         ctx.restore();
1778       } else {
1779         this.rescaleAndStroke(/* saveRestore */ true);
1780       }
1781     }
1782     if (consumePath) {
1783       this.consumePath(this.current.getClippedPathBoundingBox());
1784     }
1785     // Restore the global alpha to the fill alpha
1786     ctx.globalAlpha = this.current.fillAlpha;
1787   }
1788 
1789   closeStroke() {
1790     this.closePath();
1791     this.stroke();
1792   }
1793 
1794   fill(consumePath = true) {
1795     const ctx = this.ctx;
1796     const fillColor = this.current.fillColor;
1797     const isPatternFill = this.current.patternFill;
1798     let needRestore = false;
1799 
1800     if (isPatternFill) {
1801       ctx.save();
1802       ctx.fillStyle = fillColor.getPattern(
1803         ctx,
1804         this,
1805         getCurrentTransformInverse(ctx),
1806         PathType.FILL
1807       );
1808       needRestore = true;
1809     }
1810 
1811     const intersect = this.current.getClippedPathBoundingBox();
1812     if (this.contentVisible && intersect !== null) {
1813       if (this.pendingEOFill) {
1814         ctx.fill("evenodd");
1815         this.pendingEOFill = false;
1816       } else {
1817         ctx.fill();
1818       }
1819     }
1820 
1821     if (needRestore) {
1822       ctx.restore();
1823     }
1824     if (consumePath) {
1825       this.consumePath(intersect);
1826     }
1827   }
1828 
1829   eoFill() {
1830     this.pendingEOFill = true;
1831     this.fill();
1832   }
1833 
1834   fillStroke() {
1835     this.fill(false);
1836     this.stroke(false);
1837 
1838     this.consumePath();
1839   }
1840 
1841   eoFillStroke() {
1842     this.pendingEOFill = true;
1843     this.fillStroke();
1844   }
1845 
1846   closeFillStroke() {
1847     this.closePath();
1848     this.fillStroke();
1849   }
1850 
1851   closeEOFillStroke() {
1852     this.pendingEOFill = true;
1853     this.closePath();
1854     this.fillStroke();
1855   }
1856 
1857   endPath() {
1858     this.consumePath();
1859   }
1860 
1861   // Clipping
1862   clip() {
1863     this.pendingClip = NORMAL_CLIP;
1864   }
1865 
1866   eoClip() {
1867     this.pendingClip = EO_CLIP;
1868   }
1869 
1870   // Text
1871   beginText() {
1872     this.current.textMatrix = IDENTITY_MATRIX;
1873     this.current.textMatrixScale = 1;
1874     this.current.x = this.current.lineX = 0;
1875     this.current.y = this.current.lineY = 0;
1876   }
1877 
1878   endText() {
1879     const paths = this.pendingTextPaths;
1880     const ctx = this.ctx;
1881     if (paths === undefined) {
1882       ctx.beginPath();
1883       return;
1884     }
1885 
1886     ctx.save();
1887     ctx.beginPath();
1888     for (const path of paths) {
1889       ctx.setTransform(...path.transform);
1890       ctx.translate(path.x, path.y);
1891       path.addToPath(ctx, path.fontSize);
1892     }
1893     ctx.restore();
1894     ctx.clip();
1895     ctx.beginPath();
1896     delete this.pendingTextPaths;
1897   }
1898 
1899   setCharSpacing(spacing) {
1900     this.current.charSpacing = spacing;
1901   }
1902 
1903   setWordSpacing(spacing) {
1904     this.current.wordSpacing = spacing;
1905   }
1906 
1907   setHScale(scale) {
1908     this.current.textHScale = scale / 100;
1909   }
1910 
1911   setLeading(leading) {
1912     this.current.leading = -leading;
1913   }
1914 
1915   setFont(fontRefName, size) {
1916     const fontObj = this.commonObjs.get(fontRefName);
1917     const current = this.current;
1918 
1919     if (!fontObj) {
1920       throw new Error(`Can't find font for ${fontRefName}`);
1921     }
1922     current.fontMatrix = fontObj.fontMatrix || FONT_IDENTITY_MATRIX;
1923 
1924     // A valid matrix needs all main diagonal elements to be non-zero
1925     // This also ensures we bypass FF bugzilla bug #719844.
1926     if (current.fontMatrix[0] === 0 || current.fontMatrix[3] === 0) {
1927       warn("Invalid font matrix for font " + fontRefName);
1928     }
1929 
1930     // The spec for Tf (setFont) says that 'size' specifies the font 'scale',
1931     // and in some docs this can be negative (inverted x-y axes).
1932     if (size < 0) {
1933       size = -size;
1934       current.fontDirection = -1;
1935     } else {
1936       current.fontDirection = 1;
1937     }
1938 
1939     this.current.font = fontObj;
1940     this.current.fontSize = size;
1941 
1942     if (fontObj.isType3Font) {
1943       return; // we don't need ctx.font for Type3 fonts
1944     }
1945 
1946     const name = fontObj.loadedName || "sans-serif";
1947     const typeface =
1948       fontObj.systemFontInfo?.css || `"${name}", ${fontObj.fallbackName}`;
1949 
1950     let bold = "normal";
1951     if (fontObj.black) {
1952       bold = "900";
1953     } else if (fontObj.bold) {
1954       bold = "bold";
1955     }
1956     const italic = fontObj.italic ? "italic" : "normal";
1957 
1958     // Some font backends cannot handle fonts below certain size.
1959     // Keeping the font at minimal size and using the fontSizeScale to change
1960     // the current transformation matrix before the fillText/strokeText.
1961     // See https://bugzilla.mozilla.org/show_bug.cgi?id=726227
1962     let browserFontSize = size;
1963     if (size < MIN_FONT_SIZE) {
1964       browserFontSize = MIN_FONT_SIZE;
1965     } else if (size > MAX_FONT_SIZE) {
1966       browserFontSize = MAX_FONT_SIZE;
1967     }
1968     this.current.fontSizeScale = size / browserFontSize;
1969 
1970     this.ctx.font = `${italic} ${bold} ${browserFontSize}px ${typeface}`;
1971   }
1972 
1973   setTextRenderingMode(mode) {
1974     this.current.textRenderingMode = mode;
1975   }
1976 
1977   setTextRise(rise) {
1978     this.current.textRise = rise;
1979   }
1980 
1981   moveText(x, y) {
1982     this.current.x = this.current.lineX += x;
1983     this.current.y = this.current.lineY += y;
1984   }
1985 
1986   setLeadingMoveText(x, y) {
1987     this.setLeading(-y);
1988     this.moveText(x, y);
1989   }
1990 
1991   setTextMatrix(a, b, c, d, e, f) {
1992     this.current.textMatrix = [a, b, c, d, e, f];
1993     this.current.textMatrixScale = Math.hypot(a, b);
1994 
1995     this.current.x = this.current.lineX = 0;
1996     this.current.y = this.current.lineY = 0;
1997   }
1998 
1999   nextLine() {
2000     this.moveText(0, this.current.leading);
2001   }
2002 
2003   paintChar(character, x, y, patternTransform) {
2004     const ctx = this.ctx;
2005     const current = this.current;
2006     const font = current.font;
2007     const textRenderingMode = current.textRenderingMode;
2008     const fontSize = current.fontSize / current.fontSizeScale;
2009     const fillStrokeMode =
2010       textRenderingMode & TextRenderingMode.FILL_STROKE_MASK;
2011     const isAddToPathSet = !!(
2012       textRenderingMode & TextRenderingMode.ADD_TO_PATH_FLAG
2013     );
2014     const patternFill = current.patternFill && !font.missingFile;
2015 
2016     let addToPath;
2017     if (font.disableFontFace || isAddToPathSet || patternFill) {
2018       addToPath = font.getPathGenerator(this.commonObjs, character);
2019     }
2020 
2021     if (font.disableFontFace || patternFill) {
2022       ctx.save();
2023       ctx.translate(x, y);
2024       ctx.beginPath();
2025       addToPath(ctx, fontSize);
2026       if (patternTransform) {
2027         ctx.setTransform(...patternTransform);
2028       }
2029       if (
2030         fillStrokeMode === TextRenderingMode.FILL ||
2031         fillStrokeMode === TextRenderingMode.FILL_STROKE
2032       ) {
2033         ctx.fill();
2034       }
2035       if (
2036         fillStrokeMode === TextRenderingMode.STROKE ||
2037         fillStrokeMode === TextRenderingMode.FILL_STROKE
2038       ) {
2039         ctx.stroke();
2040       }
2041       ctx.restore();
2042     } else {
2043       if (
2044         fillStrokeMode === TextRenderingMode.FILL ||
2045         fillStrokeMode === TextRenderingMode.FILL_STROKE
2046       ) {
2047         ctx.fillText(character, x, y);
2048       }
2049       if (
2050         fillStrokeMode === TextRenderingMode.STROKE ||
2051         fillStrokeMode === TextRenderingMode.FILL_STROKE
2052       ) {
2053         ctx.strokeText(character, x, y);
2054       }
2055     }
2056 
2057     if (isAddToPathSet) {
2058       const paths = (this.pendingTextPaths ||= []);
2059       paths.push({
2060         transform: getCurrentTransform(ctx),
2061         x,
2062         y,
2063         fontSize,
2064         addToPath,
2065       });
2066     }
2067   }
2068 
2069   get isFontSubpixelAAEnabled() {
2070     // Checks if anti-aliasing is enabled when scaled text is painted.
2071     // On Windows GDI scaled fonts looks bad.
2072     const { context: ctx } = this.cachedCanvases.getCanvas(
2073       "isFontSubpixelAAEnabled",
2074       10,
2075       10
2076     );
2077     ctx.scale(1.5, 1);
2078     ctx.fillText("I", 0, 10);
2079     const data = ctx.getImageData(0, 0, 10, 10).data;
2080     let enabled = false;
2081     for (let i = 3; i < data.length; i += 4) {
2082       if (data[i] > 0 && data[i] < 255) {
2083         enabled = true;
2084         break;
2085       }
2086     }
2087     return shadow(this, "isFontSubpixelAAEnabled", enabled);
2088   }
2089 
2090   showText(glyphs) {
2091     const current = this.current;
2092     const font = current.font;
2093     if (font.isType3Font) {
2094       return this.showType3Text(glyphs);
2095     }
2096 
2097     const fontSize = current.fontSize;
2098     if (fontSize === 0) {
2099       return undefined;
2100     }
2101 
2102     const ctx = this.ctx;
2103     const fontSizeScale = current.fontSizeScale;
2104     const charSpacing = current.charSpacing;
2105     const wordSpacing = current.wordSpacing;
2106     const fontDirection = current.fontDirection;
2107     const textHScale = current.textHScale * fontDirection;
2108     const glyphsLength = glyphs.length;
2109     const vertical = font.vertical;
2110     const spacingDir = vertical ? 1 : -1;
2111     const defaultVMetrics = font.defaultVMetrics;
2112     const widthAdvanceScale = fontSize * current.fontMatrix[0];
2113 
2114     const simpleFillText =
2115       current.textRenderingMode === TextRenderingMode.FILL &&
2116       !font.disableFontFace &&
2117       !current.patternFill;
2118 
2119     ctx.save();
2120     ctx.transform(...current.textMatrix);
2121     ctx.translate(current.x, current.y + current.textRise);
2122 
2123     if (fontDirection > 0) {
2124       ctx.scale(textHScale, -1);
2125     } else {
2126       ctx.scale(textHScale, 1);
2127     }
2128 
2129     let patternTransform;
2130     if (current.patternFill) {
2131       ctx.save();
2132       const pattern = current.fillColor.getPattern(
2133         ctx,
2134         this,
2135         getCurrentTransformInverse(ctx),
2136         PathType.FILL
2137       );
2138       patternTransform = getCurrentTransform(ctx);
2139       ctx.restore();
2140       ctx.fillStyle = pattern;
2141     }
2142 
2143     let lineWidth = current.lineWidth;
2144     const scale = current.textMatrixScale;
2145     if (scale === 0 || lineWidth === 0) {
2146       const fillStrokeMode =
2147         current.textRenderingMode & TextRenderingMode.FILL_STROKE_MASK;
2148       if (
2149         fillStrokeMode === TextRenderingMode.STROKE ||
2150         fillStrokeMode === TextRenderingMode.FILL_STROKE
2151       ) {
2152         lineWidth = this.getSinglePixelWidth();
2153       }
2154     } else {
2155       lineWidth /= scale;
2156     }
2157 
2158     if (fontSizeScale !== 1.0) {
2159       ctx.scale(fontSizeScale, fontSizeScale);
2160       lineWidth /= fontSizeScale;
2161     }
2162 
2163     ctx.lineWidth = lineWidth;
2164 
2165     if (font.isInvalidPDFjsFont) {
2166       const chars = [];
2167       let width = 0;
2168       for (const glyph of glyphs) {
2169         chars.push(glyph.unicode);
2170         width += glyph.width;
2171       }
2172       ctx.fillText(chars.join(""), 0, 0);
2173       current.x += width * widthAdvanceScale * textHScale;
2174       ctx.restore();
2175       this.compose();
2176 
2177       return undefined;
2178     }
2179 
2180     let x = 0,
2181       i;
2182     for (i = 0; i < glyphsLength; ++i) {
2183       const glyph = glyphs[i];
2184       if (typeof glyph === "number") {
2185         x += (spacingDir * glyph * fontSize) / 1000;
2186         continue;
2187       }
2188 
2189       let restoreNeeded = false;
2190       const spacing = (glyph.isSpace ? wordSpacing : 0) + charSpacing;
2191       const character = glyph.fontChar;
2192       const accent = glyph.accent;
2193       let scaledX, scaledY;
2194       let width = glyph.width;
2195       if (vertical) {
2196         const vmetric = glyph.vmetric || defaultVMetrics;
2197         const vx =
2198           -(glyph.vmetric ? vmetric[1] : width * 0.5) * widthAdvanceScale;
2199         const vy = vmetric[2] * widthAdvanceScale;
2200 
2201         width = vmetric ? -vmetric[0] : width;
2202         scaledX = vx / fontSizeScale;
2203         scaledY = (x + vy) / fontSizeScale;
2204       } else {
2205         scaledX = x / fontSizeScale;
2206         scaledY = 0;
2207       }
2208 
2209       if (font.remeasure && width > 0) {
2210         // Some standard fonts may not have the exact width: rescale per
2211         // character if measured width is greater than expected glyph width
2212         // and subpixel-aa is enabled, otherwise just center the glyph.
2213         const measuredWidth =
2214           ((ctx.measureText(character).width * 1000) / fontSize) *
2215           fontSizeScale;
2216         if (width < measuredWidth && this.isFontSubpixelAAEnabled) {
2217           const characterScaleX = width / measuredWidth;
2218           restoreNeeded = true;
2219           ctx.save();
2220           ctx.scale(characterScaleX, 1);
2221           scaledX /= characterScaleX;
2222         } else if (width !== measuredWidth) {
2223           scaledX +=
2224             (((width - measuredWidth) / 2000) * fontSize) / fontSizeScale;
2225         }
2226       }
2227 
2228       // Only attempt to draw the glyph if it is actually in the embedded font
2229       // file or if there isn't a font file so the fallback font is shown.
2230       if (this.contentVisible && (glyph.isInFont || font.missingFile)) {
2231         if (simpleFillText && !accent) {
2232           // common case
2233           ctx.fillText(character, scaledX, scaledY);
2234         } else {
2235           this.paintChar(character, scaledX, scaledY, patternTransform);
2236           if (accent) {
2237             const scaledAccentX =
2238               scaledX + (fontSize * accent.offset.x) / fontSizeScale;
2239             const scaledAccentY =
2240               scaledY - (fontSize * accent.offset.y) / fontSizeScale;
2241             this.paintChar(
2242               accent.fontChar,
2243               scaledAccentX,
2244               scaledAccentY,
2245               patternTransform
2246             );
2247           }
2248         }
2249       }
2250 
2251       const charWidth = vertical
2252         ? width * widthAdvanceScale - spacing * fontDirection
2253         : width * widthAdvanceScale + spacing * fontDirection;
2254       x += charWidth;
2255 
2256       if (restoreNeeded) {
2257         ctx.restore();
2258       }
2259     }
2260     if (vertical) {
2261       current.y -= x;
2262     } else {
2263       current.x += x * textHScale;
2264     }
2265     ctx.restore();
2266     this.compose();
2267 
2268     return undefined;
2269   }
2270 
2271   showType3Text(glyphs) {
2272     // Type3 fonts - each glyph is a "mini-PDF"
2273     const ctx = this.ctx;
2274     const current = this.current;
2275     const font = current.font;
2276     const fontSize = current.fontSize;
2277     const fontDirection = current.fontDirection;
2278     const spacingDir = font.vertical ? 1 : -1;
2279     const charSpacing = current.charSpacing;
2280     const wordSpacing = current.wordSpacing;
2281     const textHScale = current.textHScale * fontDirection;
2282     const fontMatrix = current.fontMatrix || FONT_IDENTITY_MATRIX;
2283     const glyphsLength = glyphs.length;
2284     const isTextInvisible =
2285       current.textRenderingMode === TextRenderingMode.INVISIBLE;
2286     let i, glyph, width, spacingLength;
2287 
2288     if (isTextInvisible || fontSize === 0) {
2289       return;
2290     }
2291     this._cachedScaleForStroking[0] = -1;
2292     this._cachedGetSinglePixelWidth = null;
2293 
2294     ctx.save();
2295     ctx.transform(...current.textMatrix);
2296     ctx.translate(current.x, current.y);
2297 
2298     ctx.scale(textHScale, fontDirection);
2299 
2300     for (i = 0; i < glyphsLength; ++i) {
2301       glyph = glyphs[i];
2302       if (typeof glyph === "number") {
2303         spacingLength = (spacingDir * glyph * fontSize) / 1000;
2304         this.ctx.translate(spacingLength, 0);
2305         current.x += spacingLength * textHScale;
2306         continue;
2307       }
2308 
2309       const spacing = (glyph.isSpace ? wordSpacing : 0) + charSpacing;
2310       const operatorList = font.charProcOperatorList[glyph.operatorListId];
2311       if (!operatorList) {
2312         warn(`Type3 character "${glyph.operatorListId}" is not available.`);
2313         continue;
2314       }
2315       if (this.contentVisible) {
2316         this.processingType3 = glyph;
2317         this.save();
2318         ctx.scale(fontSize, fontSize);
2319         ctx.transform(...fontMatrix);
2320         this.executeOperatorList(operatorList);
2321         this.restore();
2322       }
2323 
2324       const transformed = Util.applyTransform([glyph.width, 0], fontMatrix);
2325       width = transformed[0] * fontSize + spacing;
2326 
2327       ctx.translate(width, 0);
2328       current.x += width * textHScale;
2329     }
2330     ctx.restore();
2331     this.processingType3 = null;
2332   }
2333 
2334   // Type3 fonts
2335   setCharWidth(xWidth, yWidth) {
2336     // We can safely ignore this since the width should be the same
2337     // as the width in the Widths array.
2338   }
2339 
2340   setCharWidthAndBounds(xWidth, yWidth, llx, lly, urx, ury) {
2341     this.ctx.rect(llx, lly, urx - llx, ury - lly);
2342     this.ctx.clip();
2343     this.endPath();
2344   }
2345 
2346   // Color
2347   getColorN_Pattern(IR) {
2348     let pattern;
2349     if (IR[0] === "TilingPattern") {
2350       const color = IR[1];
2351       const baseTransform = this.baseTransform || getCurrentTransform(this.ctx);
2352       const canvasGraphicsFactory = {
2353         createCanvasGraphics: ctx =>
2354           new CanvasGraphics(
2355             ctx,
2356             this.commonObjs,
2357             this.objs,
2358             this.canvasFactory,
2359             this.filterFactory,
2360             {
2361               optionalContentConfig: this.optionalContentConfig,
2362               markedContentStack: this.markedContentStack,
2363             }
2364           ),
2365       };
2366       pattern = new TilingPattern(
2367         IR,
2368         color,
2369         this.ctx,
2370         canvasGraphicsFactory,
2371         baseTransform
2372       );
2373     } else {
2374       pattern = this._getPattern(IR[1], IR[2]);
2375     }
2376     return pattern;
2377   }
2378 
2379   setStrokeColorN() {
2380     this.current.strokeColor = this.getColorN_Pattern(arguments);
2381   }
2382 
2383   setFillColorN() {
2384     this.current.fillColor = this.getColorN_Pattern(arguments);
2385     this.current.patternFill = true;
2386   }
2387 
2388   setStrokeRGBColor(r, g, b) {
2389     this.ctx.strokeStyle = this.current.strokeColor = Util.makeHexColor(
2390       r,
2391       g,
2392       b
2393     );
2394   }
2395 
2396   setStrokeTransparent() {
2397     this.ctx.strokeStyle = this.current.strokeColor = "transparent";
2398   }
2399 
2400   setFillRGBColor(r, g, b) {
2401     this.ctx.fillStyle = this.current.fillColor = Util.makeHexColor(r, g, b);
2402     this.current.patternFill = false;
2403   }
2404 
2405   setFillTransparent() {
2406     this.ctx.fillStyle = this.current.fillColor = "transparent";
2407     this.current.patternFill = false;
2408   }
2409 
2410   _getPattern(objId, matrix = null) {
2411     let pattern;
2412     if (this.cachedPatterns.has(objId)) {
2413       pattern = this.cachedPatterns.get(objId);
2414     } else {
2415       pattern = getShadingPattern(this.getObject(objId));
2416       this.cachedPatterns.set(objId, pattern);
2417     }
2418     if (matrix) {
2419       pattern.matrix = matrix;
2420     }
2421     return pattern;
2422   }
2423 
2424   shadingFill(objId) {
2425     if (!this.contentVisible) {
2426       return;
2427     }
2428     const ctx = this.ctx;
2429 
2430     this.save();
2431     const pattern = this._getPattern(objId);
2432     ctx.fillStyle = pattern.getPattern(
2433       ctx,
2434       this,
2435       getCurrentTransformInverse(ctx),
2436       PathType.SHADING
2437     );
2438 
2439     const inv = getCurrentTransformInverse(ctx);
2440     if (inv) {
2441       const { width, height } = ctx.canvas;
2442       const [x0, y0, x1, y1] = Util.getAxialAlignedBoundingBox(
2443         [0, 0, width, height],
2444         inv
2445       );
2446 
2447       this.ctx.fillRect(x0, y0, x1 - x0, y1 - y0);
2448     } else {
2449       // HACK to draw the gradient onto an infinite rectangle.
2450       // PDF gradients are drawn across the entire image while
2451       // Canvas only allows gradients to be drawn in a rectangle
2452       // The following bug should allow us to remove this.
2453       // https://bugzilla.mozilla.org/show_bug.cgi?id=664884
2454 
2455       this.ctx.fillRect(-1e10, -1e10, 2e10, 2e10);
2456     }
2457 
2458     this.compose(this.current.getClippedPathBoundingBox());
2459     this.restore();
2460   }
2461 
2462   // Images
2463   beginInlineImage() {
2464     unreachable("Should not call beginInlineImage");
2465   }
2466 
2467   beginImageData() {
2468     unreachable("Should not call beginImageData");
2469   }
2470 
2471   paintFormXObjectBegin(matrix, bbox) {
2472     if (!this.contentVisible) {
2473       return;
2474     }
2475     this.save();
2476     this.baseTransformStack.push(this.baseTransform);
2477 
2478     if (matrix) {
2479       this.transform(...matrix);
2480     }
2481     this.baseTransform = getCurrentTransform(this.ctx);
2482 
2483     if (bbox) {
2484       const width = bbox[2] - bbox[0];
2485       const height = bbox[3] - bbox[1];
2486       this.ctx.rect(bbox[0], bbox[1], width, height);
2487       this.current.updateRectMinMax(getCurrentTransform(this.ctx), bbox);
2488       this.clip();
2489       this.endPath();
2490     }
2491   }
2492 
2493   paintFormXObjectEnd() {
2494     if (!this.contentVisible) {
2495       return;
2496     }
2497     this.restore();
2498     this.baseTransform = this.baseTransformStack.pop();
2499   }
2500 
2501   beginGroup(group) {
2502     if (!this.contentVisible) {
2503       return;
2504     }
2505 
2506     this.save();
2507     // If there's an active soft mask we don't want it enabled for the group, so
2508     // clear it out. The mask and suspended canvas will be restored in endGroup.
2509     if (this.inSMaskMode) {
2510       this.endSMaskMode();
2511       this.current.activeSMask = null;
2512     }
2513 
2514     const currentCtx = this.ctx;
2515     // TODO non-isolated groups - according to Rik at adobe non-isolated
2516     // group results aren't usually that different and they even have tools
2517     // that ignore this setting. Notes from Rik on implementing:
2518     // - When you encounter an transparency group, create a new canvas with
2519     // the dimensions of the bbox
2520     // - copy the content from the previous canvas to the new canvas
2521     // - draw as usual
2522     // - remove the backdrop alpha:
2523     // alphaNew = 1 - (1 - alpha)/(1 - alphaBackdrop) with 'alpha' the alpha
2524     // value of your transparency group and 'alphaBackdrop' the alpha of the
2525     // backdrop
2526     // - remove background color:
2527     // colorNew = color - alphaNew *colorBackdrop /(1 - alphaNew)
2528     if (!group.isolated) {
2529       info("TODO: Support non-isolated groups.");
2530     }
2531 
2532     // TODO knockout - supposedly possible with the clever use of compositing
2533     // modes.
2534     if (group.knockout) {
2535       warn("Knockout groups not supported.");
2536     }
2537 
2538     const currentTransform = getCurrentTransform(currentCtx);
2539     if (group.matrix) {
2540       currentCtx.transform(...group.matrix);
2541     }
2542     if (!group.bbox) {
2543       throw new Error("Bounding box is required.");
2544     }
2545 
2546     // Based on the current transform figure out how big the bounding box
2547     // will actually be.
2548     let bounds = Util.getAxialAlignedBoundingBox(
2549       group.bbox,
2550       getCurrentTransform(currentCtx)
2551     );
2552     // Clip the bounding box to the current canvas.
2553     const canvasBounds = [
2554       0,
2555       0,
2556       currentCtx.canvas.width,
2557       currentCtx.canvas.height,
2558     ];
2559     bounds = Util.intersect(bounds, canvasBounds) || [0, 0, 0, 0];
2560     // Use ceil in case we're between sizes so we don't create canvas that is
2561     // too small and make the canvas at least 1x1 pixels.
2562     const offsetX = Math.floor(bounds[0]);
2563     const offsetY = Math.floor(bounds[1]);
2564     const drawnWidth = Math.max(Math.ceil(bounds[2]) - offsetX, 1);
2565     const drawnHeight = Math.max(Math.ceil(bounds[3]) - offsetY, 1);
2566 
2567     this.current.startNewPathAndClipBox([0, 0, drawnWidth, drawnHeight]);
2568 
2569     let cacheId = "groupAt" + this.groupLevel;
2570     if (group.smask) {
2571       // Using two cache entries is case if masks are used one after another.
2572       cacheId += "_smask_" + (this.smaskCounter++ % 2);
2573     }
2574     const scratchCanvas = this.cachedCanvases.getCanvas(
2575       cacheId,
2576       drawnWidth,
2577       drawnHeight
2578     );
2579     const groupCtx = scratchCanvas.context;
2580 
2581     // Since we created a new canvas that is just the size of the bounding box
2582     // we have to translate the group ctx.
2583     groupCtx.translate(-offsetX, -offsetY);
2584     groupCtx.transform(...currentTransform);
2585 
2586     if (group.smask) {
2587       // Saving state and cached mask to be used in setGState.
2588       this.smaskStack.push({
2589         canvas: scratchCanvas.canvas,
2590         context: groupCtx,
2591         offsetX,
2592         offsetY,
2593         subtype: group.smask.subtype,
2594         backdrop: group.smask.backdrop,
2595         transferMap: group.smask.transferMap || null,
2596         startTransformInverse: null, // used during suspend operation
2597       });
2598     } else {
2599       // Setup the current ctx so when the group is popped we draw it at the
2600       // right location.
2601       currentCtx.setTransform(1, 0, 0, 1, 0, 0);
2602       currentCtx.translate(offsetX, offsetY);
2603       currentCtx.save();
2604     }
2605     // The transparency group inherits all off the current graphics state
2606     // except the blend mode, soft mask, and alpha constants.
2607     copyCtxState(currentCtx, groupCtx);
2608     this.ctx = groupCtx;
2609     this.setGState([
2610       ["BM", "source-over"],
2611       ["ca", 1],
2612       ["CA", 1],
2613     ]);
2614     this.groupStack.push(currentCtx);
2615     this.groupLevel++;
2616   }
2617 
2618   endGroup(group) {
2619     if (!this.contentVisible) {
2620       return;
2621     }
2622     this.groupLevel--;
2623     const groupCtx = this.ctx;
2624     const ctx = this.groupStack.pop();
2625     this.ctx = ctx;
2626     // Turn off image smoothing to avoid sub pixel interpolation which can
2627     // look kind of blurry for some pdfs.
2628     this.ctx.imageSmoothingEnabled = false;
2629 
2630     if (group.smask) {
2631       this.tempSMask = this.smaskStack.pop();
2632       this.restore();
2633     } else {
2634       this.ctx.restore();
2635       const currentMtx = getCurrentTransform(this.ctx);
2636       this.restore();
2637       this.ctx.save();
2638       this.ctx.setTransform(...currentMtx);
2639       const dirtyBox = Util.getAxialAlignedBoundingBox(
2640         [0, 0, groupCtx.canvas.width, groupCtx.canvas.height],
2641         currentMtx
2642       );
2643       this.ctx.drawImage(groupCtx.canvas, 0, 0);
2644       this.ctx.restore();
2645       this.compose(dirtyBox);
2646     }
2647   }
2648 
2649   beginAnnotation(id, rect, transform, matrix, hasOwnCanvas) {
2650     // The annotations are drawn just after the page content.
2651     // The page content drawing can potentially have set a transform,
2652     // a clipping path, whatever...
2653     // So in order to have something clean, we restore the initial state.
2654     this.#restoreInitialState();
2655     resetCtxToDefault(this.ctx);
2656 
2657     this.ctx.save();
2658     this.save();
2659 
2660     if (this.baseTransform) {
2661       this.ctx.setTransform(...this.baseTransform);
2662     }
2663 
2664     if (rect) {
2665       const width = rect[2] - rect[0];
2666       const height = rect[3] - rect[1];
2667 
2668       if (hasOwnCanvas && this.annotationCanvasMap) {
2669         transform = transform.slice();
2670         transform[4] -= rect[0];
2671         transform[5] -= rect[1];
2672 
2673         rect = rect.slice();
2674         rect[0] = rect[1] = 0;
2675         rect[2] = width;
2676         rect[3] = height;
2677 
2678         const [scaleX, scaleY] = Util.singularValueDecompose2dScale(
2679           getCurrentTransform(this.ctx)
2680         );
2681         const { viewportScale } = this;
2682         const canvasWidth = Math.ceil(
2683           width * this.outputScaleX * viewportScale
2684         );
2685         const canvasHeight = Math.ceil(
2686           height * this.outputScaleY * viewportScale
2687         );
2688 
2689         this.annotationCanvas = this.canvasFactory.create(
2690           canvasWidth,
2691           canvasHeight
2692         );
2693         const { canvas, context } = this.annotationCanvas;
2694         this.annotationCanvasMap.set(id, canvas);
2695         this.annotationCanvas.savedCtx = this.ctx;
2696         this.ctx = context;
2697         this.ctx.save();
2698         this.ctx.setTransform(scaleX, 0, 0, -scaleY, 0, height * scaleY);
2699 
2700         resetCtxToDefault(this.ctx);
2701       } else {
2702         resetCtxToDefault(this.ctx);
2703 
2704         // Consume a potential path before clipping.
2705         this.endPath();
2706 
2707         this.ctx.rect(rect[0], rect[1], width, height);
2708         this.ctx.clip();
2709         this.ctx.beginPath();
2710       }
2711     }
2712 
2713     this.current = new CanvasExtraState(
2714       this.ctx.canvas.width,
2715       this.ctx.canvas.height
2716     );
2717 
2718     this.transform(...transform);
2719     this.transform(...matrix);
2720   }
2721 
2722   endAnnotation() {
2723     if (this.annotationCanvas) {
2724       this.ctx.restore();
2725       this.#drawFilter();
2726 
2727       this.ctx = this.annotationCanvas.savedCtx;
2728       delete this.annotationCanvas.savedCtx;
2729       delete this.annotationCanvas;
2730     }
2731   }
2732 
2733   paintImageMaskXObject(img) {
2734     if (!this.contentVisible) {
2735       return;
2736     }
2737     const count = img.count;
2738     img = this.getObject(img.data, img);
2739     img.count = count;
2740 
2741     const ctx = this.ctx;
2742     const glyph = this.processingType3;
2743 
2744     if (glyph) {
2745       if (glyph.compiled === undefined) {
2746         glyph.compiled = compileType3Glyph(img);
2747       }
2748 
2749       if (glyph.compiled) {
2750         glyph.compiled(ctx);
2751         return;
2752       }
2753     }
2754     const mask = this._createMaskCanvas(img);
2755     const maskCanvas = mask.canvas;
2756 
2757     ctx.save();
2758     // The mask is drawn with the transform applied. Reset the current
2759     // transform to draw to the identity.
2760     ctx.setTransform(1, 0, 0, 1, 0, 0);
2761     ctx.drawImage(maskCanvas, mask.offsetX, mask.offsetY);
2762     ctx.restore();
2763     this.compose();
2764   }
2765 
2766   paintImageMaskXObjectRepeat(
2767     img,
2768     scaleX,
2769     skewX = 0,
2770     skewY = 0,
2771     scaleY,
2772     positions
2773   ) {
2774     if (!this.contentVisible) {
2775       return;
2776     }
2777 
2778     img = this.getObject(img.data, img);
2779 
2780     const ctx = this.ctx;
2781     ctx.save();
2782     const currentTransform = getCurrentTransform(ctx);
2783     ctx.transform(scaleX, skewX, skewY, scaleY, 0, 0);
2784     const mask = this._createMaskCanvas(img);
2785 
2786     ctx.setTransform(
2787       1,
2788       0,
2789       0,
2790       1,
2791       mask.offsetX - currentTransform[4],
2792       mask.offsetY - currentTransform[5]
2793     );
2794     for (let i = 0, ii = positions.length; i < ii; i += 2) {
2795       const trans = Util.transform(currentTransform, [
2796         scaleX,
2797         skewX,
2798         skewY,
2799         scaleY,
2800         positions[i],
2801         positions[i + 1],
2802       ]);
2803 
2804       const [x, y] = Util.applyTransform([0, 0], trans);
2805       ctx.drawImage(mask.canvas, x, y);
2806     }
2807     ctx.restore();
2808     this.compose();
2809   }
2810 
2811   paintImageMaskXObjectGroup(images) {
2812     if (!this.contentVisible) {
2813       return;
2814     }
2815     const ctx = this.ctx;
2816 
2817     const fillColor = this.current.fillColor;
2818     const isPatternFill = this.current.patternFill;
2819 
2820     for (const image of images) {
2821       const { data, width, height, transform } = image;
2822 
2823       const maskCanvas = this.cachedCanvases.getCanvas(
2824         "maskCanvas",
2825         width,
2826         height
2827       );
2828       const maskCtx = maskCanvas.context;
2829       maskCtx.save();
2830 
2831       const img = this.getObject(data, image);
2832       putBinaryImageMask(maskCtx, img);
2833 
2834       maskCtx.globalCompositeOperation = "source-in";
2835 
2836       maskCtx.fillStyle = isPatternFill
2837         ? fillColor.getPattern(
2838             maskCtx,
2839             this,
2840             getCurrentTransformInverse(ctx),
2841             PathType.FILL
2842           )
2843         : fillColor;
2844       maskCtx.fillRect(0, 0, width, height);
2845 
2846       maskCtx.restore();
2847 
2848       ctx.save();
2849       ctx.transform(...transform);
2850       ctx.scale(1, -1);
2851       drawImageAtIntegerCoords(
2852         ctx,
2853         maskCanvas.canvas,
2854         0,
2855         0,
2856         width,
2857         height,
2858         0,
2859         -1,
2860         1,
2861         1
2862       );
2863       ctx.restore();
2864     }
2865     this.compose();
2866   }
2867 
2868   paintImageXObject(objId) {
2869     if (!this.contentVisible) {
2870       return;
2871     }
2872     const imgData = this.getObject(objId);
2873     if (!imgData) {
2874       warn("Dependent image isn't ready yet");
2875       return;
2876     }
2877 
2878     this.paintInlineImageXObject(imgData);
2879   }
2880 
2881   paintImageXObjectRepeat(objId, scaleX, scaleY, positions) {
2882     if (!this.contentVisible) {
2883       return;
2884     }
2885     const imgData = this.getObject(objId);
2886     if (!imgData) {
2887       warn("Dependent image isn't ready yet");
2888       return;
2889     }
2890 
2891     const width = imgData.width;
2892     const height = imgData.height;
2893     const map = [];
2894     for (let i = 0, ii = positions.length; i < ii; i += 2) {
2895       map.push({
2896         transform: [scaleX, 0, 0, scaleY, positions[i], positions[i + 1]],
2897         x: 0,
2898         y: 0,
2899         w: width,
2900         h: height,
2901       });
2902     }
2903     this.paintInlineImageXObjectGroup(imgData, map);
2904   }
2905 
2906   applyTransferMapsToCanvas(ctx) {
2907     if (this.current.transferMaps !== "none") {
2908       ctx.filter = this.current.transferMaps;
2909       ctx.drawImage(ctx.canvas, 0, 0);
2910       ctx.filter = "none";
2911     }
2912     return ctx.canvas;
2913   }
2914 
2915   applyTransferMapsToBitmap(imgData) {
2916     if (this.current.transferMaps === "none") {
2917       return imgData.bitmap;
2918     }
2919     const { bitmap, width, height } = imgData;
2920     const tmpCanvas = this.cachedCanvases.getCanvas(
2921       "inlineImage",
2922       width,
2923       height
2924     );
2925     const tmpCtx = tmpCanvas.context;
2926     tmpCtx.filter = this.current.transferMaps;
2927     tmpCtx.drawImage(bitmap, 0, 0);
2928     tmpCtx.filter = "none";
2929 
2930     return tmpCanvas.canvas;
2931   }
2932 
2933   paintInlineImageXObject(imgData) {
2934     if (!this.contentVisible) {
2935       return;
2936     }
2937     const width = imgData.width;
2938     const height = imgData.height;
2939     const ctx = this.ctx;
2940 
2941     this.save();
2942 
2943     if (
2944       (typeof PDFJSDev !== "undefined" && PDFJSDev.test("MOZCENTRAL")) ||
2945       !isNodeJS
2946     ) {
2947       // The filter, if any, will be applied in applyTransferMapsToBitmap.
2948       // It must be applied to the image before rescaling else some artifacts
2949       // could appear.
2950       // The final restore will reset it to its value.
2951       const { filter } = ctx;
2952       if (filter !== "none" && filter !== "") {
2953         ctx.filter = "none";
2954       }
2955     }
2956 
2957     // scale the image to the unit square
2958     ctx.scale(1 / width, -1 / height);
2959 
2960     let imgToPaint;
2961     if (imgData.bitmap) {
2962       imgToPaint = this.applyTransferMapsToBitmap(imgData);
2963     } else if (
2964       (typeof HTMLElement === "function" && imgData instanceof HTMLElement) ||
2965       !imgData.data
2966     ) {
2967       // typeof check is needed due to node.js support, see issue #8489
2968       imgToPaint = imgData;
2969     } else {
2970       const tmpCanvas = this.cachedCanvases.getCanvas(
2971         "inlineImage",
2972         width,
2973         height
2974       );
2975       const tmpCtx = tmpCanvas.context;
2976       putBinaryImageData(tmpCtx, imgData);
2977       imgToPaint = this.applyTransferMapsToCanvas(tmpCtx);
2978     }
2979 
2980     const scaled = this._scaleImage(
2981       imgToPaint,
2982       getCurrentTransformInverse(ctx)
2983     );
2984     ctx.imageSmoothingEnabled = getImageSmoothingEnabled(
2985       getCurrentTransform(ctx),
2986       imgData.interpolate
2987     );
2988 
2989     drawImageAtIntegerCoords(
2990       ctx,
2991       scaled.img,
2992       0,
2993       0,
2994       scaled.paintWidth,
2995       scaled.paintHeight,
2996       0,
2997       -height,
2998       width,
2999       height
3000     );
3001     this.compose();
3002     this.restore();
3003   }
3004 
3005   paintInlineImageXObjectGroup(imgData, map) {
3006     if (!this.contentVisible) {
3007       return;
3008     }
3009     const ctx = this.ctx;
3010     let imgToPaint;
3011     if (imgData.bitmap) {
3012       imgToPaint = imgData.bitmap;
3013     } else {
3014       const w = imgData.width;
3015       const h = imgData.height;
3016 
3017       const tmpCanvas = this.cachedCanvases.getCanvas("inlineImage", w, h);
3018       const tmpCtx = tmpCanvas.context;
3019       putBinaryImageData(tmpCtx, imgData);
3020       imgToPaint = this.applyTransferMapsToCanvas(tmpCtx);
3021     }
3022 
3023     for (const entry of map) {
3024       ctx.save();
3025       ctx.transform(...entry.transform);
3026       ctx.scale(1, -1);
3027       drawImageAtIntegerCoords(
3028         ctx,
3029         imgToPaint,
3030         entry.x,
3031         entry.y,
3032         entry.w,
3033         entry.h,
3034         0,
3035         -1,
3036         1,
3037         1
3038       );
3039       ctx.restore();
3040     }
3041     this.compose();
3042   }
3043 
3044   paintSolidColorImageMask() {
3045     if (!this.contentVisible) {
3046       return;
3047     }
3048     this.ctx.fillRect(0, 0, 1, 1);
3049     this.compose();
3050   }
3051 
3052   // Marked content
3053 
3054   markPoint(tag) {
3055     // TODO Marked content.
3056   }
3057 
3058   markPointProps(tag, properties) {
3059     // TODO Marked content.
3060   }
3061 
3062   beginMarkedContent(tag) {
3063     this.markedContentStack.push({
3064       visible: true,
3065     });
3066   }
3067 
3068   beginMarkedContentProps(tag, properties) {
3069     if (tag === "OC") {
3070       this.markedContentStack.push({
3071         visible: this.optionalContentConfig.isVisible(properties),
3072       });
3073     } else {
3074       this.markedContentStack.push({
3075         visible: true,
3076       });
3077     }
3078     this.contentVisible = this.isContentVisible();
3079   }
3080 
3081   endMarkedContent() {
3082     this.markedContentStack.pop();
3083     this.contentVisible = this.isContentVisible();
3084   }
3085 
3086   // Compatibility
3087 
3088   beginCompat() {
3089     // TODO ignore undefined operators (should we do that anyway?)
3090   }
3091 
3092   endCompat() {
3093     // TODO stop ignoring undefined operators
3094   }
3095 
3096   // Helper functions
3097 
3098   consumePath(clipBox) {
3099     const isEmpty = this.current.isEmptyClip();
3100     if (this.pendingClip) {
3101       this.current.updateClipFromPath();
3102     }
3103     if (!this.pendingClip) {
3104       this.compose(clipBox);
3105     }
3106     const ctx = this.ctx;
3107     if (this.pendingClip) {
3108       if (!isEmpty) {
3109         if (this.pendingClip === EO_CLIP) {
3110           ctx.clip("evenodd");
3111         } else {
3112           ctx.clip();
3113         }
3114       }
3115       this.pendingClip = null;
3116     }
3117     this.current.startNewPathAndClipBox(this.current.clipBox);
3118     ctx.beginPath();
3119   }
3120 
3121   getSinglePixelWidth() {
3122     if (!this._cachedGetSinglePixelWidth) {
3123       const m = getCurrentTransform(this.ctx);
3124       if (m[1] === 0 && m[2] === 0) {
3125         // Fast path
3126         this._cachedGetSinglePixelWidth =
3127           1 / Math.min(Math.abs(m[0]), Math.abs(m[3]));
3128       } else {
3129         const absDet = Math.abs(m[0] * m[3] - m[2] * m[1]);
3130         const normX = Math.hypot(m[0], m[2]);
3131         const normY = Math.hypot(m[1], m[3]);
3132         this._cachedGetSinglePixelWidth = Math.max(normX, normY) / absDet;
3133       }
3134     }
3135     return this._cachedGetSinglePixelWidth;
3136   }
3137 
3138   getScaleForStroking() {
3139     // A pixel has thicknessX = thicknessY = 1;
3140     // A transformed pixel is a parallelogram and the thicknesses
3141     // corresponds to the heights.
3142     // The goal of this function is to rescale before setting the
3143     // lineWidth in order to have both thicknesses greater or equal
3144     // to 1 after transform.
3145     if (this._cachedScaleForStroking[0] === -1) {
3146       const { lineWidth } = this.current;
3147       const { a, b, c, d } = this.ctx.getTransform();
3148       let scaleX, scaleY;
3149 
3150       if (b === 0 && c === 0) {
3151         // Fast path
3152         const normX = Math.abs(a);
3153         const normY = Math.abs(d);
3154         if (normX === normY) {
3155           if (lineWidth === 0) {
3156             scaleX = scaleY = 1 / normX;
3157           } else {
3158             const scaledLineWidth = normX * lineWidth;
3159             scaleX = scaleY = scaledLineWidth < 1 ? 1 / scaledLineWidth : 1;
3160           }
3161         } else if (lineWidth === 0) {
3162           scaleX = 1 / normX;
3163           scaleY = 1 / normY;
3164         } else {
3165           const scaledXLineWidth = normX * lineWidth;
3166           const scaledYLineWidth = normY * lineWidth;
3167           scaleX = scaledXLineWidth < 1 ? 1 / scaledXLineWidth : 1;
3168           scaleY = scaledYLineWidth < 1 ? 1 / scaledYLineWidth : 1;
3169         }
3170       } else {
3171         // A pixel (base (x, y)) is transformed by M into a parallelogram:
3172         //  - its area is |det(M)|;
3173         //  - heightY (orthogonal to Mx) has a length: |det(M)| / norm(Mx);
3174         //  - heightX (orthogonal to My) has a length: |det(M)| / norm(My).
3175         // heightX and heightY are the thicknesses of the transformed pixel
3176         // and they must be both greater or equal to 1.
3177         const absDet = Math.abs(a * d - b * c);
3178         const normX = Math.hypot(a, b);
3179         const normY = Math.hypot(c, d);
3180         if (lineWidth === 0) {
3181           scaleX = normY / absDet;
3182           scaleY = normX / absDet;
3183         } else {
3184           const baseArea = lineWidth * absDet;
3185           scaleX = normY > baseArea ? normY / baseArea : 1;
3186           scaleY = normX > baseArea ? normX / baseArea : 1;
3187         }
3188       }
3189       this._cachedScaleForStroking[0] = scaleX;
3190       this._cachedScaleForStroking[1] = scaleY;
3191     }
3192     return this._cachedScaleForStroking;
3193   }
3194 
3195   // Rescale before stroking in order to have a final lineWidth
3196   // with both thicknesses greater or equal to 1.
3197   rescaleAndStroke(saveRestore) {
3198     const { ctx } = this;
3199     const { lineWidth } = this.current;
3200     const [scaleX, scaleY] = this.getScaleForStroking();
3201 
3202     ctx.lineWidth = lineWidth || 1;
3203 
3204     if (scaleX === 1 && scaleY === 1) {
3205       ctx.stroke();
3206       return;
3207     }
3208 
3209     const dashes = ctx.getLineDash();
3210     if (saveRestore) {
3211       ctx.save();
3212     }
3213 
3214     ctx.scale(scaleX, scaleY);
3215 
3216     // How the dashed line is rendered depends on the current transform...
3217     // so we added a rescale to handle too thin lines and consequently
3218     // the way the line is dashed will be modified.
3219     // If scaleX === scaleY, the dashed lines will be rendered correctly
3220     // else we'll have some bugs (but only with too thin lines).
3221     // Here we take the max... why not taking the min... or something else.
3222     // Anyway, as said it's buggy when scaleX !== scaleY.
3223     if (dashes.length > 0) {
3224       const scale = Math.max(scaleX, scaleY);
3225       ctx.setLineDash(dashes.map(x => x / scale));
3226       ctx.lineDashOffset /= scale;
3227     }
3228 
3229     ctx.stroke();
3230 
3231     if (saveRestore) {
3232       ctx.restore();
3233     }
3234   }
3235 
3236   isContentVisible() {
3237     for (let i = this.markedContentStack.length - 1; i >= 0; i--) {
3238       if (!this.markedContentStack[i].visible) {
3239         return false;
3240       }
3241     }
3242     return true;
3243   }
3244 }
3245 
3246 for (const op in OPS) {
3247   if (CanvasGraphics.prototype[op] !== undefined) {
3248     CanvasGraphics.prototype[OPS[op]] = CanvasGraphics.prototype[op];
3249   }
3250 }
3251 
3252 export { CanvasGraphics };
</code>

Your task:
You are a software tester at pdf.js.
1. Write exactly one javascript test `it("...", async () => {...})` block.
2. Your test must fail on the code before the patch, and pass after, hence the test will verify that the patch resolves the issue.
3. The test must be self-contained and to-the-point.
4. Use only the provided imports (respect the paths exactly how they are given) by importing dynamically for compatibility with Node.js — no new dependencies. 
5. Return only the javascript code (no comments or explanations).

Example structure:
it("should <describe behavior>", async () => {
  const { example } = await import("../../src/core/example.js");
  <initialize required variables>;
  <define expected variable>;
  <generate actual variables>;
  <compare expected with actual>;
});

