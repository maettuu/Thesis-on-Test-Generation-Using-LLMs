Before you begin:
- Keep going until the job is completely solved — don’t stop halfway.
- If you’re unsure about the behavior, reread the provided patch carefully; do not hallucinate.
- Plan your approach before writing code by reflecting on whether the test truly fails before and passes after.

Issue:
<issue>
Regression between Firefox 109.0.1 and 115.0.2 - document used to render, now does not
Link to PDF file here: [issue16759.pdf](https://github.com/mozilla/pdf.js/files/12185373/issue16759.pdf) (from [https://lab6.com/1](https://lab6.com/1))

Configuration:
- Web browser and its version: Firefox 115.0.2 (64-bit)
- Operating system and its version: Ubuntu 22.04
- PDF.js version: Version built into Firefox 115.0.2


Steps to reproduce the problem:
1. Try to load the above URL
2. Document does not render. The following error message can be found in the console:

```
Invalid or corrupted PDF file.

PDF.js v3.7.96 (build: 23958ffc5)
Message: Invalid PDF structure.
```

This document used to render in Firefox 109.0.1 (possibly later versions too, but that's the old version I have to hand). It renders in Chrome and Okular, and also passes PDF validators (https://www.pdfen.com/pdf-a-validator and VeraPDF).

N.B. This is a polyglot PDF/MP3 file that does not rely on parser bugs. I believe it to be fully conformant to the PDF spec, but it may push the boundaries of what a PDF processor expects, or I may be wrong about it being fully conformant.

</issue>

Patch:
<patch>
diff --git a/src/core/xref.js b/src/core/xref.js
--- a/src/core/xref.js
+++ b/src/core/xref.js
@@ -431,7 +431,7 @@ class XRef {
       }
       return skipped;
     }
-    const gEndobjRegExp = /\b(endobj|\d+\s+\d+\s+obj|xref|trailer)\b/g;
+    const gEndobjRegExp = /\b(endobj|\d+\s+\d+\s+obj|xref|trailer\s*<<)\b/g;
     const gStartxrefRegExp = /\b(startxref|\d+\s+\d+\s+obj)\b/g;
     const objRegExp = /^(\d+)\s+(\d+)\s+obj\b/;


</patch>

Imports:
<imports>
Available Packages
Dev Dependencies:
- @babel/core: ^7.22.9
- @babel/plugin-transform-modules-commonjs: ^7.22.5
- @babel/preset-env: ^7.22.9
- @babel/runtime: ^7.22.6
- @javascript-obfuscator/escodegen: 2.3.0
- acorn: ^8.10.0
- autoprefixer: ^10.4.14
- babel-loader: ^9.1.3
- caniuse-lite: ^1.0.30001517
- canvas: ^2.11.2
- core-js: ^3.31.1
- cross-env: ^7.0.3
- es-module-shims: 1.4.7
- eslint: ^8.45.0
- eslint-config-prettier: ^8.8.0
- eslint-plugin-fetch-options: ^0.0.5
- eslint-plugin-html: ^7.1.0
- eslint-plugin-import: ^2.27.5
- eslint-plugin-json: ^3.1.0
- eslint-plugin-mozilla: ^3.1.0
- eslint-plugin-no-unsanitized: ^4.0.2
- eslint-plugin-prettier: ^5.0.0
- eslint-plugin-sort-exports: ^0.8.0
- eslint-plugin-unicorn: ^48.0.0
- globals: ^13.20.0
- gulp: ^4.0.2
- gulp-postcss: ^9.0.1
- gulp-rename: ^2.0.0
- gulp-replace: ^1.1.4
- gulp-zip: ^5.1.0
- jasmine: ^5.1.0
- jsdoc: ^4.0.2
- jstransformer-markdown-it: ^3.0.0
- merge-stream: ^2.0.0
- mkdirp: ^3.0.1
- needle: ^3.2.0
- path2d-polyfill: ^2.0.1
- pngjs: ^7.0.0
- postcss: ^8.4.27
- postcss-dir-pseudo-class: ^8.0.0
- prettier: ^3.0.0
- puppeteer: ^20.9.0
- rimraf: ^3.0.2
- streamqueue: ^1.1.2
- stylelint: ^15.10.2
- stylelint-prettier: ^4.0.0
- terser: ^5.19.2
- through2: ^4.0.2
- ttest: ^4.0.0
- typescript: ^5.1.6
- typogr: ^0.6.8
- vinyl: ^3.0.0
- webpack: ^5.88.2
- webpack-stream: ^7.0.0
- wintersmith: ^2.5.0
- yargs: ^17.7.2

Engines:
- node: >=18

Available Relative Imports:
- `../../src/core/annotation.js`: Annotation, AnnotationBorderStyle, AnnotationFactory, MarkupAnnotation, getQuadPoints
- `../../src/core/bidi.js`: bidi
- `../../src/core/cff_parser.js`: CFFCharset, CFFCompiler, CFFFDSelect, CFFParser, CFFStrings
- `../../src/core/cmap.js`: CMap, CMapFactory, IdentityCMap
- `../../src/core/colorspace.js`: ColorSpace
- `../../src/core/core_utils.js`: arrayBuffersToBytes, encodeToXmlString, escapePDFName, escapeString, getInheritableProperty, isAscii, isWhiteSpace, log2, numberToString, parseXFAPath, recoverJsURL, stringToUTF16HexString, stringToUTF16String, toRomanNumerals, validateCSSFont
- `../../src/core/crypto.js`: AES128Cipher, AES256Cipher, ARCFourCipher, CipherTransformFactory, PDF17, PDF20, calculateMD5, calculateSHA256, calculateSHA384, calculateSHA512
- `../../src/core/default_appearance.js`: createDefaultAppearance, parseAppearanceStream, parseDefaultAppearance
- `../../src/core/document.js`: PDFDocument, Page
- `../../src/core/encodings.js`: getEncoding
- `../../src/core/evaluator.js`: PartialEvaluator
- `../../src/core/font_substitutions.js`: getFontSubstitution
- `../../src/core/fonts_utils.js`: SEAC_ANALYSIS_ENABLED
- `../../src/core/function.js`: PDFFunctionFactory, PostScriptCompiler, PostScriptEvaluator
- `../../src/core/glyphlist.js`: getDingbatsGlyphsUnicode, getGlyphsUnicode
- `../../src/core/image_utils.js`: GlobalImageCache, LocalColorSpaceCache
- `../../src/core/jbig2.js`: Jbig2Image
- `../../src/core/jpg.js`: JpegImage
- `../../src/core/jpx.js`: JpxImage
- `../../src/core/metadata_parser.js`: MetadataParser
- `../../src/core/operator_list.js`: OperatorList
- `../../src/core/parser.js`: Lexer, Linearization, Parser
- `../../src/core/predictor_stream.js`: PredictorStream
- `../../src/core/primitives.js`: Cmd, Dict, EOF, Name, Ref, RefSet, RefSetCache, isCmd, isDict, isName, isRefsEqual
- `../../src/core/ps_parser.js`: PostScriptLexer, PostScriptParser
- `../../src/core/stream.js`: NullStream, Stream, StringStream
- `../../src/core/type1_parser.js`: Type1Parser
- `../../src/core/unicode.js`: getCharUnicodeCategory, getUnicodeForGlyph, getUnicodeRangeFor, mapSpecialUnicodeValues
- `../../src/core/worker.js`: WorkerMessageHandler, WorkerTask
- `../../src/core/writer.js`: incrementalUpdate, writeDict
- `../../src/core/xfa/bind.js`: Binder
- `../../src/core/xfa/data.js`: DataHandler
- `../../src/core/xfa/factory.js`: XFAFactory
- `../../src/core/xfa/formcalc_lexer.js`: Lexer, TOKEN, Token
- `../../src/core/xfa/formcalc_parser.js`: Errors, Parser
- `../../src/core/xfa/parser.js`: XFAParser
- `../../src/core/xfa/som.js`: searchNode
- `../../src/core/xfa/symbol_utils.js`: $dump, $getChildren, $getChildrenByClass, $getChildrenByName, $text, $uid
- `../../src/core/xml_parser.js`: SimpleXMLParser, XMLParserBase
- `../../src/display/annotation_layer.js`: AnnotationLayer
- `../../src/display/annotation_storage.js`: AnnotationStorage
- `../../src/display/api.js`: DefaultCMapReaderFactory, DefaultCanvasFactory, DefaultStandardFontDataFactory, LoopbackPort, PDFDataRangeTransport, PDFDocumentLoadingTask, PDFDocumentProxy, PDFPageProxy, PDFWorker, PDFWorkerUtil, RenderTask, SVGGraphics, build, getDocument, version
- `../../src/display/display_utils.js`: DOMCanvasFactory, DOMSVGFactory, PDFDateString, PageViewport, PixelsPerInch, RenderingCancelledException, StatTimer, getFilenameFromUrl, getPdfFilenameFromUrl, getXfaPageViewport, isDataScheme, isPdfFile, isValidFetchUrl, loadScript, setLayerDimensions
- `../../src/display/editor/annotation_editor_layer.js`: AnnotationEditorLayer
- `../../src/display/editor/tools.js`: AnnotationEditorUIManager, CommandManager
- `../../src/display/fetch_stream.js`: PDFFetchStream
- `../../src/display/metadata.js`: Metadata
- `../../src/display/network.js`: PDFNetworkStream
- `../../src/display/network_utils.js`: createResponseStatusError, extractFilenameFromHeader, validateRangeRequestCapabilities, validateResponseStatus
- `../../src/display/node_stream.js`: PDFNodeStream
- `../../src/display/svg.js`: SVGGraphics
- `../../src/display/text_layer.js`: TextLayerRenderTask, renderTextLayer, updateTextLayer
- `../../src/display/worker_options.js`: GlobalWorkerOptions
- `../../src/display/xfa_layer.js`: XfaLayer
- `../../src/shared/message_handler.js`: MessageHandler
- `../../src/shared/murmurhash3.js`: MurmurHash3_64
- `../../src/shared/util.js`: AbortException, AnnotationBorderStyleType, AnnotationEditorParamsType, AnnotationEditorType, AnnotationFieldFlag, AnnotationFlag, AnnotationMode, AnnotationType, CMapCompressionType, FeatureTest, FormatError, ImageKind, InvalidPDFException, MissingPDFException, OPS, PasswordException, PasswordResponses, PermissionFlag, PromiseCapability, RenderingIntentFlag, UnexpectedResponseException, UnknownErrorException, Util, VerbosityLevel, bytesToString, createValidAbsoluteUrl, getModificationDate, getVerbosityLevel, isArrayBuffer, isNodeJS, normalizeUnicode, objectSize, setVerbosityLevel, shadow, string32, stringToBytes, stringToPDFString, stringToUTF8String
- `../../web/annotation_layer_builder.js`: AnnotationLayerBuilder
- `../../web/download_manager.js`: DownloadManager
- `../../web/event_utils.js`: EventBus, WaitOnType, waitOnEventOrTimeout
- `../../web/genericl10n.js`: GenericL10n
- `../../web/l10n_utils.js`: NullL10n
- `../../web/pdf_find_controller.js`: FindState, PDFFindController
- `../../web/pdf_find_utils.js`: CharacterType, getCharacterType
- `../../web/pdf_history.js`: PDFHistory, isDestArraysEqual, isDestHashesEqual
- `../../web/pdf_link_service.js`: LinkTarget, PDFLinkService, SimpleLinkService
- `../../web/pdf_page_view.js`: PDFPageView
- `../../web/pdf_scripting_manager.component.js`: PDFScriptingManager
- `../../web/pdf_single_page_viewer.js`: PDFSinglePageViewer
- `../../web/pdf_viewer.js`: PDFPageViewBuffer, PDFViewer
- `../../web/struct_tree_layer_builder.js`: StructTreeLayerBuilder
- `../../web/text_layer_builder.js`: TextLayerBuilder
- `../../web/ui_utils.js`: AutoPrintRegExp, ProgressBar, RenderingStates, ScrollMode, SpreadMode, backtrackBeforeAllVisibleElements, binarySearchFirstItem, getPageSizeInches, getVisibleElements, isPortraitOrientation, isValidRotation, parseQueryString, removeNullCharacters
- `../../web/xfa_layer_builder.js`: XfaLayerBuilder
- `./test_utils.js`: CMAP_URL, DefaultFileReaderFactory, STANDARD_FONT_DATA_URL, TEST_PDFS_PATH, XRefMock, buildGetDocumentParams, createIdFactory
- `./testreporter.js`: TestReporter
</imports>

Code:
<code>
File:
src/core/xref.js
1 /* Copyright 2021 Mozilla Foundation
2  *
3  * Licensed under the Apache License, Version 2.0 (the "License");
4  * you may not use this file except in compliance with the License.
5  * You may obtain a copy of the License at
6  *
7  *     http://www.apache.org/licenses/LICENSE-2.0
8  *
9  * Unless required by applicable law or agreed to in writing, software
10  * distributed under the License is distributed on an "AS IS" BASIS,
11  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12  * See the License for the specific language governing permissions and
13  * limitations under the License.
14  */
15 
16 import {
17   assert,
18   bytesToString,
19   FormatError,
20   info,
21   InvalidPDFException,
22   warn,
23 } from "../shared/util.js";
24 import { CIRCULAR_REF, Cmd, Dict, isCmd, Ref, RefSet } from "./primitives.js";
25 import { Lexer, Parser } from "./parser.js";
26 import {
27   MissingDataException,
28   ParserEOFException,
29   XRefEntryException,
30   XRefParseException,
31 } from "./core_utils.js";
32 import { BaseStream } from "./base_stream.js";
33 import { CipherTransformFactory } from "./crypto.js";
34 
35 class XRef {
36   #firstXRefStmPos = null;
37 
38   constructor(stream, pdfManager) {
39     this.stream = stream;
40     this.pdfManager = pdfManager;
41     this.entries = [];
42     this._xrefStms = new Set();
43     this._cacheMap = new Map(); // Prepare the XRef cache.
44     this._pendingRefs = new RefSet();
45     this._newPersistentRefNum = null;
46     this._newTemporaryRefNum = null;
47   }
48 
394   indexObjects() {
395     // Simple scan through the PDF content to find objects,
396     // trailers and XRef streams.
397     const TAB = 0x9,
398       LF = 0xa,
399       CR = 0xd,
400       SPACE = 0x20;
401     const PERCENT = 0x25,
402       LT = 0x3c;
403 
404     function readToken(data, offset) {
405       let token = "",
406         ch = data[offset];
407       while (ch !== LF && ch !== CR && ch !== LT) {
408         if (++offset >= data.length) {
409           break;
410         }
411         token += String.fromCharCode(ch);
412         ch = data[offset];
413       }
414       return token;
415     }
416     function skipUntil(data, offset, what) {
417       const length = what.length,
418         dataLength = data.length;
419       let skipped = 0;
420       // finding byte sequence
421       while (offset < dataLength) {
422         let i = 0;
423         while (i < length && data[offset + i] === what[i]) {
424           ++i;
425         }
426         if (i >= length) {
427           break; // sequence found
428         }
429         offset++;
430         skipped++;
431       }
432       return skipped;
433     }
434     const gEndobjRegExp = /\b(endobj|\d+\s+\d+\s+obj|xref|trailer)\b/g;
435     const gStartxrefRegExp = /\b(startxref|\d+\s+\d+\s+obj)\b/g;
436     const objRegExp = /^(\d+)\s+(\d+)\s+obj\b/;
437 
438     const trailerBytes = new Uint8Array([116, 114, 97, 105, 108, 101, 114]);
439     const startxrefBytes = new Uint8Array([
440       115, 116, 97, 114, 116, 120, 114, 101, 102,
441     ]);
442     const xrefBytes = new Uint8Array([47, 88, 82, 101, 102]);
443 
444     // Clear out any existing entries, since they may be bogus.
445     this.entries.length = 0;
446     this._cacheMap.clear();
447 
448     const stream = this.stream;
449     stream.pos = 0;
450     const buffer = stream.getBytes(),
451       bufferStr = bytesToString(buffer),
452       length = buffer.length;
453     let position = stream.start;
454     const trailers = [],
455       xrefStms = [];
456     while (position < length) {
457       let ch = buffer[position];
458       if (ch === TAB || ch === LF || ch === CR || ch === SPACE) {
459         ++position;
460         continue;
461       }
462       if (ch === PERCENT) {
463         // %-comment
464         do {
465           ++position;
466           if (position >= length) {
467             break;
468           }
469           ch = buffer[position];
470         } while (ch !== LF && ch !== CR);
471         continue;
472       }
473       const token = readToken(buffer, position);
474       let m;
475       if (
476         token.startsWith("xref") &&
477         (token.length === 4 || /\s/.test(token[4]))
478       ) {
479         position += skipUntil(buffer, position, trailerBytes);
480         trailers.push(position);
481         position += skipUntil(buffer, position, startxrefBytes);
482       } else if ((m = objRegExp.exec(token))) {
483         const num = m[1] | 0,
484           gen = m[2] | 0;
485 
486         const startPos = position + token.length;
487         let contentLength,
488           updateEntries = false;
489         if (!this.entries[num]) {
490           updateEntries = true;
491         } else if (this.entries[num].gen === gen) {
492           // Before overwriting an existing entry, ensure that the new one won't
493           // cause *immediate* errors when it's accessed (fixes issue13783.pdf).
494           try {
495             const parser = new Parser({
496               lexer: new Lexer(stream.makeSubStream(startPos)),
497             });
498             parser.getObj();
499             updateEntries = true;
500           } catch (ex) {
501             if (ex instanceof ParserEOFException) {
502               warn(`indexObjects -- checking object (${token}): "${ex}".`);
503             } else {
504               // The error may come from the `Parser`-instance being initialized
505               // without an `XRef`-instance (we don't have a usable one yet).
506               updateEntries = true;
507             }
508           }
509         }
510         if (updateEntries) {
511           this.entries[num] = {
512             offset: position - stream.start,
513             gen,
514             uncompressed: true,
515           };
516         }
517 
518         // Find the next "obj" string, rather than "endobj", to ensure that
519         // we won't skip over a new 'obj' operator in corrupt files where
520         // 'endobj' operators are missing (fixes issue9105_reduced.pdf).
521         gEndobjRegExp.lastIndex = startPos;
522         const match = gEndobjRegExp.exec(bufferStr);
523 
524         if (match) {
525           const endPos = gEndobjRegExp.lastIndex + 1;
526           contentLength = endPos - position;
527 
528           if (match[1] !== "endobj") {
529             warn(
530               `indexObjects: Found "${match[1]}" inside of another "obj", ` +
531                 'caused by missing "endobj" -- trying to recover.'
532             );
533             contentLength -= match[1].length + 1;
534           }
535         } else {
536           contentLength = length - position;
537         }
538         const content = buffer.subarray(position, position + contentLength);
539 
540         // checking XRef stream suspect
541         // (it shall have '/XRef' and next char is not a letter)
542         const xrefTagOffset = skipUntil(content, 0, xrefBytes);
543         if (xrefTagOffset < contentLength && content[xrefTagOffset + 5] < 64) {
544           xrefStms.push(position - stream.start);
545           this._xrefStms.add(position - stream.start); // Avoid recursion
546         }
547 
548         position += contentLength;
549       } else if (
550         token.startsWith("trailer") &&
551         (token.length === 7 || /\s/.test(token[7]))
552       ) {
553         trailers.push(position);
554 
555         const startPos = position + token.length;
556         let contentLength;
557         // Attempt to handle (some) corrupt documents, where no 'startxref'
558         // operators are present (fixes issue15590.pdf).
559         gStartxrefRegExp.lastIndex = startPos;
560         const match = gStartxrefRegExp.exec(bufferStr);
561 
562         if (match) {
563           const endPos = gStartxrefRegExp.lastIndex + 1;
564           contentLength = endPos - position;
565 
566           if (match[1] !== "startxref") {
567             warn(
568               `indexObjects: Found "${match[1]}" after "trailer", ` +
569                 'caused by missing "startxref" -- trying to recover.'
570             );
571             contentLength -= match[1].length + 1;
572           }
573         } else {
574           contentLength = length - position;
575         }
576         position += contentLength;
577       } else {
578         position += token.length + 1;
579       }
580     }
581     // reading XRef streams
582     for (const xrefStm of xrefStms) {
583       this.startXRefQueue.push(xrefStm);
584       this.readXRef(/* recoveryMode */ true);
585     }
586 
587     const trailerDicts = [];
588     // Pre-parsing the trailers to check if the document is possibly encrypted.
589     let isEncrypted = false;
590     for (const trailer of trailers) {
591       stream.pos = trailer;
592       const parser = new Parser({
593         lexer: new Lexer(stream),
594         xref: this,
595         allowStreams: true,
596         recoveryMode: true,
597       });
598       const obj = parser.getObj();
599       if (!isCmd(obj, "trailer")) {
600         continue;
601       }
602       // read the trailer dictionary
603       const dict = parser.getObj();
604       if (!(dict instanceof Dict)) {
605         continue;
606       }
607       trailerDicts.push(dict);
608 
609       if (dict.has("Encrypt")) {
610         isEncrypted = true;
611       }
612     }
613 
614     // finding main trailer
615     let trailerDict, trailerError;
616     for (const dict of [...trailerDicts, "genFallback", ...trailerDicts]) {
617       if (dict === "genFallback") {
618         if (!trailerError) {
619           break; // No need to fallback if there were no validation errors.
620         }
621         this._generationFallback = true;
622         continue;
623       }
624       // Do some basic validation of the trailer/root dictionary candidate.
625       let validPagesDict = false;
626       try {
627         const rootDict = dict.get("Root");
628         if (!(rootDict instanceof Dict)) {
629           continue;
630         }
631         const pagesDict = rootDict.get("Pages");
632         if (!(pagesDict instanceof Dict)) {
633           continue;
634         }
635         const pagesCount = pagesDict.get("Count");
636         if (Number.isInteger(pagesCount)) {
637           validPagesDict = true;
638         }
639         // The top-level /Pages dictionary isn't obviously corrupt.
640       } catch (ex) {
641         trailerError = ex;
642         continue;
643       }
644       // taking the first one with 'ID'
645       if (
646         validPagesDict &&
647         (!isEncrypted || dict.has("Encrypt")) &&
648         dict.has("ID")
649       ) {
650         return dict;
651       }
652       // The current dictionary is a candidate, but continue searching.
653       trailerDict = dict;
654     }
655     // No trailer with 'ID', taking last one (if exists).
656     if (trailerDict) {
657       return trailerDict;
658     }
659     // No trailer dictionary found, taking the "top"-dictionary (if exists).
660     if (this.topDict) {
661       return this.topDict;
662     }
663     // nothing helps
664     throw new InvalidPDFException("Invalid PDF structure.");
665   }
666 
988 }
989 
</code>

PR summary:
<pr_summary>
Avoid eagerly matching "trailer"-strings when searching for incomplete objects in `XRef.indexObjects` (issue 16759, PR 15854 follow-up, bug 1845762)
When searching for "endobj"-operators, make sure that we don't accidentally match a "trailer"-string in /Content-streams without /Filter-entries (i.e. streams that contain "raw" and thus human-readable data).
</pr_summary>

Your task:
You are a software tester at pdf.js.
1. Write exactly one javascript test `it("...", async () => {...})` block.
2. Your test must fail on the code before the patch, and pass after, hence the test will verify that the patch resolves the issue.
3. The test must be self-contained and to-the-point.
4. Use only the provided imports (respect the paths exactly how they are given) by importing dynamically for compatibility with Node.js — no new dependencies. 
5. Return only the javascript code (no comments or explanations).

Example structure:
it("should <describe behavior>", async () => {
  const { example } = await import("../../src/core/example.js");
  <initialize required variables>;
  <define expected variable>;
  <generate actual variables>;
  <compare expected with actual>;
});

