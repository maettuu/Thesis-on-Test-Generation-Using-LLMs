{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3bae4256-81bf-4682-8ef5-93d2dcd24b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdev=\"\"\"diff --git a/bugbug/db.py b/bugbug/db.py\n",
    "--- a/bugbug/db.py\n",
    "+++ b/bugbug/db.py\n",
    "@@ -22,6 +22,10 @@\n",
    " logger = logging.getLogger(__name__)\n",
    " \n",
    " \n",
    "+class LastModifiedNotAvailable(Exception):\n",
    "+    pass\n",
    "+\n",
    "+\n",
    " def register(path, url, version, support_files=[]):\n",
    "     DATABASES[path] = {\"url\": url, \"version\": version, \"support_files\": support_files}\n",
    " \n",
    "@@ -119,7 +123,7 @@\n",
    "     last_modified = utils.get_last_modified(url)\n",
    " \n",
    "     if last_modified is None:\n",
    "-        raise Exception(\"Last-Modified is not available\")\n",
    "+        raise LastModifiedNotAvailable()\n",
    " \n",
    "     return last_modified\n",
    " \n",
    "\n",
    "diff --git a/bugbug/phabricator.py b/bugbug/phabricator.py\n",
    "--- a/bugbug/phabricator.py\n",
    "+++ b/bugbug/phabricator.py\n",
    "@@ -12,6 +12,7 @@\n",
    " from tqdm import tqdm\n",
    " \n",
    " from bugbug import db\n",
    "+from bugbug.db import LastModifiedNotAvailable ###NOT COVERED###\n",
    " \n",
    " logger = logging.getLogger(__name__)\n",
    " \n",
    "@@ -146,9 +147,8 @@\n",
    " def download_modified_revisions():\n",
    "     try:\n",
    "         last_modified = db.last_modified(REVISIONS_DB)\n",
    "-    except Exception as e:\n",
    "-        if str(e) == \"Last-Modified is not available\":\n",
    "-            return\n",
    "+    except LastModifiedNotAvailable: ###NOT COVERED###\n",
    "+        return ###NOT COVERED###\n",
    " \n",
    "     modified_revisions = get(modified_start=last_modified)\n",
    "     modified_revision_ids = set(rev[\"id\"] for rev in modified_revisions)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "xdevai=\"\"\"diff --git a/bugbug/db.py b/bugbug/db.py\n",
    "--- a/bugbug/db.py\n",
    "+++ b/bugbug/db.py\n",
    "@@ -22,6 +22,10 @@\n",
    " logger = logging.getLogger(__name__)\n",
    " \n",
    " \n",
    "+class LastModifiedNotAvailable(Exception):\n",
    "+    pass\n",
    "+\n",
    "+\n",
    " def register(path, url, version, support_files=[]):\n",
    "     DATABASES[path] = {\"url\": url, \"version\": version, \"support_files\": support_files}\n",
    " \n",
    "@@ -119,7 +123,7 @@\n",
    "     last_modified = utils.get_last_modified(url)\n",
    " \n",
    "     if last_modified is None:\n",
    "-        raise Exception(\"Last-Modified is not available\")\n",
    "+        raise LastModifiedNotAvailable()\n",
    " \n",
    "     return last_modified\n",
    " \n",
    "\n",
    "diff --git a/bugbug/phabricator.py b/bugbug/phabricator.py\n",
    "--- a/bugbug/phabricator.py\n",
    "+++ b/bugbug/phabricator.py\n",
    "@@ -12,6 +12,7 @@\n",
    " from tqdm import tqdm\n",
    " \n",
    " from bugbug import db\n",
    "+from bugbug.db import LastModifiedNotAvailable\n",
    " \n",
    " logger = logging.getLogger(__name__)\n",
    " \n",
    "@@ -146,9 +147,8 @@\n",
    " def download_modified_revisions():\n",
    "     try:\n",
    "         last_modified = db.last_modified(REVISIONS_DB)\n",
    "-    except Exception as e:\n",
    "-        if str(e) == \"Last-Modified is not available\":\n",
    "-            return\n",
    "+    except LastModifiedNotAvailable:\n",
    "+        return\n",
    " \n",
    "     modified_revisions = get(modified_start=last_modified)\n",
    "     modified_revision_ids = set(rev[\"id\"] for rev in modified_revisions)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "46b20886-cfd9-4288-a672-6ef38dd6788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_for_comment_lines = []\n",
    "for (ldev, ldevai) in zip(xdev.splitlines(), xdevai.splitlines()):\n",
    "    if ldev!=ldevai:\n",
    "        patch_for_comment_lines.append(ldev.replace(\"###NOT COVERED###\", \"###ONLY COVERED BY ABOVE TEST###\"))\n",
    "    else:\n",
    "        patch_for_comment_lines.append(ldev)\n",
    "patch_for_comment = \"\\n\".join(patch_for_comment_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ceb6daa3-026e-4cb1-ae47-d26d417e6f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff --git a/bugbug/db.py b/bugbug/db.py\n",
      "--- a/bugbug/db.py\n",
      "+++ b/bugbug/db.py\n",
      "@@ -22,6 +22,10 @@\n",
      " logger = logging.getLogger(__name__)\n",
      " \n",
      " \n",
      "+class LastModifiedNotAvailable(Exception):\n",
      "+    pass\n",
      "+\n",
      "+\n",
      " def register(path, url, version, support_files=[]):\n",
      "     DATABASES[path] = {\"url\": url, \"version\": version, \"support_files\": support_files}\n",
      " \n",
      "@@ -119,7 +123,7 @@\n",
      "     last_modified = utils.get_last_modified(url)\n",
      " \n",
      "     if last_modified is None:\n",
      "-        raise Exception(\"Last-Modified is not available\")\n",
      "+        raise LastModifiedNotAvailable()\n",
      " \n",
      "     return last_modified\n",
      " \n",
      "\n",
      "diff --git a/bugbug/phabricator.py b/bugbug/phabricator.py\n",
      "--- a/bugbug/phabricator.py\n",
      "+++ b/bugbug/phabricator.py\n",
      "@@ -12,6 +12,7 @@\n",
      " from tqdm import tqdm\n",
      " \n",
      " from bugbug import db\n",
      "+from bugbug.db import LastModifiedNotAvailable ###ONLY COVERED BY ABOVE TEST###\n",
      " \n",
      " logger = logging.getLogger(__name__)\n",
      " \n",
      "@@ -146,9 +147,8 @@\n",
      " def download_modified_revisions():\n",
      "     try:\n",
      "         last_modified = db.last_modified(REVISIONS_DB)\n",
      "-    except Exception as e:\n",
      "-        if str(e) == \"Last-Modified is not available\":\n",
      "-            return\n",
      "+    except LastModifiedNotAvailable: ###ONLY COVERED BY ABOVE TEST###\n",
      "+        return ###ONLY COVERED BY ABOVE TEST###\n",
      " \n",
      "     modified_revisions = get(modified_start=last_modified)\n",
      "     modified_revision_ids = set(rev[\"id\"] for rev in modified_revisions)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(patch_for_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46302ed-9b27-4f88-aa57-b2cccb236302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ff8db2fc-2828-4fbe-9a0d-0d2d6e1f7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "#sys.path.append('/Users/konstantinos/local-desktop/swt-bench/') # TODO\n",
    "from webhook_handler.paper_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b5080fbc-b364-431e-8374-1d7983d0adf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'webhook_handler.paper_utils' from '/Users/konstantinos/local-desktop/github_bot/webhook_handler/paper_utils.py'>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import webhook_handler.paper_utils\n",
    "\n",
    "importlib.reload(webhook_handler.paper_utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7ac79fed-803b-4779-a390-5e4a1c662f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"myapp\")\n",
    "logger.debug(\"Entered webhook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3a80b0-9be7-4f49-b65a-96a7b78aeee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info = print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2961b5a-439f-419f-940c-c8067ea36f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fa34aec-a38f-4bcf-9612-eb7f6368837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import difflib\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "def get_function_definitions(source: str) -> dict:\n",
    "    \"\"\"Extract function and method definitions from the source code - only for functions starting with test*\"\"\"\n",
    "    tree = ast.parse(source)\n",
    "    functions = {}\n",
    "    \n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "            function_name = node.name\n",
    "            if function_name.startswith('test'):\n",
    "                function_body = ast.get_source_segment(source, node)\n",
    "                functions[function_name] = function_body\n",
    "    \n",
    "    return functions\n",
    "\n",
    "def find_changed_functions(old_source: str, new_source: str) -> List[str]:\n",
    "    \"\"\"Find functions that have changed between two versions of a Python file.\"\"\"\n",
    "    old_funcs = get_function_definitions(old_source)\n",
    "    new_funcs = get_function_definitions(new_source)\n",
    "    \n",
    "    changed_functions = []\n",
    "    \n",
    "    for func_name, new_body in new_funcs.items():\n",
    "        old_body = old_funcs.get(func_name)\n",
    "        if old_body is None:\n",
    "            # Function is new\n",
    "            changed_functions.append(func_name)\n",
    "        elif old_body and old_body != new_body:\n",
    "            # Function exists but has changed\n",
    "            diff = list(difflib.unified_diff(old_body.splitlines(), new_body.splitlines()))\n",
    "            if diff:\n",
    "                changed_functions.append(func_name)\n",
    "    \n",
    "    return changed_functions\n",
    "\n",
    "def extract_functions_and_methods(source: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Extracts global function names and class methods from Python source code.\n",
    "    \n",
    "    :param source: A string containing Python source code.\n",
    "    :return: A dictionary mapping function/method names to \"global\" or their class name.\n",
    "    \"\"\"\n",
    "    tree = ast.parse(source)\n",
    "    result = {}\n",
    "    \n",
    "    for node in tree.body:\n",
    "        if isinstance(node, ast.FunctionDef):\n",
    "            # Global function\n",
    "            \n",
    "            result[node.name] = \"global\"\n",
    "        elif isinstance(node, ast.ClassDef):\n",
    "            # Class with methods\n",
    "            class_name = node.name\n",
    "            for sub_node in node.body:\n",
    "                if isinstance(sub_node, ast.FunctionDef):\n",
    "                    # Method inside the class\n",
    "                    result[sub_node.name] = class_name\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ae4e89e-4450-4cf3-98da-bc549c437e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "import sys\n",
    "import re\n",
    "\n",
    "def read_dockerfile(commit_hash, dockerfile_path=\"Dockerfile\"):\n",
    "    \"\"\"Reads the Dockerfile, replaces the commit hash, and returns the modified content.\"\"\"\n",
    "    with open(dockerfile_path, \"r\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Replace the commit hash dynamically\n",
    "    content = content.replace(\"RUN git checkout <commit_hash>\", f\"RUN git checkout {commit_hash}\")\n",
    "\n",
    "    return content\n",
    "\n",
    "def build_docker_image(commit_hash, image_tag=\"bugbug_image\", dockerfile_path=\"Dockerfile\"):\n",
    "    \"\"\"Builds a Docker image using the Python Docker SDK.\"\"\"\n",
    "    client = docker.from_env()\n",
    "\n",
    "    # Read the modified Dockerfile content\n",
    "    dockerfile_content = read_dockerfile(commit_hash, dockerfile_path)\n",
    "\n",
    "    # Write a temporary Dockerfile (this avoids modifying the original file)\n",
    "    temp_dockerfile = \"Dockerfile.temp\"\n",
    "    with open(temp_dockerfile, \"w\") as f:\n",
    "        f.write(dockerfile_content)\n",
    "\n",
    "    print(f\"[*] Using commit hash: {commit_hash}\")\n",
    "    \n",
    "    # Build the Docker image\n",
    "    try:\n",
    "        image, build_logs = client.images.build(path=\".\", \n",
    "                                                tag=image_tag, \n",
    "                                                dockerfile=temp_dockerfile,\n",
    "                                                network_mode=\"host\")\n",
    "\n",
    "        # Print build logs\n",
    "        for log in build_logs:\n",
    "            if \"stream\" in log:\n",
    "                print(log[\"stream\"].strip())\n",
    "\n",
    "        print(f\"[+] Docker image '{image_tag}' built successfully.\")\n",
    "    except docker.errors.BuildError as e:\n",
    "        print(f\"[!] Build failed: {e}\")\n",
    "        sys.exit(1)\n",
    "    except docker.errors.APIError as e:\n",
    "        print(f\"[!] Docker API error: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc345bb6-2535-4031-8b27-caa4b4de0837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import tarfile\n",
    "import io\n",
    "def run_test_in_container(image_tag, model_test_patch, test_to_run, golden_code_patch=None):\n",
    "    \"\"\"Creates a container, applies the patch, runs the test, and returns the result.\"\"\"\n",
    "    client = docker.from_env()\n",
    "\n",
    "    # Create a temporary patch file\n",
    "    with tempfile.NamedTemporaryFile(delete=False, mode=\"w\") as patch_file:\n",
    "        patch_file.write(model_test_patch)\n",
    "        patch_file_path = patch_file.name\n",
    "\n",
    "    try:\n",
    "        logger.info(\"[*] Creating container...\")\n",
    "        container = client.containers.create(\n",
    "            image=image_tag,\n",
    "            command=\"/bin/sh -c 'sleep infinity'\",  # Keep the container running\n",
    "            tty=True,  # Allocate a TTY for interactive use\n",
    "            detach=True\n",
    "        )\n",
    "\n",
    "        container.start()\n",
    "        logger.info(f\"[+] Container {container.short_id} started.\")\n",
    "\n",
    "        #### A) Test patch (Always)\n",
    "        model_test_patch_fname = \"test_patch.diff\"\n",
    "        patch_dest_path = f\"/app/bugbug/{model_test_patch_fname}\"\n",
    "        # Create a tar archive\n",
    "        tar_stream = io.BytesIO()\n",
    "        with tarfile.open(fileobj=tar_stream, mode=\"w\") as tar:\n",
    "            tar.add(patch_file_path, arcname=model_test_patch_fname)\n",
    "        tar_stream.seek(0)\n",
    "        # Copy the tar archive to the container\n",
    "        container.put_archive(\"/app/bugbug\", tar_stream.getvalue())\n",
    "        print(f\"[+] Patch file copied to {patch_dest_path}\")\n",
    "\n",
    "        \n",
    "\n",
    "        # Apply the patch inside the container\n",
    "        apply_patch_cmd = f\"/bin/sh -c 'cd /app/bugbug && git apply {model_test_patch_fname}'\"\n",
    "        exec_result = container.exec_run(apply_patch_cmd)\n",
    "\n",
    "        if exec_result.exit_code != 0:\n",
    "            print(f\"[!] Failed to apply patch: {exec_result.output.decode()}\")\n",
    "            return \"ERROR\", exec_result.output.decode()\n",
    "\n",
    "        print(\"[+] Test patch applied successfully.\")\n",
    "\n",
    "\n",
    "        if golden_code_patch is not None:\n",
    "\n",
    "            # Create a temporary patch file\n",
    "            with tempfile.NamedTemporaryFile(delete=False, mode=\"w\") as patch_file:\n",
    "                patch_file.write(golden_code_patch)\n",
    "                patch_file_path = patch_file.name\n",
    "        \n",
    "            #### B) Model patch (Only in post-PR code)\n",
    "            golden_code_patch_fname = \"golden_code_patch.diff\"\n",
    "            patch_dest_path = f\"/app/bugbug/{golden_code_patch_fname}\"\n",
    "            # Create a tar archive\n",
    "            tar_stream = io.BytesIO()\n",
    "            with tarfile.open(fileobj=tar_stream, mode=\"w\") as tar:\n",
    "                tar.add(patch_file_path, arcname=golden_code_patch_fname)\n",
    "            tar_stream.seek(0)\n",
    "            # Copy the tar archive to the container\n",
    "            container.put_archive(\"/app/bugbug\", tar_stream.getvalue())\n",
    "            logger.info(f\"[+] Patch file copied to {patch_dest_path}\")\n",
    "\n",
    "            # Apply the patch inside the container\n",
    "            apply_patch_cmd = f\"/bin/sh -c 'cd /app/bugbug && git apply {golden_code_patch_fname}'\"\n",
    "            exec_result = container.exec_run(apply_patch_cmd)\n",
    "    \n",
    "            if exec_result.exit_code != 0:\n",
    "                logger.info(f\"[!] Failed to apply patch: {exec_result.output.decode()}\")\n",
    "                return \"ERROR\", exec_result.exit_code\n",
    "    \n",
    "            logger.info(\"[+] Code patch applied successfully.\")\n",
    "\n",
    "        # Run the test command\n",
    "        coverage_report_separator = \"COVERAGE_REPORT_STARTING_HERE\"\n",
    "        test_command = (\n",
    "            \"/bin/sh -c 'cd /app/bugbug && \"\n",
    "            f\"coverage run --branch -m pytest -rA -vv -o console_output_style=classic --tb=no {test_to_run} ; \" # Here we use \";\" instead of \"&&\" so that the next command runs even if the test fails\n",
    "            \"coverage report -m > coverage_report.txt && \"\n",
    "            f\"echo '{coverage_report_separator}' && \"\n",
    "            \"cat coverage_report.txt'\"\n",
    "        )\n",
    "        exec_result = container.exec_run(test_command, stdout=True, stderr=True)\n",
    "        stdout_output_all = exec_result.output.decode()\n",
    "        stdout, coverage_report = stdout_output_all.split(coverage_report_separator)\n",
    "\n",
    "        logger.info(\"[+] Test command executed.\")\n",
    "\n",
    "        # Determine PASS/FAIL from output\n",
    "        if \"PASSED\" in stdout:\n",
    "            test_result = \"PASS\"\n",
    "        else:\n",
    "            test_result = \"FAIL\"\n",
    "\n",
    "        logger.info(f\"[+] Test result: {test_result}\")\n",
    "\n",
    "        return test_result, stdout, coverage_report\n",
    "\n",
    "    finally:\n",
    "        # Cleanup\n",
    "        os.remove(patch_file_path)\n",
    "        container.stop()\n",
    "        container.remove()\n",
    "        logger.info(\"[*] Container stopped and removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af743992-3ba7-47e6-99fc-71a8ebd61992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "#GITHUB_API_URL = f\"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/pulls\"\n",
    "HEADERS = {\n",
    "    \"Accept\": \"application/vnd.github.v3+json\",\n",
    "    \"Authorization\": \"Bearer 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\"\n",
    "}\n",
    "\n",
    "def fetch_pr_files(pr_number, repo_owner, repo_name):\n",
    "    url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/pulls/{pr_number}/files\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    if response.status_code == 403 and \"X-RateLimit-Reset\" in response.headers:\n",
    "        reset_time = int(response.headers[\"X-RateLimit-Reset\"])\n",
    "        wait_time = reset_time - int(time.time()) + 1\n",
    "        print(f\"Rate limit exceeded. Waiting for {wait_time} seconds...\")\n",
    "        time.sleep(max(wait_time, 1))\n",
    "        return fetch_pr_files(pr_number)\n",
    "        \n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186cf325-dd37-4817-8d89-763748c23efc",
   "metadata": {},
   "source": [
    "# GAME ON Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f38fe3-f866-46a0-89c7-dc00685d9d5b",
   "metadata": {},
   "source": [
    "# TODO: 1 test for generation and 1 for amplification\n",
    "I need two real PRs, \n",
    "- one that contains a test with <100% and the model generates a coverage-increasing test (maybe cache it)\n",
    "- the same PR where no test is included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e37048d-ea02-4108-af15-6267e699fb29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fd1def1-5bb5-4d49-a92e-bf9340ccc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/konstantinos/local-desktop/swebench_repos/bugbug_experiments/webhook_2025-02-05_16-02-39.json') as f: # no issue\n",
    "with open('/Users/konstantinos/local-desktop/swebench_repos/bugbug_experiments/webhook_2025-02-05_16-46-09.json') as f:\n",
    "    payload = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cacc72d0-2726-4a5e-8a61-5bd2b0864513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edited'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload[\"action\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32e915d5-7dd5-42f0-9d95-b78c19b13d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from payload\n",
    "pr_number      = payload[\"pull_request\"][\"number\"]\n",
    "pr_title       = payload[\"pull_request\"][\"title\"]\n",
    "pr_description = payload[\"pull_request\"][\"body\"]\n",
    "pr_url         = payload[\"pull_request\"][\"url\"]\n",
    "owner          = payload[\"repository\"][\"owner\"][\"login\"]\n",
    "repo           = payload[\"repository\"][\"name\"]\n",
    "diff           = payload[\"pull_request\"][\"diff_url\"] # patch\n",
    "base_branch    = payload[\"pull_request\"][\"base\"][\"ref\"]\n",
    "base_commit    = payload[\"pull_request\"][\"base\"][\"sha\"]\n",
    "head_branch    = payload[\"pull_request\"][\"head\"][\"ref\"]\n",
    "head_commit    = payload[\"pull_request\"][\"head\"][\"sha\"]\n",
    "instance_id    = f\"{owner}__{repo}-{pr_number}\"\n",
    "\n",
    "if pr_description is None:\n",
    "    pr_description = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b95dd1d8-ac06-4504-a5eb-450a90ebf337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file contents from the github API (we could also get them by cloning the repo in the docker)\n",
    "files = fetch_pr_files(pr_number, owner, repo)\n",
    "\n",
    "code_fname_arr = []\n",
    "code_content_before_arr = []\n",
    "code_content_after_arr  = []\n",
    "test_fname_arr = []\n",
    "test_content_before_arr = []\n",
    "test_content_after_arr  = []\n",
    "at_least_one_python_code_file = False\n",
    "for file_dict in files:\n",
    "    fname = file_dict[\"filename\"]\n",
    "    after_url = file_dict[\"raw_url\"]\n",
    "    response_after = requests.get(after_url, headers=HEADERS)\n",
    "    if response_after.status_code == 200:\n",
    "        content_after = response_after.text\n",
    "    else:\n",
    "        content_after = \"\" # probably file deleted\n",
    "    \n",
    "    before_url = f\"https://github.com/{owner}/{repo}/raw/{base_commit}/{fname}\"\n",
    "    response_before = requests.get(before_url, headers=HEADERS)\n",
    "    if response_before.status_code == 200:\n",
    "        content_before = response_before.text\n",
    "    else:\n",
    "        content_before = \"\" # probably file deleted\n",
    "\n",
    "    if is_test_file(fname):\n",
    "        test_fname_arr.append(fname)\n",
    "        test_content_before_arr.append(content_before)\n",
    "        test_content_after_arr.append(content_after)\n",
    "    else:\n",
    "        code_fname_arr.append(fname)\n",
    "        code_content_before_arr.append(content_before)\n",
    "        code_content_after_arr.append(content_after)\n",
    "        if fname.endswith(\".py\") and not at_least_one_python_code_file:\n",
    "            at_least_one_python_code_file = True\n",
    "\n",
    "if not at_least_one_python_code_file: # if the PR changed only non-python files return\n",
    "    logger.info(\"No .py code files (except maybe for test) were modified, skipping\")\n",
    "\n",
    "# If test file already exists, we do amplification, otherwise generation\n",
    "contains_test_file = len(test_fname_arr) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4edc885-bec5-4b40-9087-25840f07b30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contains_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e762f690-0052-42ad-a0f2-350b7b597f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create golden code patch\n",
    "diffs = []\n",
    "for (fname, fcontent_before, fcontent_after) in zip(code_fname_arr, code_content_before_arr, code_content_after_arr):\n",
    "\n",
    "    diff = unified_diff(fcontent_before, fcontent_after, fromfile=fname, tofile=fname)\n",
    "    diffs.append(diff)\n",
    "\n",
    "golden_code_patch = \"\\n\".join(diffs)+\"\\n\"\n",
    "\n",
    "# Create golden test patch\n",
    "diffs = []\n",
    "for (fname, fcontent_before, fcontent_after) in zip(test_fname_arr, test_content_before_arr, test_content_after_arr):\n",
    "\n",
    "    diff = unified_diff(fcontent_before, fcontent_after, fromfile=fname, tofile=fname)\n",
    "    diffs.append(diff)\n",
    "\n",
    "golden_test_patch = \"\\n\".join(diffs)+\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c5db389d-5fea-479b-8610-da69c7425dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Skipped patch 'a_bugbug_code_search_searchfox_api.py'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Slice golden files\n",
    "if code_fname_arr: # sometimes all the changes are counted as tests e.g., test_test_scheduling.py\n",
    "    code_content_before_sliced_arr = slice_golden_file(\n",
    "        code_content_before_arr, \n",
    "        golden_code_patch,\n",
    "        \"\",\n",
    "        return_file=\"pre\",\n",
    "        append_line_numbers=True\n",
    "        )\n",
    "else:\n",
    "    code_content_before_sliced_arr = code_content_before_arr.copy()\n",
    "\n",
    "if test_fname_arr: # sometimes there are no tests\n",
    "    test_content_after_sliced_arr = slice_golden_file(\n",
    "        test_content_before_arr, \n",
    "        golden_test_patch,\n",
    "        \"\",\n",
    "        return_file=\"post\",\n",
    "        append_line_numbers=True\n",
    "        )\n",
    "else:\n",
    "    test_content_after_sliced_arr = test_content_before_arr.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a698dbf5-77b4-4578-9488-6a44a3bf483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webhook_handler.views import check_if_has_linked_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "534410b4-a6de-47b9-b6f4-6a7764f86c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked with issue #2\n"
     ]
    }
   ],
   "source": [
    "# Check if the PR is linked to a GH Issue\n",
    "has_linked_issue, linked_issue, issue_title, issue_description = check_if_has_linked_issue(pr_description, owner, repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58790d58-a47e-497c-8c2c-6f2381a88ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Creating container...\n",
      "[+] Container 3cc534951509 started.\n",
      "[+] Patch file copied to /app/bugbug/test_patch.diff\n",
      "[+] Test patch applied successfully.\n",
      "[+] Patch file copied to /app/bugbug/golden_code_patch.diff\n",
      "[+] Code patch applied successfully.\n",
      "[+] Test command executed.\n",
      "[+] Test result: FAIL\n",
      "[*] Container stopped and removed.\n"
     ]
    }
   ],
   "source": [
    "golden_test_patch = model_test_patch # REMOVE\n",
    "if contains_test_file or True: # REMOVE\n",
    "\n",
    "    assert golden_test_patch.strip(), \"In test amplification mode with empty developer test patch\"\n",
    "    \n",
    "    # We give the whole patch to apply to create the post-PR environment\n",
    "    test_result, stdout, coverage_report = run_test_in_container(image_tag, golden_test_patch, test_to_run, golden_code_patch=golden_code_patch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673c4989-c6c0-402e-8cbc-35536f98028a",
   "metadata": {},
   "source": [
    "# Test amplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "645dc173-cdb3-45ae-a014-9a342c186c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_files = extract_edited_files(golden_code_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cda4dcd0-ceb1-4502-a379-96b06784dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply the patch instead of using the existing \"after\" array to also capture the offset of the patch\n",
    "code_content_after_arr_from_patch, stderr = apply_patch(code_content_before_arr, golden_code_patch)\n",
    "try:\n",
    "    offsets = extract_offsets_from_stderr(stderr)\n",
    "except AssertionError as e:\n",
    "    print(\"Different offsets in a single file for, skipping\")\n",
    "    #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "da48e226-3b8c-4728-8384-c8ca7ca77837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-tuple of the form (line, line_no, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aa71b657-f37a-457d-b482-7968121c0f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('f\"https://searchfox.org/mozilla-central/search?q=symbol:{symbol_name}\",',\n",
       "  95,\n",
       "  'bugbug/code_search/searchfox_api.py')]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_number_of_edited_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8827b70d-5349-457f-85d7-27ae1af7dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missed_lines_and_decorate_patch(edited_files, code_content_before_arr, code_content_after_arr, golden_code_patch, offsets, coverage_report):\n",
    "    # In code_after_labeled, we will label every line that is not covered with a \n",
    "    # comment: \"# NOT COVERED\"\n",
    "    code_after_labeled_arr    = []\n",
    "    modified_and_missed_lines = []\n",
    "    \n",
    "    for (edited_file, code_after, offset, ii) in zip(edited_files, code_content_after_arr, offsets, range(len(edited_files))):\n",
    "        code_after_labeled = code_after.splitlines()\n",
    "        \n",
    "        this_file_coverage = [l for l in coverage_report.splitlines() if l.startswith(edited_file)]\n",
    "        if not this_file_coverage:\n",
    "            # #print(\"No data to report in test_coverage.txt for %s, probably all lines are covered\" % edited_file)\n",
    "            # All lines where covered for this file so we just appened the initial contents\n",
    "            # without any decoration\n",
    "            code_after_labeled_arr.append(\"\\n\".join(code_after_labeled))\n",
    "            continue\n",
    "        else:\n",
    "            this_file_coverage = this_file_coverage[0]\n",
    "    \n",
    "    \n",
    "        line_range_str = this_file_coverage.split('%')[-1]\n",
    "        \n",
    "        missed_lines, missed_branches = parse_missed_lines_and_branches(line_range_str)\n",
    "        line_number_of_edited_lines = get_line_number_of_edited_lines(golden_code_patch)\n",
    "        for (line, line_no, line_file) in line_number_of_edited_lines:\n",
    "            if line_file == edited_file:\n",
    "                # + offset because of fuzzy diff | -1 because it's 1-indexed\n",
    "                line_no_adjusted = line_no+offset-1\n",
    "                # print(line)\n",
    "                # print(code_after.splitlines()[line_no_adjusted].strip())\n",
    "                # print(\"=========\")\n",
    "                assert line == code_after.splitlines()[line_no_adjusted].strip(), \"Line mismatch\"\n",
    "                # Make it 1-indexed again\n",
    "                if line_no_adjusted+1 in missed_lines:\n",
    "                    modified_and_missed_lines.append(code_after.splitlines()[line_no_adjusted].strip()) # here it's 0-indexed\n",
    "                    code_after_labeled[line_no_adjusted] = code_after_labeled[line_no_adjusted] + \" ###NOT COVERED###\"\n",
    "    \n",
    "        \n",
    "        code_after_labeled_arr.append(\"\\n\".join(code_after_labeled))\n",
    "    \n",
    "        \n",
    "        golden_patch_labeled = \"\"\n",
    "        for (c, c_labeled, fname) in zip(code_content_before_arr, code_after_labeled_arr, edited_files):\n",
    "            \n",
    "            golden_patch_labeled += unified_diff(c, \n",
    "                                         c_labeled, \n",
    "                                         fromfile=fname, \n",
    "                                         tofile=fname) + \"\\n\"\n",
    "        \n",
    "        decorated_patch = golden_patch_labeled\n",
    "\n",
    "    # if modified_and_missed_lines is empty, golden_patch_labeled is the same as golden_patch\n",
    "    return modified_and_missed_lines, golden_patch_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9a58c206-f981-476f-bd66-ad2686804660",
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_lines_dev, decorated_patch = get_missed_lines_and_decorate_patch(edited_files, code_content_before_arr, code_content_after_arr_from_patch, golden_code_patch, offsets, coverage_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5f13ea00-d654-4c9b-bee6-3a27527a9b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(missed_lines_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a9ad666d-1527-48f2-98aa-fe63dfda66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt\n",
    "include_issue_description = True\n",
    "include_golden_code       = True\n",
    "sliced                    = \"LongCorr\" # LongCorr or No\n",
    "include_issue_comments    = False\n",
    "include_pr_desc           = True\n",
    "\n",
    "# These signify amplification instead of generation\n",
    "include_golden_test_code = True\n",
    "test_code_sliced         = True\n",
    "include_uncovered_lines_by_dvlpr_test = True\n",
    "\n",
    "instance = {}\n",
    "instance[\"instance_id\"] = instance_id\n",
    "instance[\"patch\"] = golden_code_patch\n",
    "instance[\"golden_test_names\"] = test_fname_arr\n",
    "instance[\"golden_test_contents\"] = test_content_after_arr\n",
    "instance[\"golden_test_contents_sliced\"] = test_content_after_sliced_arr # TODO: slice it first\n",
    "instance[\"patch_labeled\"] = golden_code_patch # TODO: label it first\n",
    "instance[\"problem_statement\"] = issue_description\n",
    "instance[\"hints_text\"] = \"\"\n",
    "instance[\"golden_code_names\"] = code_fname_arr\n",
    "instance[\"golden_code_contents\"] = code_content_before_arr\n",
    "instance[\"golden_code_contents_sliced_long\"] = code_content_before_sliced_arr\n",
    "instance[\"title\"] = pr_title\n",
    "instance[\"description\"] = pr_description\n",
    "instance[\"base_commit\"] = base_commit\n",
    "instance[\"patch_labeled\"] = decorated_patch\n",
    "\n",
    "prompt = build_prompt(instance,\n",
    "                    include_issue_description=include_issue_description,\n",
    "                    include_golden_code=include_golden_code, \n",
    "                    sliced=sliced, \n",
    "                    include_issue_comments=include_issue_comments, \n",
    "                    include_pr_desc=include_pr_desc,\n",
    "                    include_golden_test_code=include_golden_test_code,\n",
    "                    test_code_sliced=test_code_sliced,\n",
    "                    include_uncovered_lines_by_dvlpr_test=include_uncovered_lines_by_dvlpr_test\n",
    "                    )\n",
    "\n",
    "if len(prompt)>=1048576: # gpt4o limit (can I get it from a config or sth?)\n",
    "    print(\"Prompt exceeds limits, skipping...\")\n",
    "    raise ValueError(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33d6ca-5062-41d7-9ce9-8f435603b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Query model\n",
    "# model = \"gpt-4o\"\n",
    "# T     = 0.0\n",
    "# response = query_model(prompt, model=model, T=T)\n",
    "\n",
    "# new_test = response.replace('```python', '')\n",
    "# new_test = new_test.replace('```', '')\n",
    "# new_test = adjust_function_indentation(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9018a96e-1734-49e4-b14a-db08d787802d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef test_search_with_symbol_prefix():\\n    from bugbug.code_search.searchfox_api import search\\n    from unittest.mock import patch\\n    import requests\\n\\n    # Mock the response from the searchfox API\\n    mock_response = requests.Response()\\n    mock_response.status_code = 200\\n    mock_response._content = b\\'var results = {\"normal\": {\"Definitions (symbol_name)\": [{\"path\": \"some/path\"}]}};\\\\n\\'\\n\\n    with patch(\\'bugbug.utils.get_session\\') as mock_get_session:\\n        mock_get_session.return_value.get.return_value = mock_response\\n\\n        # Call the search function with a symbol name\\n        result = search(\"dummy_commit_hash\", \"symbol_name\")\\n\\n        # Check if the correct URL was called\\n        mock_get_session.return_value.get.assert_called_with(\\n            \"https://searchfox.org/mozilla-central/search?q=symbol:symbol_name\",\\n            headers={\"User-Agent\": mock.ANY}\\n        )\\n\\n        # Verify the result\\n        assert result == []  # Assuming get_functions returns an empty list for simplicity'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f41112f8-ab67-4e27-a138-f71d532a70df",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_changed_func_or_class, most_similar_file, success = get_best_file_to_inject_golden(test_content_before_arr, test_content_after_arr, test_fname_arr, new_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d0523b47-af68-4b47-b29b-810b3420d7b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m         insert_in_class\u001b[38;5;241m=\u001b[39mmost_similar_changed_func_or_class[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Grab the first test file and insert at the end\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     most_similar_file \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mxx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_content_before_arr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m     insert_in_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOCLASS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m most_similar_file_idx \u001b[38;5;241m=\u001b[39m golden_test_file_arr\u001b[38;5;241m.\u001b[39mindex(most_similar_file)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    if not most_similar_changed_func_or_class:\n",
    "        # it may be the case that a global variable holding parameterization values\n",
    "        # for a test was changed (see astropy__astropy-12907)\n",
    "        # In this case, append to the end\n",
    "        insert_in_class=\"NOCLASS\"\n",
    "        print(\"Never goes in here anymore I think\")\n",
    "    elif most_similar_changed_func_or_class[0] == 'function':\n",
    "        insert_in_class=\"NOCLASS\"\n",
    "    else:\n",
    "        insert_in_class=most_similar_changed_func_or_class[1]\n",
    "else:\n",
    "    # Grab the first test file and insert at the end\n",
    "    most_similar_file = [xx for xx in test_content_before_arr if xx.split('/')[-1].startswith('test') and xx.endswith('.py')][0]\n",
    "    insert_in_class=\"NOCLASS\"\n",
    "\n",
    "most_similar_file_idx = golden_test_file_arr.index(most_similar_file)\n",
    "golden_test_content = test_content_before_arr[most_similar_file_idx]\n",
    "golden_test_content_after = test_content_after_arr[most_similar_file_idx]\n",
    "\n",
    "# Add the model test on top of the developer test to measure difference\n",
    "new_test_file_contents = append_function(golden_test_content_after, new_test, insert_in_class=insert_in_class)\n",
    "\n",
    "model_test_patch = \"\"\n",
    "for (test_filename, test_code, test_code_after_patch, ii) in zip(golden_test_file_arr, golden_test_content_arr, golden_test_content_after_patch_arr, range(len(golden_test_file_arr))):\n",
    "    if ii == most_similar_file_idx:\n",
    "        model_test_patch += unified_diff(test_code, \n",
    "                         new_test_file_contents, \n",
    "                         fromfile=test_filename, \n",
    "                         tofile=test_filename, \n",
    "                         context_lines=40) + \"\\n\"\n",
    "    else:\n",
    "        model_test_patch += unified_diff(test_code, \n",
    "                         test_code_after_patch, \n",
    "                         fromfile=test_filename, \n",
    "                         tofile=test_filename, \n",
    "                         context_lines=40) + \"\\n\"\n",
    "                         # we need to write many context lines in the file because the edited\n",
    "                         # function name must appear in order for TDD-Bench to run the test\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a789f29a-e4fc-471b-831d-019ee4aa13e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Creating container...\n",
      "[+] Container 845d320c56db started.\n",
      "[+] Patch file copied to /app/bugbug/test_patch.diff\n",
      "[+] Test patch applied successfully.\n",
      "[+] Patch file copied to /app/bugbug/golden_code_patch.diff\n",
      "[+] Code patch applied successfully.\n",
      "[+] Test command executed.\n",
      "[+] Test result: FAIL\n",
      "[*] Container stopped and removed.\n"
     ]
    }
   ],
   "source": [
    "# We give the whole patch to apply to create the post-PR environment\n",
    "test_result_dev_and_ai, stdout_dev_and_ai, coverage_report_dev_and_ai = run_test_in_container(image_tag, model_test_patch, test_to_run, golden_code_patch=golden_code_patch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9ad7575f-290d-462b-82a8-01d22e30d713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_lines_dev # this is only for developer tests (and must be non-empty if we are doing amplification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "15eb82bc-110d-4eb2-85f7-06cc3e573bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_lines_dev_and_ai, _ = get_missed_lines_and_decorate_patch(edited_files, code_content_before_arr, code_content_after_arr_from_patch, golden_code_patch, offsets, coverage_report_dev_and_ai)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d27b5d6c-d895-40a2-bcad-3c89e6b81976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_lines_dev_and_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9a57800a-e72e-422c-a7a4-3e6a6d6956dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lines modified by the developer code patch\n",
    "modified_lines = [l[1:].strip() for l in golden_code_patch.splitlines() if l.startswith('+') and not l.startswith('+++')]\n",
    "n_modified = len(modified_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9141ed2e-13fb-498b-a2c7-d08f5edaf9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lines = set(missed_lines_dev) - set(missed_lines_dev_and_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b7f5d6eb-9bb5-4e57-b615-2d4572ccc132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new lines covered by AI\n"
     ]
    }
   ],
   "source": [
    "if len(new_lines) > 0:\n",
    "    print(\"These lines were missed by the developer test by covered by the AI test:\\n%s\" % \"\\n\".join(new_lines))\n",
    "    coverage_dev = (n_modified-len(set(missed_lines_dev)))/n_modified\n",
    "    coverage_dev_and_ai = (n_modified-len(set(missed_lines_dev_and_ai)))/n_modified\n",
    "    print(\"Coverage before: %0.2f\\nCoverage after: %0.2f\\n\" % (coverage_dev, coverage_dev_and_ai))\n",
    "else:\n",
    "    print(\"No new lines covered by AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6ea53-b0d3-42d1-9298-e2fcdd5a715e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a51880a-9578-49cc-aae4-abee67de2eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "209da6a9-e570-49f3-b0fb-89a5146e5a53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be1e08-fea8-482e-a56c-b2cdb17c276e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aff0ea-5ec4-4a11-b640-fd3c556d3ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed9e5f9-f9fe-454c-b556-74b3b3a76f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6805555-9789-45a5-8eae-b095647f0400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5d177b0-287f-4b68-b076-87e0ca7eb2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt\n",
    "include_issue_description = True\n",
    "include_golden_code       = True\n",
    "sliced                    = \"LongCorr\" # LongCorr or No\n",
    "include_issue_comments    = False\n",
    "include_pr_desc           = True\n",
    "\n",
    "if contains_test_file:\n",
    "    include_golden_test_code = True\n",
    "    test_code_sliced         = True\n",
    "    include_uncovered_lines_by_dvlpr_test = True\n",
    "\n",
    "instance = {}\n",
    "instance[\"instance_id\"] = instance_id\n",
    "instance[\"patch\"] = golden_code_patch\n",
    "instance[\"golden_test_names\"] = test_fname_arr\n",
    "instance[\"golden_test_contents\"] = test_content_after_arr\n",
    "instance[\"golden_test_contents_sliced\"] = test_content_after_sliced_arr # TODO: slice it first\n",
    "instance[\"patch_labeled\"] = golden_code_patch # TODO: label it first\n",
    "instance[\"problem_statement\"] = issue_description\n",
    "instance[\"hints_text\"] = \"\"\n",
    "instance[\"golden_code_names\"] = code_fname_arr\n",
    "instance[\"golden_code_contents\"] = code_content_before_arr\n",
    "instance[\"golden_code_contents_sliced_long\"] = code_content_before_sliced_arr\n",
    "instance[\"title\"] = pr_title\n",
    "instance[\"description\"] = pr_description\n",
    "instance[\"base_commit\"] = base_commit\n",
    "\n",
    "prompt = build_prompt(instance, # TODO\n",
    "                       include_issue_description=include_issue_description,\n",
    "                       include_golden_code=include_golden_code, \n",
    "                       sliced=sliced, \n",
    "                       include_issue_comments=include_issue_comments, \n",
    "                       include_pr_desc=include_pr_desc,\n",
    "                     )\n",
    "\n",
    "if len(prompt)>=1048576: # gpt4o limit\n",
    "    print(\"Prompt exceeds limits, skipping...\")\n",
    "    raise ValueError(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d48dca97-a9e7-4a9b-8ff5-7d682841adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query model\n",
    "model = \"gpt-4o\"\n",
    "T     = 0.0\n",
    "response = query_model(prompt, model=model, T=T)\n",
    "\n",
    "new_test = response.replace('```python', '')\n",
    "new_test = new_test.replace('```', '')\n",
    "new_test = adjust_function_indentation(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6a720df-e31e-48f5-9bdf-00e0d4163f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests/test_repository.py\n"
     ]
    }
   ],
   "source": [
    "# Run history injection to inject the file\n",
    "tmp_repo_dir = \"tmp_repo_dir\"\n",
    "res = subprocess.run([\"git\", \"clone\", f\"https://github.com/{owner}/{repo}.git\", tmp_repo_dir], capture_output=True, check=True)\n",
    "\n",
    "try:\n",
    "    test_filename, test_file_content, new_test_file_content = inject_test(instance, tmp_repo_dir, new_test)\n",
    "    test_filename = test_filename.replace(tmp_repo_dir+'/', '')\n",
    "finally:\n",
    "    res = subprocess.run([\"rm\", \"-rf\", tmp_repo_dir], capture_output=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "094c4902-5467-453b-bbac-0557b45ae576",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_patch = unified_diff(test_file_content, new_test_file_content, fromfile=test_filename, tofile=test_filename)+\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82d06023-bf77-44ab-a64c-e014ead7bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract string of the type fname::class::method\n",
    "func2class             = extract_functions_and_methods(new_test_file_content)\n",
    "contributing_functions = find_changed_functions(test_file_content, new_test_file_content)\n",
    "func2test_arr           = []\n",
    "if contributing_functions:\n",
    "    for func in contributing_functions:\n",
    "        scope = func2class.get(func, \"\")\n",
    "        if scope == \"\":\n",
    "            #print(\"Empty scope in ii=%d\" % ii)\n",
    "            pass\n",
    "        elif scope == \"global\":\n",
    "            func2test_arr.append(f\"{test_filename}::{func}\")\n",
    "        else: # class scope\n",
    "            func2test_arr.append(f\"{test_filename}::{scope}::{func}\")\n",
    "else:\n",
    "    print(\"No contributing functions in ii=%d\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73358593-b7de-447d-959b-e29aaed3e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_run = func2test_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6df464c-f5f6-485d-bdf7-77f13fcb8cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tests/test_repository.py::test_search_with_symbol_prefix']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func2test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13b44538-b803-4a52-8165-f8575f57a4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_search_with_symbol_prefix']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributing_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2927ba6-e3e3-4fa4-921a-202a33706023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Using commit hash: f55705881866c3bf3256d6cd320617e0af1b3d15\n",
      "Step 1/21 : FROM --platform=linux/amd64 ubuntu:22.04\n",
      "\n",
      "---> a24be041d957\n",
      "Step 2/21 : ENV DEBIAN_FRONTEND=noninteractive\n",
      "\n",
      "---> Using cache\n",
      "---> 93762435df10\n",
      "Step 3/21 : ENV TZ=UTC\n",
      "\n",
      "---> Using cache\n",
      "---> bc5c552aabe2\n",
      "Step 4/21 : WORKDIR /app\n",
      "\n",
      "---> Using cache\n",
      "---> 00bb21a30bdf\n",
      "Step 5/21 : RUN apt-get update && apt-get install -y     software-properties-common     tzdata     git     build-essential     cmake     libopenblas-dev     libomp-dev     curl     && add-apt-repository ppa:deadsnakes/ppa -y     && apt-get update && apt-get install -y     python3.12     python3.12-dev     python3.12-venv     && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "---> Using cache\n",
      "---> 2c8b1b5dcf7e\n",
      "Step 6/21 : RUN python3.12 -m ensurepip --upgrade\n",
      "\n",
      "---> Using cache\n",
      "---> a30c0508ad70\n",
      "Step 7/21 : RUN python3.12 -m pip install --upgrade pip\n",
      "\n",
      "---> Using cache\n",
      "---> 671f0f2210ce\n",
      "Step 8/21 : RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.12 1\n",
      "\n",
      "---> Using cache\n",
      "---> 8b717ecc7a17\n",
      "Step 9/21 : RUN git clone https://github.com/mozilla/bugbug.git /app/bugbug\n",
      "\n",
      "---> Using cache\n",
      "---> 1555d0ef9e01\n",
      "Step 10/21 : WORKDIR /app/bugbug\n",
      "\n",
      "---> Using cache\n",
      "---> ee9468741947\n",
      "Step 11/21 : RUN git checkout f55705881866c3bf3256d6cd320617e0af1b3d15\n",
      "\n",
      "---> Using cache\n",
      "---> cffc3cdc83da\n",
      "Step 12/21 : RUN apt-get remove -y python3-blinker\n",
      "\n",
      "---> Using cache\n",
      "---> e78d42f58efa\n",
      "Step 13/21 : RUN pip install --no-cache-dir -r requirements.txt\n",
      "\n",
      "---> Using cache\n",
      "---> cf3e2ac3d6b2\n",
      "Step 14/21 : RUN pip install --no-cache-dir -r test-requirements.txt\n",
      "\n",
      "---> Using cache\n",
      "---> d125a67aa835\n",
      "Step 15/21 : RUN pip install --no-cache-dir -r extra-nn-requirements.txt\n",
      "\n",
      "---> Using cache\n",
      "---> 2d477c70fd86\n",
      "Step 16/21 : RUN pip install --no-cache-dir -r extra-nlp-requirements.txt\n",
      "\n",
      "---> Using cache\n",
      "---> 4e396611f446\n",
      "Step 17/21 : RUN pip install --no-cache-dir -r http_service/requirements.txt\n",
      "\n",
      "---> Using cache\n",
      "---> 1f241eb14bc8\n",
      "Step 18/21 : RUN pip install --no-cache-dir -r infra/spawn_pipeline_requirements.txt\n",
      "\n",
      "---> Using cache\n",
      "---> a24171d28413\n",
      "Step 19/21 : RUN pip install --no-cache-dir -r functions/sync-review-comments-db/requirements.txt\n",
      "\n",
      "---> Using cache\n",
      "---> e146dc800f39\n",
      "Step 20/21 : RUN pip install -e .\n",
      "\n",
      "---> Using cache\n",
      "---> 31fa7ab2ca52\n",
      "Step 21/21 : CMD [\"python3\", \"-c\", \"print('BugBug environment is ready')\"]\n",
      "\n",
      "---> Using cache\n",
      "---> 0f8ab514f3a1\n",
      "Successfully built 0f8ab514f3a1\n",
      "Successfully tagged kitsiosk__bugbug-1:latest\n",
      "[+] Docker image 'kitsiosk__bugbug-1' built successfully.\n"
     ]
    }
   ],
   "source": [
    "image_tag=instance_id\n",
    "build_docker_image(base_commit, image_tag=image_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87c56a5c-26d2-42bd-bf70-51a8a2a874d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tests/test_repository.py::test_search_with_symbol_prefix'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_to_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8b3a6a5-f56f-4073-8d86-9d544eed7cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Creating container...\n",
      "[+] Container b9c50ac44137 started.\n",
      "[+] Patch file copied to /app/bugbug/test_patch.diff\n",
      "[+] Test patch applied successfully.\n",
      "[+] Test command executed.\n",
      "[+] Test result: FAIL\n",
      "[*] Container stopped and removed.\n"
     ]
    }
   ],
   "source": [
    "test_result, stdout, coverage_report = run_test_in_container(image_tag, model_test_patch, test_to_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a0d60-92e4-4032-bd3e-2dbd64a94303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "18c2a08c-04fc-49b8-b02e-b58785ca5a2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Creating container...\n",
      "[+] Container 261ea64922b2 started.\n",
      "[+] Patch file copied to /app/bugbug/test_patch.diff\n",
      "[+] Test patch applied successfully.\n",
      "[+] Patch file copied to /app/bugbug/golden_code_patch.diff\n",
      "[+] Code patch applied successfully.\n",
      "Here1\n",
      "============================= test session starts ==============================\n",
      "platform linux -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /usr/bin/python3.12\n",
      "cachedir: .pytest_cache\n",
      "hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/app/bugbug/.hypothesis/examples'))\n",
      "rootdir: /app/bugbug\n",
      "configfile: pyproject.toml\n",
      "plugins: cov-6.0.0, hypothesis-6.124.7, responses-0.5.1, anyio-4.8.0\n",
      "collecting ... collected 1 item\n",
      "\n",
      "tests/test_repository.py::test_search_symbol_query FAILED\n",
      "\n",
      "=========================== short test summary info ============================\n",
      "FAILED tests/test_repository.py::test_search_symbol_query - requests.exceptions.ConnectionError: Connection refused by Responses - the call doesn't match any registered mock.\n",
      "\n",
      "Request: \n",
      "- GET https://searchfox.org/mozilla-central/source/some/path\n",
      "\n",
      "Available matches:\n",
      "============================== 1 failed in 2.29s ===============================\n",
      "COVERAGE_REPORT_STARTING_HERE\n",
      "Name                                       Stmts   Miss Branch BrPart  Cover   Missing\n",
      "--------------------------------------------------------------------------------------\n",
      "/usr/lib/python3/dist-packages/six.py        503    248    158     22    46%   49-72, 77, 103-104, 117, 123-126, 136-138, 150, 159-162, 190-192, 202-203, 213, 232-233, 324, 504, 512, 517-523, 535-541, 546-548, 554-556, 561, 566, 570-584, 599, 602, 605, 608, 616-632, 644, 647, 661-663, 669-689, 695, 699, 703, 707, 714-737, 753-754, 759-811, 813-820, 830-850, 861-877, 886-889, 892->894, 909-913, 928-936, 950-955, 966-973, 981->986, 986->998, 994-995\n",
      "bugbug/__init__.py                             5      1      0      0    80%   12\n",
      "bugbug/bugzilla.py                           253    205     82      0    14%   109-114, 123, 127-144, 148-193, 197-216, 220-261, 267, 278, 282, 286-307, 311, 315-324, 338-351, 362-408, 412-429, 433-445, 449-462, 470-482, 486-496, 505-636\n",
      "bugbug/code_search/__init__.py                 0      0      0      0   100%\n",
      "bugbug/code_search/function_search.py         18      2      0      0    89%   23, 29\n",
      "bugbug/code_search/searchfox_api.py           91     54     30      2    37%   23-31, 44-69, 73-89, 117->116, 129-130, 133-158, 163-168, 177-182, 189-229\n",
      "bugbug/code_search/searchfox_data.py         268    249    124      1     5%   22-47, 57-139, 143-145, 149-188, 194-360, 381-415, 420-505, 512-635\n",
      "bugbug/code_search/searchfox_download.py      50     41     24      1    14%   20-108, 112\n",
      "bugbug/commit_features.py                    183     90     36      0    42%   21, 28, 35, 40, 50, 60, 72, 79, 86, 93, 100, 107, 114, 119-125, 139, 312-335, 342-346, 538, 591-594, 644, 659-660, 698, 703, 710, 715-716, 754, 761, 766-767, 813, 817, 822-823, 863, 867-886, 890, 968-976, 979-983, 986-1036\n",
      "bugbug/db.py                                 158    114     42      1    22%   35->exit, 41, 45, 49-63, 68-87, 93-115, 119-123, 127-136, 141, 146-147, 150-151, 156-157, 160-164, 173-203, 207-214, 218-221, 225-228, 232-250\n",
      "bugbug/repository.py                         745    642    274      1    10%   112-117, 153, 157-166, 183-218, 221-222, 225, 228, 231-241, 246-252, 255-260, 264-274, 278, 289-299, 307, 316-319, 324-326, 330-333, 338, 356-377, 383-395, 401-444, 454-600, 606-657, 668-708, 719-866, 870, 876-958, 962, 966-976, 981-996, 999-1002, 1005-1008, 1015-1018, 1024-1199, 1208-1214, 1220-1236, 1241-1242, 1247-1249, 1253-1273, 1277-1290, 1295-1296, 1301-1302, 1308-1328, 1333-1334, 1348-1418, 1429-1441, 1445-1456, 1460-1468, 1476-1509, 1515-1543, 1547-1554\n",
      "bugbug/rust_code_analysis_server.py           51     34     14      0    26%   23-37, 41, 44-52, 55-56, 59, 62-66, 78-85\n",
      "bugbug/utils.py                              355    250     84      3    25%   47-60, 64, 68-71, 76-83, 88, 91, 94, 99, 102, 105, 115-117, 120-121, 129-140, 151, 157-160, 166, 170-172, 176-188, 192-228, 232-243, 247-262, 266-278, 282-294, 299-312, 317-329, 333-343, 347-354, 361-366, 371-373, 376-383, 387-388, 391-401, 404-421, 426-435, 438-441, 444, 447-450, 453, 456-458, 462-466, 471-472, 475-477, 480-487, 492-505, 519-548, 554, 563-564, 573-580, 584, 600\n",
      "tests/conftest.py                             30     11      2      0    66%   37-42, 47-53\n",
      "tests/test_repository.py                    1234   1180      4      0     4%   29-44, 48, 54-59, 63-64, 73-90, 94-133, 137-181, 185-237, 241-400, 404-484, 488-551, 556-707, 711-724, 733-775, 779-783, 790-834, 850-1322, 1326-1776, 1781-2070, 2075-2193, 2203-2270, 2274-2282, 2286-2356, 2365-2572, 2615-2823, 2881-2887\n",
      "--------------------------------------------------------------------------------------\n",
      "TOTAL                                       3944   3121    874     31    18%\n",
      "\n",
      "\n",
      "Name                                       Stmts   Miss Branch BrPart  Cover   Missing\n",
      "--------------------------------------------------------------------------------------\n",
      "/usr/lib/python3/dist-packages/six.py        503    248    158     22    46%   49-72, 77, 103-104, 117, 123-126, 136-138, 150, 159-162, 190-192, 202-203, 213, 232-233, 324, 504, 512, 517-523, 535-541, 546-548, 554-556, 561, 566, 570-584, 599, 602, 605, 608, 616-632, 644, 647, 661-663, 669-689, 695, 699, 703, 707, 714-737, 753-754, 759-811, 813-820, 830-850, 861-877, 886-889, 892->894, 909-913, 928-936, 950-955, 966-973, 981->986, 986->998, 994-995\n",
      "bugbug/__init__.py                             5      1      0      0    80%   12\n",
      "bugbug/bugzilla.py                           253    205     82      0    14%   109-114, 123, 127-144, 148-193, 197-216, 220-261, 267, 278, 282, 286-307, 311, 315-324, 338-351, 362-408, 412-429, 433-445, 449-462, 470-482, 486-496, 505-636\n",
      "bugbug/code_search/__init__.py                 0      0      0      0   100%\n",
      "bugbug/code_search/function_search.py         18      2      0      0    89%   23, 29\n",
      "bugbug/code_search/searchfox_api.py           91     54     30      2    37%   23-31, 44-69, 73-89, 117->116, 129-130, 133-158, 163-168, 177-182, 189-229\n",
      "bugbug/code_search/searchfox_data.py         268    249    124      1     5%   22-47, 57-139, 143-145, 149-188, 194-360, 381-415, 420-505, 512-635\n",
      "bugbug/code_search/searchfox_download.py      50     41     24      1    14%   20-108, 112\n",
      "bugbug/commit_features.py                    183     90     36      0    42%   21, 28, 35, 40, 50, 60, 72, 79, 86, 93, 100, 107, 114, 119-125, 139, 312-335, 342-346, 538, 591-594, 644, 659-660, 698, 703, 710, 715-716, 754, 761, 766-767, 813, 817, 822-823, 863, 867-886, 890, 968-976, 979-983, 986-1036\n",
      "bugbug/db.py                                 158    114     42      1    22%   35->exit, 41, 45, 49-63, 68-87, 93-115, 119-123, 127-136, 141, 146-147, 150-151, 156-157, 160-164, 173-203, 207-214, 218-221, 225-228, 232-250\n",
      "bugbug/repository.py                         745    642    274      1    10%   112-117, 153, 157-166, 183-218, 221-222, 225, 228, 231-241, 246-252, 255-260, 264-274, 278, 289-299, 307, 316-319, 324-326, 330-333, 338, 356-377, 383-395, 401-444, 454-600, 606-657, 668-708, 719-866, 870, 876-958, 962, 966-976, 981-996, 999-1002, 1005-1008, 1015-1018, 1024-1199, 1208-1214, 1220-1236, 1241-1242, 1247-1249, 1253-1273, 1277-1290, 1295-1296, 1301-1302, 1308-1328, 1333-1334, 1348-1418, 1429-1441, 1445-1456, 1460-1468, 1476-1509, 1515-1543, 1547-1554\n",
      "bugbug/rust_code_analysis_server.py           51     34     14      0    26%   23-37, 41, 44-52, 55-56, 59, 62-66, 78-85\n",
      "bugbug/utils.py                              355    250     84      3    25%   47-60, 64, 68-71, 76-83, 88, 91, 94, 99, 102, 105, 115-117, 120-121, 129-140, 151, 157-160, 166, 170-172, 176-188, 192-228, 232-243, 247-262, 266-278, 282-294, 299-312, 317-329, 333-343, 347-354, 361-366, 371-373, 376-383, 387-388, 391-401, 404-421, 426-435, 438-441, 444, 447-450, 453, 456-458, 462-466, 471-472, 475-477, 480-487, 492-505, 519-548, 554, 563-564, 573-580, 584, 600\n",
      "tests/conftest.py                             30     11      2      0    66%   37-42, 47-53\n",
      "tests/test_repository.py                    1234   1180      4      0     4%   29-44, 48, 54-59, 63-64, 73-90, 94-133, 137-181, 185-237, 241-400, 404-484, 488-551, 556-707, 711-724, 733-775, 779-783, 790-834, 850-1322, 1326-1776, 1781-2070, 2075-2193, 2203-2270, 2274-2282, 2286-2356, 2365-2572, 2615-2823, 2881-2887\n",
      "--------------------------------------------------------------------------------------\n",
      "TOTAL                                       3944   3121    874     31    18%\n",
      "\n",
      "[+] Test command executed.\n",
      "[+] Test result: FAIL\n",
      "[*] Container stopped and removed.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m golden_code_patch   \u001b[38;5;241m=\u001b[39m instance[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m test_result, stdout \u001b[38;5;241m=\u001b[39m run_test_in_container(image_tag, model_test_patch, test_to_run, golden_code_patch\u001b[38;5;241m=\u001b[39mgolden_code_patch)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "golden_code_patch = instance[\"patch\"]\n",
    "test_result, stdout, coverage_report = run_test_in_container(image_tag, model_test_patch, test_to_run, golden_code_patch=golden_code_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d50005ad-51fb-4aae-be55-90e528b90e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform linux -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /usr/bin/python3.12\n",
      "cachedir: .pytest_cache\n",
      "hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/app/bugbug/.hypothesis/examples'))\n",
      "rootdir: /app/bugbug\n",
      "configfile: pyproject.toml\n",
      "plugins: cov-6.0.0, hypothesis-6.124.7, responses-0.5.1, anyio-4.8.0\n",
      "collecting ... collected 1 item\n",
      "\n",
      "tests/test_repository.py::test_search_symbol_query FAILED\n",
      "\n",
      "=========================== short test summary info ============================\n",
      "FAILED tests/test_repository.py::test_search_symbol_query - requests.exceptions.ConnectionError: Connection refused by Responses - the call doesn't match any registered mock.\n",
      "\n",
      "Request: \n",
      "- GET https://searchfox.org/mozilla-central/source/some/path\n",
      "\n",
      "Available matches:\n",
      "============================== 1 failed in 2.41s ===============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "33ad0420-4952-4f25-a95d-ebb99a60e2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kitsiosk'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92218e9f-9794-4188-96ef-d1091c392904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
